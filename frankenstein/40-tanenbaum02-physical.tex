\chapter{The physical layer}

In this chapter we will look at the lowest layer depicted in the hierarchy of \vref{fig:osi-model}.
It defines the mechanical, electrical, and timing interfaces to the network.
We will begin with a theoretical analysis of data transmission, only to discover that Mother (Parent?) Nature puts some limits on what can be sent over a channel.

Then we will cover three kinds of transmission media: guided (copper
wire and fiber optics), wireless (terrestrial radio), and satellite.
This material will provide background information on the key
transmission technologies used in modern networks.

The remainder of the chapter will be devoted to three examples of
communication systems used in practice for wide area computer networks:
the (fixed) telephone system, the mobile phone system, and the cable
television system. All three use fiber optics in the backbone, but they
are organized differently and use different technologies for the last
mile.

\section{The theoretical basis for data communication}

Information can be transmitted on wires by varying some physical property such as voltage or current.
By representing the value of this voltage or current as a single-valued function of time, $f(t)$, we can model the behavior of the signal and analyze it mathematically.
This analysis is the subject of the following sections.
\subsection{Fourier analysis}

In the early 19th century, the French mathematician Jean-Baptiste Fourier proved that any reasonably behaved periodic function, $g(t)$ with period $T$ can be constructed as the sum of a (possibly infinite) number of sines and cosines:

\begin{equation}
g(t) = \frac{1}{2}c + \sum_{n=1}^\infty a_n \sin(2\pi nft) + \sum_{n=1}^\infty b_n \cos(2\pi nft) \label{eqn:fourier}
\end{equation}

where $f = 1/T$ is the fundamental frequency, $a_n$ and $b_n$ are the sine and cosine amplitudes of the $n$th emph{harmonics} (terms), and $c$ is a constant.
Such a decomposition is called a \emph{Fourier series}.
From the Fourier series, the function can be reconstructed; that is, if the period, $T$, is known and the amplitudes are given, the original function of time can be found by
performing the sums of \cref{eqn:fourier}.

A data signal that has a finite duration (which all of them do) can be
handled by just imagining that it repeats the entire pattern over and
over forever (i.e., the interval from $T$ to $2T$ is the same as from $0$ to $T$, etc.).

The $a_n$ amplitudes can be computed for any given $g(t)$ by multiplying both sides of \cref{eqn:fourier} by $\sin(2\pi kft)$ and then integrating from 0 to $T$.
Since

%\includegraphics{02icon02.gif}

~

only one term of the summation survives: {a}{\textsubscript{n}}{.} The
{b}{\textsubscript{n}} summation vanishes completely. Similarly, by
multiplying
\protect\hyperlink{0130661023_ch02lev1sec1.htmlux5cux23ch02eq01}{Eq.
(2-1)} by cos(2{p}{kft}) and integrating between 0 and {T}, we can
derive {b}{\textsubscript{n}}{.} By just integrating both sides of the
equation as it stands, we can find {c}. The results of performing these
operations are as follows:

%\includegraphics{02icon03.gif}

~

\protect\hypertarget{0130661023_ch02lev1sec1.htmlux5cux23ch02lev2sec2}{}{}

\subsection{Bandwidth-Limited Signals}

To see what all this has to do with data communication, let us consider
a specific example: the transmission of the ASCII character ``b''
encoded in an 8-bit byte. The bit pattern that is to be transmitted is
01100010. The left-hand part of
\protect\hyperlink{0130661023_ch02lev1sec1.htmlux5cux23ch02fig01}{Fig.
2-1(a)} shows the voltage output by the transmitting computer. The
Fourier analysis of this signal yields the coefficients:

\subparagraph[Figure 2-1. (a) A binary signal and its root-mean-square
Fourier amplitudes. (b)-(e) Successive approximations to the original
signal.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec1.htmlux5cux23ch02fig01}{}{}Figure
2-1. (a) A binary signal and its root-mean-square Fourier amplitudes.
(b)-(e) Successive approximations to the original
signal.}{Figure 2-1. (a) A binary signal and its root-mean-square Fourier amplitudes. (b)-(e) Successive approximations to the original signal.}}

%\includegraphics{02fig01.gif}

%\includegraphics{02icon04.gif}

~

The root-mean-square amplitudes,
%\includegraphics{02icon05.gif}
, for the
first few terms are shown on the right-hand side of
\protect\hyperlink{0130661023_ch02lev1sec1.htmlux5cux23ch02fig01}{Fig.
2-1(a)}. These values are of interest because their squares are
proportional to the energy transmitted at the corresponding frequency.

No transmission facility can transmit signals without losing some power
in the process. If all the Fourier components were equally diminished,
the resulting signal would be reduced in amplitude but not distorted
{[}i.e., it would have the same nice squared-off shape as
\protect\hyperlink{0130661023_ch02lev1sec1.htmlux5cux23ch02fig01}{Fig.
2-1(a)}{]}. Unfortunately, all transmission facilities diminish
different Fourier components by different amounts, thus introducing
distortion. Usually, the amplitudes are transmitted undiminished from 0
up to some frequency {f}{\textsubscript{c}} {[}measured in cycles/sec or
Hertz (Hz){]} with all frequencies above this cutoff frequency
attenuated. The range of frequencies transmitted without being strongly
attenuated is called the {bandwidth}. In practice, the cutoff is not
really sharp, so often the quoted bandwidth is from 0 to the frequency
at which half the power gets through.

The bandwidth is a physical property of the transmission medium and
usually depends on the construction, thickness, and length of the
medium. In some cases a filter is introduced into the circuit to limit
the amount of bandwidth available to each customer. For example, a
telephone wire may have a bandwidth of 1 MHz for short distances, but
telephone companies add a filter restricting each customer to about 3100
Hz. This bandwidth is adequate for intelligible speech and improves
system-wide efficiency by limiting resource usage by customers.

Now let us consider how the signal of
\protect\hyperlink{0130661023_ch02lev1sec1.htmlux5cux23ch02fig01}{Fig.
2-1(a)} would look if the bandwidth were so low that only the lowest
frequencies were transmitted {[}i.e., if the function were being
approximated by the first few terms of
\protect\hyperlink{0130661023_ch02lev1sec1.htmlux5cux23ch02eq01}{Eq.
(2-1)}{]}.
\protect\hyperlink{0130661023_ch02lev1sec1.htmlux5cux23ch02fig01}{Figure
2-1(b)} shows the signal that results from a channel that allows only
the first harmonic (the fundamental, {f}) to pass through. Similarly,
\protect\hyperlink{0130661023_ch02lev1sec1.htmlux5cux23ch02fig01}{Fig.
2-1(c)}-\protect\hyperlink{0130661023_ch02lev1sec1.htmlux5cux23ch02fig01}{(e)}
show the spectra and reconstructed functions for higher-bandwidth
channels.

Given a bit rate of {b} bits/sec, the time required to send 8 bits (for
example) 1 bit at a time is 8{/b} sec, so the frequency of the first
harmonic is {b/}8 Hz. An ordinary telephone line, often called a
{voice-grade line}, has an artificially-introduced cutoff frequency just
above 3000 Hz. This restriction means that the number of the highest
harmonic passed through is roughly 3000{/}({b/}8) or 24,000{/b}, (the
cutoff is not sharp).

For some data rates, the numbers work out as shown in
\protect\hyperlink{0130661023_ch02lev1sec1.htmlux5cux23ch02fig02}{Fig.
2-2}. From these numbers, it is clear that trying to send at 9600 bps
over a voice-grade telephone line will transform
\protect\hyperlink{0130661023_ch02lev1sec1.htmlux5cux23ch02fig01}{Fig.
2-1(a)} into something looking like
\protect\hyperlink{0130661023_ch02lev1sec1.htmlux5cux23ch02fig01}{Fig.
2-1(c)}, making accurate reception of the original binary bit stream
tricky. It should be obvious that at data rates much higher than 38.4
kbps, there is no hope at all for {binary} signals, even if the
transmission facility is completely noiseless. In other words, limiting
the bandwidth limits the data rate, even for perfect channels. However,
sophisticated coding schemes that make use of several voltage levels do
exist and can achieve higher data rates. We will discuss these later in
this chapter.

\subparagraph[Figure 2-2. Relation between data rate and
harmonics.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec1.htmlux5cux23ch02fig02}{}{}Figure
2-2. Relation between data rate and
harmonics.}{Figure 2-2. Relation between data rate and harmonics.}}

%\includegraphics{02fig02.gif}

\protect\hypertarget{0130661023_ch02lev1sec1.htmlux5cux23ch02lev2sec3}{}{}

\subsection{The Maximum Data Rate of a Channel}

As early as 1924, an AT\&T engineer, Henry Nyquist, realized that even a
perfect channel has a finite transmission capacity. He derived an
equation expressing the maximum data rate for a finite bandwidth
noiseless channel. In 1948, Claude Shannon carried Nyquist's work
further and extended it to the case of a channel subject to random (that
is, thermodynamic) noise (Shannon, 1948). We will just briefly summarize
their now classical results here.

Nyquist proved that if an arbitrary signal has been run through a
low-pass filter of bandwidth {H}, the filtered signal can be completely
reconstructed by making only 2{H} (exact) samples per second. Sampling
the line faster than 2{H} times per second is pointless because the
higher frequency components that such sampling could recover have
already been filtered out. If the signal consists of {V} discrete
levels, Nyquist's theorem states:

%\includegraphics{02icon06.gif}

~

For example, a noiseless 3-kHz channel cannot transmit binary (i.e.,
two-level) signals at a rate exceeding 6000 bps.

So far we have considered only noiseless channels. If random noise is
present, the situation deteriorates rapidly. And there is always random
(thermal) noise present due to the motion of the molecules in the
system. The amount of thermal noise present is measured by the ratio of
the signal power to the noise power, called the {signal-to-noise ratio}.
If we denote the signal power by {S} and the noise power by {N}, the
signal-to-noise ratio is {S/N}. Usually, the ratio itself is not quoted;
instead, the quantity 10 log\textsubscript{10} {S/N} is given. These
units are called {decibels} (dB). An {S/N} ratio of 10 is 10 dB, a ratio
of 100 is 20 dB, a ratio of 1000 is 30 dB, and so on. The manufacturers
of stereo amplifiers often characterize the bandwidth (frequency range)
over which their product is linear by giving the 3-dB frequency on each
end. These are the points at which the amplification factor has been
approximately halved (because log\textsubscript{10}3
%\includegraphics{u2248.gif}
 0.5).

Shannon's major result is that the maximum data rate of a noisy channel
whose bandwidth is {H} Hz, and whose signal-to-noise ratio is {S/N}, is
given by

%\includegraphics{02icon07.gif}

~

For example, a channel of 3000-Hz bandwidth with a signal to thermal
noise ratio of 30 dB (typical parameters of the analog part of the
telephone system) can never transmit much more than 30,000 bps, no
matter how many or how few signal levels are used and no matter how
often or how infrequently samples are taken. Shannon's result was
derived from information-theory arguments and applies to any channel
subject to thermal noise. Counterexamples should be treated in the same
category as perpetual motion machines. It should be noted that this is
only an upper bound and real systems rarely achieve it.

\protect\hypertarget{0130661023_ch02lev1sec2.html}{}{}

\protect\hypertarget{0130661023_ch02lev1sec2.htmlux5cux23ch02lev1sec2}{}{}

\section{Guided Transmission Media}

The purpose of the physical layer is to transport a raw bit stream from
one machine to another. Various physical media can be used for the
actual transmission. Each one has its own niche in terms of bandwidth,
delay, cost, and ease of installation and maintenance. Media are roughly
grouped into guided media, such as copper wire and fiber optics, and
unguided media, such as radio and lasers through the air. We will look
at all of these in the following sections.

\protect\hypertarget{0130661023_ch02lev1sec2.htmlux5cux23ch02lev2sec4}{}{}

\subsection{Magnetic media}

One of the most common ways to transport data from one computer to
another is to write them onto magnetic tape or removable media (e.g.,
recordable DVDs), physically transport the tape or disks to the
destination machine, and read them back in again. Although this method
is not as sophisticated as using a geosynchronous communication
satellite, it is often more cost effective, especially for applications
in which high bandwidth or cost per bit transported is the key factor.

A simple calculation will make this point clear. An industry standard
Ultrium tape can hold 200 gigabytes. A box 60 x 60 x 60 cm can hold
about 1000 of these tapes, for a total capacity of 200 terabytes, or
1600 terabits (1.6 petabits). A box of tapes can be delivered anywhere
in the United States in 24 hours by Federal Express and other companies.
The effective bandwidth of this transmission is 1600 terabits/86,400
sec, or 19 Gbps. If the destination is only an hour away by road, the
bandwidth is increased to over 400 Gbps. No computer network can even
approach this.

For a bank with many gigabytes of data to be backed up daily on a second
machine (so the bank can continue to function even in the face of a
major flood or earthquake), it is likely that no other transmission
technology can even begin to approach magnetic tape for performance. Of
course, networks are getting faster, but tape densities are increasing,
too.

If we now look at cost, we get a similar picture. The cost of an Ultrium
tape is around \$40 when bought in bulk. A tape can be reused at least
ten times, so the tape cost is maybe \$4000 per box per usage. Add to
this another \$1000 for shipping (probably much less), and we have a
cost of roughly \$5000 to ship 200 TB. This amounts to shipping a
gigabyte for under 3 cents. No network can beat that. The moral of the
story is:

\begin{quote}
{Never underestimate the bandwidth of a station wagon full of tapes
hurtling down the highway}
\end{quote}

\protect\hypertarget{0130661023_ch02lev1sec2.htmlux5cux23ch02lev2sec5}{}{}

\subsection{Twisted pair}

Although the bandwidth characteristics of magnetic tape are excellent,
the delay characteristics are poor. Transmission time is measured in
minutes or hours, not milliseconds. For many applications an on-line
connection is needed. One of the oldest and still most common
transmission media is {twisted pair}. A twisted pair consists of two
insulated copper wires, typically about 1 mm thick. The wires are
twisted together in a helical form, just like a DNA molecule. Twisting
is done because two parallel wires constitute a fine antenna. When the
wires are twisted, the waves from different twists cancel out, so the
wire radiates less effectively.

The most common application of the twisted pair is the telephone system.
Nearly all telephones are connected to the telephone company (telco)
office by a twisted pair. Twisted pairs can run several kilometers
without amplification, but for longer distances, repeaters are needed.
When many twisted pairs run in parallel for a substantial distance, such
as all the wires coming from an apartment building to the telephone
company office, they are bundled together and encased in a protective
sheath. The pairs in these bundles would interfere with one another if
it were not for the twisting. In parts of the world where telephone
lines run on poles above ground, it is common to see bundles several
centimeters in diameter.

Twisted pairs can be used for transmitting either analog or digital
signals. The bandwidth depends on the thickness of the wire and the
distance traveled, but several megabits/sec can be achieved for a few
kilometers in many cases. Due to their adequate performance and low
cost, twisted pairs are widely used and are likely to remain so for
years to come.

Twisted pair cabling comes in several varieties, two of which are
important for computer networks. {Category 3} twisted pairs consist of
two insulated wires gently twisted together. Four such pairs are
typically grouped in a plastic sheath to protect the wires and keep them
together. Prior to about 1988, most office buildings had one category 3
cable running from a central {wiring closet} on each floor into each
office. This scheme allowed up to four regular telephones or two
multiline telephones in each office to connect to the telephone company
equipment in the wiring closet.

Starting around 1988, the more advanced {category 5} twisted pairs were
introduced. They are similar to category 3 pairs, but with more twists
per centimeter, which results in less crosstalk and a better-quality
signal over longer distances, making them more suitable for high-speed
computer communication. Up-and-coming categories are 6 and 7, which are
capable of handling signals with bandwidths of 250 MHz and 600 MHz,
respectively (versus a mere 16 MHz and 100 MHz for categories 3 and 5,
respectively).

All of these wiring types are often referred to as {UTP} ({Unshielded
Twisted Pair}), to contrast them with the bulky, expensive, shielded
twisted pair cables IBM introduced in the early 1980s, but which have
not proven popular outside of IBM installations. Twisted pair cabling is
illustrated in
\protect\hyperlink{0130661023_ch02lev1sec2.htmlux5cux23ch02fig03}{Fig.
2-3}.

\subparagraph[Figure 2-3. (a) Category 3 UTP. (b) Category 5
UTP.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec2.htmlux5cux23ch02fig03}{}{}Figure
2-3. (a) Category 3 UTP. (b) Category 5
UTP.}{Figure 2-3. (a) Category 3 UTP. (b) Category 5 UTP.}}

%\includegraphics{02fig03.gif}

\protect\hypertarget{0130661023_ch02lev1sec2.htmlux5cux23ch02lev2sec6}{}{}

\subsection{Coaxial cable}

Another common transmission medium is the {coaxial cable} (known to its
many friends as just ``coax'' and pronounced ``co-ax''). It has better
shielding than twisted pairs, so it can span longer distances at higher
speeds. Two kinds of coaxial cable are widely used. One kind, 50-ohm
cable, is commonly used when it is intended for digital transmission
from the start. The other kind, 75-ohm cable, is commonly used for
analog transmission and cable television but is becoming more important
with the advent of Internet over cable. This distinction is based on
historical, rather than technical, factors (e.g., early dipole antennas
had an impedance of 300 ohms, and it was easy to use existing 4:1
impedance matching transformers).

A coaxial cable consists of a stiff copper wire as the core, surrounded
by an insulating material. The insulator is encased by a cylindrical
conductor, often as a closely-woven braided mesh. The outer conductor is
covered in a protective plastic sheath. A cutaway view of a coaxial
cable is shown in
\protect\hyperlink{0130661023_ch02lev1sec2.htmlux5cux23ch02fig04}{Fig.
2-4}.

\subparagraph[Figure 2-4. A coaxial
cable.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec2.htmlux5cux23ch02fig04}{}{}Figure
2-4. A coaxial cable.}{Figure 2-4. A coaxial cable.}}

%\includegraphics{02fig04.gif}

The construction and shielding of the coaxial cable give it a good
combination of high bandwidth and excellent noise immunity. The
bandwidth possible depends on the cable quality, length, and
signal-to-noise ratio of the data signal. Modern cables have a bandwidth
of close to 1 GHz. Coaxial cables used to be widely used within the
telephone system for long-distance lines but have now largely been
replaced by fiber optics on long-haul routes. Coax is still widely used
for cable television and metropolitan area networks, however.

\protect\hypertarget{0130661023_ch02lev1sec2.htmlux5cux23ch02lev2sec7}{}{}

\subsection{Fiber optics}

Many people in the computer industry take enormous pride in how fast
computer technology is improving. The original (1981) IBM PC ran at a
clock speed of 4.77 MHz. Twenty years later, PCs could run at 2 GHz, a
gain of a factor of 20 per decade. Not too bad.

In the same period, wide area data communication went from 56 kbps (the
ARPANET) to 1 Gbps (modern optical communication), a gain of more than a
factor of 125 per decade, while at the same time the error rate went
from 10\textsuperscript{-5} per bit to almost zero.

Furthermore, single CPUs are beginning to approach physical limits, such
as speed of light and heat dissipation problems. In contrast, with
{current} fiber technology, the achievable bandwidth is certainly in
excess of 50,000 Gbps (50 Tbps) and many people are looking very hard
for better technologies and materials. The current practical signaling
limit of about 10 Gbps is due to our inability to convert between
electrical and optical signals any faster, although in the laboratory,
100 Gbps has been achieved on a single fiber.

In the race between computing and communication, communication won. The
full implications of essentially infinite bandwidth (although not at
zero cost) have not yet sunk in to a generation of computer scientists
and engineers taught to think in terms of the low Nyquist and Shannon
limits imposed by copper wire. The new conventional wisdom should be
that all computers are hopelessly slow and that networks should try to
avoid computation at all costs, no matter how much bandwidth that
wastes. In this section we will study fiber optics to see how that
transmission technology works.

An optical transmission system has three key components: the light
source, the transmission medium, and the detector. Conventionally, a
pulse of light indicates a 1 bit and the absence of light indicates a 0
bit. The transmission medium is an ultra-thin fiber of glass. The
detector generates an electrical pulse when light falls on it. By
attaching a light source to one end of an optical fiber and a detector
to the other, we have a unidirectional data transmission system that
accepts an electrical signal, converts and transmits it by light pulses,
and then reconverts the output to an electrical signal at the receiving
end.

This transmission system would leak light and be useless in practice
except for an interesting principle of physics. When a light ray passes
from one medium to another, for example, from fused silica to air, the
ray is refracted (bent) at the silica/air boundary, as shown in
\protect\hyperlink{0130661023_ch02lev1sec2.htmlux5cux23ch02fig05}{Fig.
2-5(a)}. Here we see a light ray incident on the boundary at an angle
{a}\textsubscript{1} emerging at an angle {b}\textsubscript{1}{.} The
amount of refraction depends on the properties of the two media (in
particular, their indices of refraction). For angles of incidence above
a certain critical value, the light is refracted back into the silica;
none of it escapes into the air. Thus, a light ray incident at or above
the critical angle is trapped inside the fiber, as shown in
\protect\hyperlink{0130661023_ch02lev1sec2.htmlux5cux23ch02fig05}{Fig.
2-5(b)}, and can propagate for many kilometers with virtually no loss.

\subparagraph[Figure 2-5. (a) Three examples of a light ray from inside
a silica fiber impinging on the air/silica boundary at different angles.
(b) Light trapped by total internal
reflection.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec2.htmlux5cux23ch02fig05}{}{}Figure
2-5. (a) Three examples of a light ray from inside a silica fiber
impinging on the air/silica boundary at different angles. (b) Light
trapped by total internal
reflection.}{Figure 2-5. (a) Three examples of a light ray from inside a silica fiber impinging on the air/silica boundary at different angles. (b) Light trapped by total internal reflection.}}

%\includegraphics{02fig05.gif}

The sketch of
\protect\hyperlink{0130661023_ch02lev1sec2.htmlux5cux23ch02fig05}{Fig.
2-5(b)} shows only one trapped ray, but since any light ray incident on
the boundary above the critical angle will be reflected internally, many
different rays will be bouncing around at different angles. Each ray is
said to have a different {mode}, so a fiber having this property is
called a {multimode fiber}.

However, if the fiber's diameter is reduced to a few wavelengths of
light, the fiber acts like a wave guide, and the light can propagate
only in a straight line, without bouncing, yielding a {single-mode
fiber}. Single-mode fibers are more expensive but are widely used for
longer distances. Currently available single-mode fibers can transmit
data at 50 Gbps for 100 km without amplification. Even higher data rates
have been achieved in the laboratory for shorter distances.

\protect\hypertarget{0130661023_ch02lev1sec2.htmlux5cux23ch02lev3sec1}{}{}

\subparagraph{Transmission of Light through Fiber}

Optical fibers are made of glass, which, in turn, is made from sand, an
inexpensive raw material available in unlimited amounts. Glassmaking was
known to the ancient Egyptians, but their glass had to be no more than 1
mm thick or the light could not shine through. Glass transparent enough
to be useful for windows was developed during the Renaissance. The glass
used for modern optical fibers is so transparent that if the oceans were
full of it instead of water, the seabed would be as visible from the
surface as the ground is from an airplane on a clear day.

The attenuation of light through glass depends on the wavelength of the
light (as well as on some physical properties of the glass). For the
kind of glass used in fibers, the attenuation is shown in
\protect\hyperlink{0130661023_ch02lev1sec2.htmlux5cux23ch02fig06}{Fig.
2-6} in decibels per linear kilometer of fiber. The attenuation in
decibels is given by the formula

\subparagraph[Figure 2-6. Attenuation of light through fiber in the
infrared
region.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec2.htmlux5cux23ch02fig06}{}{}Figure
2-6. Attenuation of light through fiber in the infrared
region.}{Figure 2-6. Attenuation of light through fiber in the infrared region.}}

%\includegraphics{02fig06.gif}

%\includegraphics{02icon08.gif}

~

For example, a factor of two loss gives an attenuation of 10
log\textsubscript{10} 2 = 3 dB. The figure shows the near infrared part
of the spectrum, which is what is used in practice. Visible light has
slightly shorter wavelengths, from 0.4 to 0.7 microns (1 micron is
10\textsuperscript{-6} meters). The true metric purist would refer to
these wavelengths as 400 nm to 700 nm, but we will stick with
traditional usage.

Three wavelength bands are used for optical communication. They are
centered at 0.85, 1.30, and 1.55 microns, respectively. The last two
have good attenuation properties (less than 5 percent loss per
kilometer). The 0.85 micron band has higher attenuation, but at that
wavelength the lasers and electronics can be made from the same material
(gallium arsenide). All three bands are 25,000 to 30,000 GHz wide.

Light pulses sent down a fiber spread out in length as they propagate.
This spreading is called {chromatic dispersion}. The amount of it is
wavelength dependent. One way to keep these spread-out pulses from
overlapping is to increase the distance between them, but this can be
done only by reducing the signaling rate. Fortunately, it has been
discovered that by making the pulses in a special shape related to the
reciprocal of the hyperbolic cosine, nearly all the dispersion effects
cancel out, and it is possible to send pulses for thousands of
kilometers without appreciable shape distortion. These pulses are called
{solitons}. A considerable amount of research is going on to take
solitons out of the lab and into the field.

\protect\hypertarget{0130661023_ch02lev1sec2.htmlux5cux23ch02lev3sec2}{}{}

\subparagraph{Fiber Cables}

Fiber optic cables are similar to coax, except without the braid.
\protect\hyperlink{0130661023_ch02lev1sec2.htmlux5cux23ch02fig07}{Figure
2-7(a)} shows a single fiber viewed from the side. At the center is the
glass core through which the light propagates. In multimode fibers, the
core is typically 50 microns in diameter, about the thickness of a human
hair. In single-mode fibers, the core is 8 to 10 microns.

\subparagraph[Figure 2-7. (a) Side view of a single fiber. (b) End view
of a sheath with three
fibers.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec2.htmlux5cux23ch02fig07}{}{}Figure
2-7. (a) Side view of a single fiber. (b) End view of a sheath with
three
fibers.}{Figure 2-7. (a) Side view of a single fiber. (b) End view of a sheath with three fibers.}}

%\includegraphics{02fig07.gif}

The core is surrounded by a glass cladding with a lower index of
refraction than the core, to keep all the light in the core. Next comes
a thin plastic jacket to protect the cladding. Fibers are typically
grouped in bundles, protected by an outer sheath.
\protect\hyperlink{0130661023_ch02lev1sec2.htmlux5cux23ch02fig07}{Figure
2-7(b)} shows a sheath with three fibers.

Terrestrial fiber sheaths are normally laid in the ground within a meter
of the surface, where they are occasionally subject to attacks by
backhoes or gophers. Near the shore, transoceanic fiber sheaths are
buried in trenches by a kind of seaplow. In deep water, they just lie on
the bottom, where they can be snagged by fishing trawlers or attacked by
giant squid.

Fibers can be connected in three different ways. First, they can
terminate in connectors and be plugged into fiber sockets. Connectors
lose about 10 to 20 percent of the light, but they make it easy to
reconfigure systems.

Second, they can be spliced mechanically. Mechanical splices just lay
the two carefully-cut ends next to each other in a special sleeve and
clamp them in place. Alignment can be improved by passing light through
the junction and then making small adjustments to maximize the signal.
Mechanical splices take trained personnel about 5 minutes and result in
a 10 percent light loss.

Third, two pieces of fiber can be fused (melted) to form a solid
connection. A fusion splice is almost as good as a single drawn fiber,
but even here, a small amount of attenuation occurs.

For all three kinds of splices, reflections can occur at the point of
the splice, and the reflected energy can interfere with the signal.

Two kinds of light sources are typically used to do the signaling, LEDs
(Light Emitting Diodes) and semiconductor lasers. They have different
properties, as shown in
\protect\hyperlink{0130661023_ch02lev1sec2.htmlux5cux23ch02fig08}{Fig.
2-8}. They can be tuned in wavelength by inserting Fabry-Perot or
Mach-Zehnder interferometers between the source and the fiber.
Fabry-Perot interferometers are simple resonant cavities consisting of
two parallel mirrors. The light is incident perpendicular to the
mirrors. The length of the cavity selects out those wavelengths that fit
inside an integral number of times. Mach-Zehnder interferometers
separate the light into two beams. The two beams travel slightly
different distances. They are recombined at the end and are in phase for
only certain wavelengths.

\subparagraph[Figure 2-8. A comparison of semiconductor diodes and LEDs
as light
sources.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec2.htmlux5cux23ch02fig08}{}{}Figure
2-8. A comparison of semiconductor diodes and LEDs as light
sources.}{Figure 2-8. A comparison of semiconductor diodes and LEDs as light sources.}}

%\includegraphics{02fig08.gif}

The receiving end of an optical fiber consists of a photodiode, which
gives off an electrical pulse when struck by light. The typical response
time of a photodiode is 1 nsec, which limits data rates to about 1 Gbps.
Thermal noise is also an issue, so a pulse of light must carry enough
energy to be detected. By making the pulses powerful enough, the error
rate can be made arbitrarily small.

\protect\hypertarget{0130661023_ch02lev1sec2.htmlux5cux23ch02lev3sec3}{}{}

\subparagraph{Fiber Optic Networks}

Fiber optics can be used for LANs as well as for long-haul transmission,
although tapping into it is more complex than connecting to an Ethernet.
One way around the problem is to realize that a ring network is really
just a collection of point-to-point links, as shown in
\protect\hyperlink{0130661023_ch02lev1sec2.htmlux5cux23ch02fig09}{Fig.
2-9}. The interface at each computer passes the light pulse stream
through to the next link and also serves as a T junction to allow the
computer to send and accept messages.

\subparagraph[Figure 2-9. A fiber optic ring with active
repeaters.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec2.htmlux5cux23ch02fig09}{}{}Figure
2-9. A fiber optic ring with active
repeaters.}{Figure 2-9. A fiber optic ring with active repeaters.}}

%\includegraphics{02fig09.gif}

Two types of interfaces are used. A passive interface consists of two
taps fused onto the main fiber. One tap has an LED or laser diode at the
end of it (for transmitting), and the other has a photodiode (for
receiving). The tap itself is completely passive and is thus extremely
reliable because a broken LED or photodiode does not break the ring. It
just takes one computer off-line.

The other interface type, shown in
\protect\hyperlink{0130661023_ch02lev1sec2.htmlux5cux23ch02fig09}{Fig.
2-9}, is the {active repeater}. The incoming light is converted to an
electrical signal, regenerated to full strength if it has been weakened,
and retransmitted as light. The interface with the computer is an
ordinary copper wire that comes into the signal regenerator. Purely
optical repeaters are now being used, too. These devices do not require
the optical to electrical to optical conversions, which means they can
operate at extremely high bandwidths.

If an active repeater fails, the ring is broken and the network goes
down. On the other hand, since the signal is regenerated at each
interface, the individual computer-to-computer links can be kilometers
long, with virtually no limit on the total size of the ring. The passive
interfaces lose light at each junction, so the number of computers and
total ring length are greatly restricted.

A ring topology is not the only way to build a LAN using fiber optics.
It is also possible to have hardware broadcasting by using the {passive
star} construction of
\protect\hyperlink{0130661023_ch02lev1sec2.htmlux5cux23ch02fig10}{Fig.
2-10}. In this design, each interface has a fiber running from its
transmitter to a silica cylinder, with the incoming fibers fused to one
end of the cylinder. Similarly, fibers fused to the other end of the
cylinder are run to each of the receivers. Whenever an interface emits a
light pulse, it is diffused inside the passive star to illuminate all
the receivers, thus achieving broadcast. In effect, the passive star
combines all the incoming signals and transmits the merged result on all
lines. Since the incoming energy is divided among all the outgoing
lines, the number of nodes in the network is limited by the sensitivity
of the photodiodes.

\subparagraph[Figure 2-10. A passive star connection in a fiber optics
network.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec2.htmlux5cux23ch02fig10}{}{}Figure
2-10. A passive star connection in a fiber optics
network.}{Figure 2-10. A passive star connection in a fiber optics network.}}

%\includegraphics{02fig10.gif}

\protect\hypertarget{0130661023_ch02lev1sec2.htmlux5cux23ch02lev3sec4}{}{}

\subparagraph{Comparison of Fiber Optics and Copper Wire}

It is instructive to compare fiber to copper. Fiber has many advantages.
To start with, it can handle much higher bandwidths than copper. This
alone would require its use in high-end networks. Due to the low
attenuation, repeaters are needed only about every 50 km on long lines,
versus about every 5 km for copper, a substantial cost saving. Fiber
also has the advantage of not being affected by power surges,
electromagnetic interference, or power failures. Nor is it affected by
corrosive chemicals in the air, making it ideal for harsh factory
environments.

Oddly enough, telephone companies like fiber for a different reason: it
is thin and lightweight. Many existing cable ducts are completely full,
so there is no room to add new capacity. Removing all the copper and
replacing it by fiber empties the ducts, and the copper has excellent
resale value to copper refiners who see it as very high grade ore. Also,
fiber is much lighter than copper. One thousand twisted pairs 1 km long
weigh 8000 kg. Two fibers have more capacity and weigh only 100 kg,
which greatly reduces the need for expensive mechanical support systems
that must be maintained. For new routes, fiber wins hands down due to
its much lower installation cost.

Finally, fibers do not leak light and are quite difficult to tap. These
properties gives fiber excellent security against potential wiretappers.

On the downside, fiber is a less familiar technology requiring skills
not all engineers have, and fibers can be damaged easily by being bent
too much. Since optical transmission is inherently unidirectional,
two-way communication requires either two fibers or two frequency bands
on one fiber. Finally, fiber interfaces cost more than electrical
interfaces. Nevertheless, the future of all fixed data communication for
distances of more than a few meters is clearly with fiber. For a
discussion of all aspects of fiber optics and their networks, see
(Hecht, 2001).

\section{Wireless transmission}

Our age has given rise to information junkies: people who need to be
on-line all the time. For these mobile users, twisted pair, coax, and
fiber optics are of no use. They need to get their hits of data for
their laptop, notebook, shirt pocket, palmtop, or wristwatch computers
without being tethered to the terrestrial communication infrastructure.
For these users, wireless communication is the answer. In the following
sections, we will look at wireless communication in general, as it has
many other important applications besides providing connectivity to
users who want to surf the Web from the beach.

Some people believe that the future holds only two kinds of
communication: fiber and wireless. All fixed (i.e., nonmobile)
computers, telephones, faxes, and so on will use fiber, and all mobile
ones will use wireless.

Wireless has advantages for even fixed devices in some circumstances.
For example, if running a fiber to a building is difficult due to the
terrain (mountains, jungles, swamps, etc.), wireless may be better. It
is noteworthy that modern wireless digital communication began in the
Hawaiian Islands, where large chunks of Pacific Ocean separated the
users and the telephone system was inadequate.

\subsection{The electromagnetic spectrum}

When electrons move, they create electromagnetic waves that can
propagate through space (even in a vacuum). These waves were predicted
by the British physicist James Clerk Maxwell in 1865 and first observed
by the German physicist Heinrich Hertz in 1887. The number of
oscillations per second of a wave is called its {frequency}, {f}, and is
measured in {Hz} (in honor of Heinrich Hertz). The distance between two
consecutive maxima (or minima) is called the {wavelength}, which is
universally designated by the Greek letter {l} (lambda).

When an antenna of the appropriate size is attached to an electrical
circuit, the electromagnetic waves can be broadcast efficiently and
received by a receiver some distance away. All wireless communication is
based on this principle.

In vacuum, all electromagnetic waves travel at the same speed, no matter
what their frequency. This speed, usually called the {speed of light},
{c}, is approximately 3 x 10\textsuperscript{8} m/sec, or about 1 foot
(30 cm) per nanosecond. (A case could be made for redefining the foot as
the distance light travels in a vacuum in 1 nsec rather than basing it
on the shoe size of some long-dead king.) In copper or fiber the speed
slows to about 2/3 of this value and becomes slightly frequency
dependent. The speed of light is the ultimate speed limit. No object or
signal can ever move faster than it.

The fundamental relation between {f}, {l}, and {c} (in vacuum) is

\textbf{\protect\hypertarget{0130661023_ch02lev1sec3.htmlux5cux23ch02eq02}{}{}
Equation 2}

%\includegraphics{02icon09.gif}

~

Since {c} is a constant, if we know {f}, we can find {l}, and vice
versa. As a rule of thumb, when {l} is in meters and {f} is in MHz,
{l}{f}
%\includegraphics{u2248.gif}
 300. For example, 100-MHz waves are
about 3 meters long, 1000-MHz waves are 0.3-meters long, and 0.1-meter
waves have a frequency of 3000 MHz.

The electromagnetic spectrum is shown in
\protect\hyperlink{0130661023_ch02lev1sec3.htmlux5cux23ch02fig11}{Fig.
2-11}. The radio, microwave, infrared, and visible light portions of the
spectrum can all be used for transmitting information by modulating the
amplitude, frequency, or phase of the waves. Ultraviolet light, X-rays,
and gamma rays would be even better, due to their higher frequencies,
but they are hard to produce and modulate, do not propagate well through
buildings, and are dangerous to living things. The bands listed at the
bottom of
\protect\hyperlink{0130661023_ch02lev1sec3.htmlux5cux23ch02fig11}{Fig.
2-11} are the official ITU names and are based on the wavelengths, so
the LF band goes from 1 km to 10 km (approximately 30 kHz to 300 kHz).
The terms LF, MF, and HF refer to low, medium, and high frequency,
respectively. Clearly, when the names were assigned, nobody expected to
go above 10 MHz, so the higher bands were later named the Very, Ultra,
Super, Extremely, and Tremendously High Frequency bands. Beyond that
there are no names, but Incredibly, Astonishingly, and Prodigiously high
frequency (IHF, AHF, and PHF) would sound nice.

\subparagraph[Figure 2-11. The electromagnetic spectrum and its uses for
communication.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec3.htmlux5cux23ch02fig11}{}{}Figure
2-11. The electromagnetic spectrum and its uses for
communication.}{Figure 2-11. The electromagnetic spectrum and its uses for communication.}}

%\includegraphics{02fig11.gif}

The amount of information that an electromagnetic wave can carry is
related to its bandwidth. With current technology, it is possible to
encode a few bits per Hertz at low frequencies, but often as many as 8
at high frequencies, so a coaxial cable with a 750 MHz bandwidth can
carry several gigabits/sec. From
\protect\hyperlink{0130661023_ch02lev1sec3.htmlux5cux23ch02fig11}{Fig.
2-11} it should now be obvious why networking people like fiber optics
so much.

If we solve
\protect\hyperlink{0130661023_ch02lev1sec3.htmlux5cux23ch02eq02}{Eq.
(2-2)} for {f} and differentiate with respect to {l}, we get

%\includegraphics{02icon10.gif}

~

If we now go to finite differences instead of differentials and only
look at absolute values, we get

\textbf{\protect\hypertarget{0130661023_ch02lev1sec3.htmlux5cux23ch02eq03}{}{}
Equation 2}

%\includegraphics{02icon11.gif}

~

Thus, given the width of a wavelength band, {D}{l}, we can compute the
corresponding frequency band, {D}{f}, and from that the data rate the
band can produce. The wider the band, the higher the data rate. As an
example, consider the 1.30-micron band of
\protect\hyperlink{0130661023_ch02lev1sec2.htmlux5cux23ch02fig06}{Fig.
2-6}. Here we have {l}=1.3 x 10\textsuperscript{-6} and {D}{l} = 0.17 x
10\textsuperscript{-6},so{D}{f} is about 30 THz. At, say, 8 bits/Hz, we
get 240 Tbps.

Most transmissions use a narrow frequency band (i.e., {D}{f/f}
%\includegraphics{u226a.gif}
 1) to get the best reception (many
watts/Hz). However, in some cases, a wide band is used, with two
variations. In {frequency hopping spread spectrum}, the transmitter hops
from frequency to frequency hundreds of times per second. It is popular
for military communication because it makes transmissions hard to detect
and next to impossible to jam. It also offers good resistance to
multipath fading because the direct signal always arrives at the
receiver first. Reflected signals follow a longer path and arrive later.
By then the receiver may have changed frequency and no longer accepts
signals on the previous frequency, thus eliminating interference between
the direct and reflected signals. In recent years, this technique has
also been applied commercially -- both 802.11 and Bluetooth use it, for
example.

As a curious footnote, the technique was co-invented by the
Austrian-born sex goddess Hedy Lamarr, the first woman to appear nude in
a motion picture (the 1933 Czech film {Extase}). Her first husband was
an armaments manufacturer who told her how easy it was to block the
radio signals then used to control torpedos. When she discovered that he
was selling weapons to Hitler, she was horrified, disguised herself as a
maid to escape him, and fled to Hollywood to continue her career as a
movie actress. In her spare time, she invented frequency hopping to help
the Allied war effort. Her scheme used 88 frequencies, the number of
keys (and frequencies) on the piano. For their invention, she and her
friend, the musical composer George Antheil, received U.S. patent
2,292,387. However, they were unable to convince the U.S. Navy that
their invention had any practical use and never received any royalties.
Only years after the patent expired did it become popular.

The other form of spread spectrum, {direct sequence spread spectrum},
which spreads the signal over a wide frequency band, is also gaining
popularity in the commercial world. In particular, some
second-generation mobile phones use it, and it will become dominant with
the third generation, thanks to its good spectral efficiency, noise
immunity, and other properties. Some wireless LANs also use it. We will
come back to spread spectrum later in this chapter. For a fascinating
and detailed history of spread spectrum communication, see (Scholtz,
1982).

For the moment, we will assume that all transmissions use a narrow
frequency band. We will now discuss how the various parts of the
electromagnetic spectrum of
\protect\hyperlink{0130661023_ch02lev1sec3.htmlux5cux23ch02fig11}{Fig.
2-11} are used, starting with radio.

\protect\hypertarget{0130661023_ch02lev1sec3.htmlux5cux23ch02lev2sec9}{}{}

\subsection{Radio Transmission}

Radio waves are easy to generate, can travel long distances, and can
penetrate buildings easily, so they are widely used for communication,
both indoors and outdoors. Radio waves also are omnidirectional, meaning
that they travel in all directions from the source, so the transmitter
and receiver do not have to be carefully aligned physically.

Sometimes omnidirectional radio is good, but sometimes it is bad. In the
1970s, General Motors decided to equip all its new Cadillacs with
computer-controlled antilock brakes. When the driver stepped on the
brake pedal, the computer pulsed the brakes on and off instead of
locking them on hard. One fine day an Ohio Highway Patrolman began using
his new mobile radio to call headquarters, and suddenly the Cadillac
next to him began behaving like a bucking bronco. When the officer
pulled the car over, the driver claimed that he had done nothing and
that the car had gone crazy.

Eventually, a pattern began to emerge: Cadillacs would sometimes go
berserk, but only on major highways in Ohio and then only when the
Highway Patrol was watching. For a long, long time General Motors could
not understand why Cadillacs worked fine in all the other states and
also on minor roads in Ohio. Only after much searching did they discover
that the Cadillac's wiring made a fine antenna for the frequency used by
the Ohio Highway Patrol's new radio system.

The properties of radio waves are frequency dependent. At low
frequencies, radio waves pass through obstacles well, but the power
falls off sharply with distance from the source, roughly as
1{/r}\textsuperscript{2} in air. At high frequencies, radio waves tend
to travel in straight lines and bounce off obstacles. They are also
absorbed by rain. At all frequencies, radio waves are subject to
interference from motors and other electrical equipment.

Due to radio's ability to travel long distances, interference between
users is a problem. For this reason, all governments tightly license the
use of radio transmitters, with one exception, discussed below.

In the VLF, LF, and MF bands, radio waves follow the ground, as
illustrated in
\protect\hyperlink{0130661023_ch02lev1sec3.htmlux5cux23ch02fig12}{Fig.
2-12(a)}. These waves can be detected for perhaps 1000 km at the lower
frequencies, less at the higher ones. AM radio broadcasting uses the MF
band, which is why the ground waves from Boston AM radio stations cannot
be heard easily in New York. Radio waves in these bands pass through
buildings easily, which is why portable radios work indoors. The main
problem with using these bands for data communication is their low
bandwidth {[}see
\protect\hyperlink{0130661023_ch02lev1sec3.htmlux5cux23ch02eq03}{Eq.
(2-3)}{]}.

\subparagraph[Figure 2-12. (a) In the VLF, LF, and MF bands, radio waves
follow the curvature of the earth. (b) In the HF band, they bounce off
the
ionosphere.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec3.htmlux5cux23ch02fig12}{}{}Figure
2-12. (a) In the VLF, LF, and MF bands, radio waves follow the curvature
of the earth. (b) In the HF band, they bounce off the
ionosphere.}{Figure 2-12. (a) In the VLF, LF, and MF bands, radio waves follow the curvature of the earth. (b) In the HF band, they bounce off the ionosphere.}}

%\includegraphics{02fig12.gif}

In the HF and VHF bands, the ground waves tend to be absorbed by the
earth. However, the waves that reach the ionosphere, a layer of charged
particles circling the earth at a height of 100 to 500 km, are refracted
by it and sent back to earth, as shown in
\protect\hyperlink{0130661023_ch02lev1sec3.htmlux5cux23ch02fig12}{Fig.
2-12(b)}. Under certain atmospheric conditions, the signals can bounce
several times. Amateur radio operators (hams) use these bands to talk
long distance. The military also communicate in the HF and VHF bands.

\protect\hypertarget{0130661023_ch02lev1sec3.htmlux5cux23ch02lev2sec10}{}{}

\subsection{Microwave Transmission}

Above 100 MHz, the waves travel in nearly straight lines and can
therefore be narrowly focused. Concentrating all the energy into a small
beam by means of a parabolic antenna (like the familiar satellite TV
dish) gives a much higher signal-to-noise ratio, but the transmitting
and receiving antennas must be accurately aligned with each other. In
addition, this directionality allows multiple transmitters lined up in a
row to communicate with multiple receivers in a row without
interference, provided some minimum spacing rules are observed. Before
fiber optics, for decades these microwaves formed the heart of the
long-distance telephone transmission system. In fact, MCI, one of
AT\&T's first competitors after it was deregulated, built its entire
system with microwave communications going from tower to tower tens of
kilometers apart. Even the company's name reflected this (MCI stood for
Microwave Communications, Inc.). MCI has since gone over to fiber and
merged with WorldCom.

Since the microwaves travel in a straight line, if the towers are too
far apart, the earth will get in the way (think about a San Francisco to
Amsterdam link). Consequently, repeaters are needed periodically. The
higher the towers are, the farther apart they can be. The distance
between repeaters goes up very roughly with the square root of the tower
height. For 100-meter-high towers, repeaters can be spaced 80 km apart.

Unlike radio waves at lower frequencies, microwaves do not pass through
buildings well. In addition, even though the beam may be well focused at
the transmitter, there is still some divergence in space. Some waves may
be refracted off low-lying atmospheric layers and may take slightly
longer to arrive than the direct waves. The delayed waves may arrive out
of phase with the direct wave and thus cancel the signal. This effect is
called {multipath fading} and is often a serious problem. It is weather
and frequency dependent. Some operators keep 10 percent of their
channels idle as spares to switch on when multipath fading wipes out
some frequency band temporarily.

The demand for more and more spectrum drives operators to yet higher
frequencies. Bands up to 10 GHz are now in routine use, but at about 4
GHz a new problem sets in: absorption by water. These waves are only a
few centimeters long and are absorbed by rain. This effect would be fine
if one were planning to build a huge outdoor microwave oven for roasting
passing birds, but for communication, it is a severe problem. As with
multipath fading, the only solution is to shut off links that are being
rained on and route around them.

In summary, microwave communication is so widely used for long-distance
telephone communication, mobile phones, television distribution, and
other uses that a severe shortage of spectrum has developed. It has
several significant advantages over fiber. The main one is that no right
of way is needed, and by buying a small plot of ground every 50 km and
putting a microwave tower on it, one can bypass the telephone system and
communicate directly. This is how MCI managed to get started as a new
long-distance telephone company so quickly. (Sprint went a completely
different route: it was formed by the Southern Pacific Railroad, which
already owned a large amount of right of way and just buried fiber next
to the tracks.)

Microwave is also relatively inexpensive. Putting up two simple towers
(may be just big poles with four guy wires) and putting antennas on each
one may be cheaper than burying 50 km of fiber through a congested urban
area or up over a mountain, and it may also be cheaper than leasing the
telephone company's fiber, especially if the telephone company has not
yet even fully paid for the copper it ripped out when it put in the
fiber.

\protect\hypertarget{0130661023_ch02lev1sec3.htmlux5cux23ch02lev3sec5}{}{}

\subparagraph{The Politics of the Electromagnetic Spectrum}

To prevent total chaos, there are national and international agreements
about who gets to use which frequencies. Since everyone wants a higher
data rate, everyone wants more spectrum. National governments allocate
spectrum for AM and FM radio, television, and mobile phones, as well as
for telephone companies, police, maritime, navigation, military,
government, and many other competing users. Worldwide, an agency of
ITU-R (WARC) tries to coordinate this allocation so devices that work in
multiple countries can be manufactured. However, countries are not bound
by ITU-R's recommendations, and the FCC (Federal Communication
Commission), which does the allocation for the United States, has
occasionally rejected ITU-R's recommendations (usually because they
required some politically-powerful group giving up some piece of the
spectrum).

Even when a piece of spectrum has been allocated to some use, such as
mobile phones, there is the additional issue of which carrier is allowed
to use which frequencies. Three algorithms were widely used in the past.
The oldest algorithm, often called the {beauty contest}, requires each
carrier to explain why its proposal serves the public interest best.
Government officials then decide which of the nice stories they enjoy
most. Having some government official award property worth billions of
dollars to his favorite company often leads to bribery, corruption,
nepotism, and worse. Furthermore, even a scrupulously honest government
official who thought that a foreign company could do a better job than
any of the national companies would have a lot of explaining to do.

This observation led to algorithm 2, holding a lottery among the
interested companies. The problem with that idea is that companies with
no interest in using the spectrum can enter the lottery. If, say, a fast
food restaurant or shoe store chain wins, it can resell the spectrum to
a carrier at a huge profit and with no risk.

Bestowing huge windfalls on alert, but otherwise random, companies has
been severely criticized by many, which led to algorithm 3: auctioning
off the bandwidth to the highest bidder. When England auctioned off the
frequencies needed for third-generation mobile systems in 2000, they
expected to get about \$4 billion. They actually received about \$40
billion because the carriers got into a feeding frenzy, scared to death
of missing the mobile boat. This event switched on nearby governments'
greedy bits and inspired them to hold their own auctions. It worked, but
it also left some of the carriers with so much debt that they are close
to bankruptcy. Even in the best cases, it will take many years to recoup
the licensing fee.

A completely different approach to allocating frequencies is to not
allocate them at all. Just let everyone transmit at will but regulate
the power used so that stations have such a short range they do not
interfere with each other. Accordingly, most governments have set aside
some frequency bands, called the {ISM} ({Industrial, Scientific,
Medical}) bands for unlicensed usage. Garage door openers, cordless
phones, radio-controlled toys, wireless mice, and numerous other
wireless household devices use the ISM bands. To minimize interference
between these uncoordinated devices, the FCC mandates that all devices
in the ISM bands use spread spectrum techniques. Similar rules apply in
other countries

The location of the ISM bands varies somewhat from country to country.
In the United States, for example, devices whose power is under 1 watt
can use the bands shown in
\protect\hyperlink{0130661023_ch02lev1sec3.htmlux5cux23ch02fig13}{Fig.
2-13} without requiring a FCC license. The 900-MHz band works best, but
it is crowded and not available worldwide. The 2.4-GHz band is available
in most countries, but it is subject to interference from microwave
ovens and radar installations. Bluetooth and some of the 802.11 wireless
LANs operate in this band. The 5.7-GHz band is new and relatively
undeveloped, so equipment for it is expensive, but since 802.11a uses
it, it will quickly become more popular.

\subparagraph[Figure 2-13. The ISM bands in the United
States.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec3.htmlux5cux23ch02fig13}{}{}Figure
2-13. The ISM bands in the United
States.}{Figure 2-13. The ISM bands in the United States.}}

%\includegraphics{02fig13.gif}

\protect\hypertarget{0130661023_ch02lev1sec3.htmlux5cux23ch02lev2sec11}{}{}

\subsection{Infrared and Millimeter Waves}

Unguided infrared and millimeter waves are widely used for short-range
communication. The remote controls used on televisions, VCRs, and
stereos all use infrared communication. They are relatively directional,
cheap, and easy to build but have a major drawback: they do not pass
through solid objects (try standing between your remote control and your
television and see if it still works). In general, as we go from
long-wave radio toward visible light, the waves behave more and more
like light and less and less like radio.

On the other hand, the fact that infrared waves do not pass through
solid walls well is also a plus. It means that an infrared system in one
room of a building will not interfere with a similar system in adjacent
rooms or buildings: you cannot control your neighbor's television with
your remote control. Furthermore, security of infrared systems against
eavesdropping is better than that of radio systems precisely for this
reason. Therefore, no government license is needed to operate an
infrared system, in contrast to radio systems, which must be licensed
outside the ISM bands. Infrared communication has a limited use on the
desktop, for example, connecting notebook computers and printers, but it
is not a major player in the communication game.

\protect\hypertarget{0130661023_ch02lev1sec3.htmlux5cux23ch02lev2sec12}{}{}

\subsection{Lightwave Transmission}

Unguided optical signaling has been in use for centuries. Paul Revere
used binary optical signaling from the Old North Church just prior to
his famous ride. A more modern application is to connect the LANs in two
buildings via lasers mounted on their rooftops. Coherent optical
signaling using lasers is inherently unidirectional, so each building
needs its own laser and its own photodetector. This scheme offers very
high bandwidth and very low cost. It is also relatively easy to install
and, unlike microwave, does not require an FCC license.

The laser's strength, a very narrow beam, is also its weakness here.
Aiming a laser beam 1-mm wide at a target the size of a pin head 500
meters away requires the marksmanship of a latter-day Annie Oakley.
Usually, lenses are put into the system to defocus the beam slightly.

A disadvantage is that laser beams cannot penetrate rain or thick fog,
but they normally work well on sunny days. However, the author once
attended a conference at a modern hotel in Europe at which the
conference organizers thoughtfully provided a room full of terminals for
the attendees to read their e-mail during boring presentations. Since
the local PTT was unwilling to install a large number of telephone lines
for just 3 days, the organizers put a laser on the roof and aimed it at
their university's computer science building a few kilometers away. They
tested it the night before the conference and it worked perfectly. At 9
a.m. the next morning, on a bright sunny day, the link failed completely
and stayed down all day. That evening, the organizers tested it again
very carefully, and once again it worked absolutely perfectly. The
pattern repeated itself for two more days consistently.

After the conference, the organizers discovered the problem. Heat from
the sun during the daytime caused convection currents to rise up from
the roof of the building, as shown in
\protect\hyperlink{0130661023_ch02lev1sec3.htmlux5cux23ch02fig14}{Fig.
2-14}. This turbulent air diverted the beam and made it dance around the
detector. Atmospheric ``seeing'' like this makes the stars twinkle
(which is why astronomers put their telescopes on the tops of
mountains -- to get above as much of the atmosphere as possible). It is
also responsible for shimmering roads on a hot day and the wavy images
seen when one looks out above a hot radiator.

\subparagraph[Figure 2-14. Convection currents can interfere with laser
communication systems. A bidirectional system with two lasers is
pictured
here.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec3.htmlux5cux23ch02fig14}{}{}Figure
2-14. Convection currents can interfere with laser communication
systems. A bidirectional system with two lasers is pictured
here.}{Figure 2-14. Convection currents can interfere with laser communication systems. A bidirectional system with two lasers is pictured here.}}

%\includegraphics{02fig14.gif}

\protect\hypertarget{0130661023_ch02lev1sec4.html}{}{}

\protect\hypertarget{0130661023_ch02lev1sec4.htmlux5cux23ch02lev1sec4}{}{}

\section{Communication Satellites}

In the 1950s and early 1960s, people tried to set up communication
systems by bouncing signals off metallized weather balloons.
Unfortunately, the received signals were too weak to be of any practical
use. Then the U.S. Navy noticed a kind of permanent weather balloon in
the sky -- the moon -- and built an operational system for ship-to-shore
communication by bouncing signals off it.

Further progress in the celestial communication field had to wait until
the first communication satellite was launched. The key difference
between an artificial satellite and a real one is that the artificial
one can amplify the signals before sending them back, turning a strange
curiosity into a powerful communication system.

Communication satellites have some interesting properties that make them
attractive for many applications. In its simplest form, a communication
satellite can be thought of as a big microwave repeater in the sky. It
contains several {transponders}, each of which listens to some portion
of the spectrum, amplifies the incoming signal, and then rebroadcasts it
at another frequency to avoid interference with the incoming signal. The
downward beams can be broad, covering a substantial fraction of the
earth's surface, or narrow, covering an area only hundreds of kilometers
in diameter. This mode of operation is known as a {bent pipe}.

According to Kepler's law, the orbital period of a satellite varies as
the radius of the orbit to the 3/2 power. The higher the satellite, the
longer the period. Near the surface of the earth, the period is about 90
minutes. Consequently, low-orbit satellites pass out of view fairly
quickly, so many of them are needed to provide continuous coverage. At
an altitude of about 35,800 km, the period is 24 hours. At an altitude
of 384,000 km, the period is about one month, as anyone who has observed
the moon regularly can testify.

A satellite's period is important, but it is not the only issue in
determining where to place it. Another issue is the presence of the Van
Allen belts, layers of highly charged particles trapped by the earth's
magnetic field. Any satellite flying within them would be destroyed
fairly quickly by the highly-energetic charged particles trapped there
by the earth's magnetic field. These factors lead to three regions in
which satellites can be placed safely. These regions and some of their
properties are illustrated in
\protect\hyperlink{0130661023_ch02lev1sec4.htmlux5cux23ch02fig15}{Fig.
2-15}. Below we will briefly describe the satellites that inhabit each
of these regions.

\subparagraph[Figure 2-15. Communication satellites and some of their
properties, including altitude above the earth, round-trip delay time,
and number of satellites needed for global
coverage.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec4.htmlux5cux23ch02fig15}{}{}Figure
2-15. Communication satellites and some of their properties, including
altitude above the earth, round-trip delay time, and number of
satellites needed for global
coverage.}{Figure 2-15. Communication satellites and some of their properties, including altitude above the earth, round-trip delay time, and number of satellites needed for global coverage.}}

%\includegraphics{02fig15.gif}

\protect\hypertarget{0130661023_ch02lev1sec4.htmlux5cux23ch02lev2sec13}{}{}

\subsection{Geostationary Satellites}

In 1945, the science fiction writer Arthur C. Clarke calculated that a
satellite at an altitude of 35,800 km in a circular equatorial orbit
would appear to remain motionless in the sky. so it would not need to be
tracked (Clarke, 1945). He went on to describe a complete communication
system that used these (manned) {geostationary satellites}, including
the orbits, solar panels, radio frequencies, and launch procedures.
Unfortunately, he concluded that satellites were impractical due to the
impossibility of putting power-hungry, fragile, vacuum tube amplifiers
into orbit, so he never pursued this idea further, although he wrote
some science fiction stories about it.

The invention of the transistor changed all that, and the first
artificial communication satellite, Telstar, was launched in July 1962.
Since then, communication satellites have become a multibillion dollar
business and the only aspect of outer space that has become highly
profitable. These high-flying satellites are often called {GEO}
({Geostationary Earth Orbit}) satellites.

With current technology, it is unwise to have geostationary satellites
spaced much closer than 2 degrees in the 360-degree equatorial plane, to
avoid interference. With a spacing of 2 degrees, there can only be 360/2
= 180 of these satellites in the sky at once. However, each transponder
can use multiple frequencies and polarizations to increase the available
bandwidth.

To prevent total chaos in the sky, orbit slot allocation is done by ITU.
This process is highly political, with countries barely out of the stone
age demanding ``their'' orbit slots (for the purpose of leasing them to
the highest bidder). Other countries, however, maintain that national
property rights do not extend up to the moon and that no country has a
legal right to the orbit slots above its territory. To add to the fight,
commercial telecommunication is not the only application. Television
broadcasters, governments, and the military also want a piece of the
orbiting pie.

Modern satellites can be quite large, weighing up to 4000 kg and
consuming several kilowatts of electric power produced by the solar
panels. The effects of solar, lunar, and planetary gravity tend to move
them away from their assigned orbit slots and orientations, an effect
countered by on-board rocket motors. This fine-tuning activity is called
{station keeping}. However, when the fuel for the motors has been
exhausted, typically in about 10 years, the satellite drifts and tumbles
helplessly, so it has to be turned off. Eventually, the orbit decays and
the satellite reenters the atmosphere and burns up or occasionally
crashes to earth.

Orbit slots are not the only bone of contention. Frequencies are, too,
because the downlink transmissions interfere with existing microwave
users. Consequently, ITU has allocated certain frequency bands to
satellite users. The main ones are listed in
\protect\hyperlink{0130661023_ch02lev1sec4.htmlux5cux23ch02fig16}{Fig.
2-16}. The C band was the first to be designated for commercial
satellite traffic. Two frequency ranges are assigned in it, the lower
one for downlink traffic (from the satellite) and the upper one for
uplink traffic (to the satellite). To allow traffic to go both ways at
the same time, two channels are required, one going each way. These
bands are already overcrowded because they are also used by the common
carriers for terrestrial microwave links. The L and S bands were added
by international agreement in 2000. However, they are narrow and
crowded.

\subparagraph[Figure 2-16. The principal satellite
bands.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec4.htmlux5cux23ch02fig16}{}{}Figure
2-16. The principal satellite
bands.}{Figure 2-16. The principal satellite bands.}}

%\includegraphics{02fig16.gif}

The next highest band available to commercial telecommunication carriers
is the Ku (K under) band. This band is not (yet) congested, and at these
frequencies, satellites can be spaced as close as 1 degree. However,
another problem exists: rain. Water is an excellent absorber of these
short microwaves. Fortunately, heavy storms are usually localized, so
using several widely separated ground stations instead of just one
circumvents the problem but at the price of extra antennas, extra
cables, and extra electronics to enable rapid switching between
stations. Bandwidth has also been allocated in the Ka (K above) band for
commercial satellite traffic, but the equipment needed to use it is
still expensive. In addition to these commercial bands, many government
and military bands also exist.

A modern satellite has around 40 transponders, each with an 80-MHz
bandwidth. Usually, each transponder operates as a bent pipe, but recent
satellites have some on-board processing capacity, allowing more
sophisticated operation. In the earliest satellites, the division of the
transponders into channels was static: the bandwidth was simply split up
into fixed frequency bands. Nowadays, each transponder beam is divided
into time slots, with various users taking turns. We will study these
two techniques (frequency division multiplexing and time division
multiplexing) in detail later in this chapter.

The first geostationary satellites had a single spatial beam that
illuminated about 1/3 of the earth's surface, called its {footprint}.
With the enormous decline in the price, size, and power requirements of
microelectronics, a much more sophisticated broadcasting strategy has
become possible. Each satellite is equipped with multiple antennas and
multiple transponders. Each downward beam can be focused on a small
geographical area, so multiple upward and downward transmissions can
take place simultaneously. Typically, these so-called {spot beams} are
elliptically shaped, and can be as small as a few hundred km in
diameter. A communication satellite for the United States typically has
one wide beam for the contiguous 48 states, plus spot beams for Alaska
and Hawaii.

A new development in the communication satellite world is the
development of low-cost microstations, sometimes called {VSATs} ({Very
Small Aperture Terminals}) (Abramson, 2000). These tiny terminals have
1-meter or smaller antennas (versus 10 m for a standard GEO antenna) and
can put out about 1 watt of power. The uplink is generally good for 19.2
kbps, but the downlink is more often 512 kbps or more. Direct broadcast
satellite television uses this technology for one-way transmission.

In many VSAT systems, the microstations do not have enough power to
communicate directly with one another (via the satellite, of course).
Instead, a special ground station, the {hub}, with a large, high-gain
antenna is needed to relay traffic between VSATs, as shown in
\protect\hyperlink{0130661023_ch02lev1sec4.htmlux5cux23ch02fig17}{Fig.
2-17}. In this mode of operation, either the sender or the receiver has
a large antenna and a powerful amplifier. The trade-off is a longer
delay in return for having cheaper end-user stations.

\subparagraph[Figure 2-17. VSATs using a
hub.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec4.htmlux5cux23ch02fig17}{}{}Figure
2-17. VSATs using a hub.}{Figure 2-17. VSATs using a hub.}}

%\includegraphics{02fig17.gif}

VSATs have great potential in rural areas. It is not widely appreciated,
but over half the world's population lives over an hour's walk from the
nearest telephone. Stringing telephone wires to thousands of small
villages is far beyond the budgets of most Third World governments, but
installing 1-meter VSAT dishes powered by solar cells is often feasible.
VSATs provide the technology that will wire the world.

Communication satellites have several properties that are radically
different from terrestrial point-to-point links. To begin with, even
though signals to and from a satellite travel at the speed of light
(nearly 300,000 km/sec), the long round-trip distance introduces a
substantial delay for GEO satellites. Depending on the distance between
the user and the ground station, and the elevation of the satellite
above the horizon, the end-to-end transit time is between 250 and 300
msec. A typical value is 270 msec (540 msec for a VSAT system with a
hub).

For comparison purposes, terrestrial microwave links have a propagation
delay of roughly 3 sec/km, and coaxial cable or fiber optic links have
a delay of approximately 5 sec/km. The latter is slower than the former
because electromagnetic signals travel faster in air than in solid
materials.

Another important property of satellites is that they are inherently
broadcast media. It does not cost more to send a message to thousands of
stations within a transponder's footprint than it does to send to one.
For some applications, this property is very useful. For example, one
could imagine a satellite broadcasting popular Web pages to the caches
of a large number of computers spread over a wide area. Even when
broadcasting can be simulated with point-to-point lines, satellite
broadcasting may be much cheaper. On the other hand, from a security and
privacy point of view, satellites are a complete disaster: everybody can
hear everything. Encryption is essential when security is required.

Satellites also have the property that the cost of transmitting a
message is independent of the distance traversed. A call across the
ocean costs no more to service than a call across the street. Satellites
also have excellent error rates and can be deployed almost instantly, a
major consideration for military communication.

\protect\hypertarget{0130661023_ch02lev1sec4.htmlux5cux23ch02lev2sec14}{}{}

\subsection{Medium-Earth Orbit Satellites}

At much lower altitudes, between the two Van Allen belts, we find the
{MEO} ({Medium-Earth Orbit}) satellites. As viewed from the earth, these
drift slowly in longitude, taking something like 6 hours to circle the
earth. Accordingly, they must be tracked as they move through the sky.
Because they are lower than the GEOs, they have a smaller footprint on
the ground and require less powerful transmitters to reach them.
Currently they are not used for telecommunications, so we will not
examine them further here. The 24 {GPS} ({Global Positioning System})
satellites orbiting at about 18,000 km are examples of MEO satellites.

\protect\hypertarget{0130661023_ch02lev1sec4.htmlux5cux23ch02lev2sec15}{}{}

\subsection{Low-Earth Orbit Satellites}

Moving down in altitude, we come to the {LEO} ({Low-Earth Orbit})
satellites. Due to their rapid motion, large numbers of them are needed
for a complete system. On the other hand, because the satellites are so
close to the earth, the ground stations do not need much power, and the
round-trip delay is only a few milliseconds. In this section we will
examine three examples, two aimed at voice communication and one aimed
at Internet service.

\protect\hypertarget{0130661023_ch02lev1sec4.htmlux5cux23ch02lev3sec6}{}{}

\subparagraph{Iridium}

As mentioned above, for the first 30 years of the satellite era,
low-orbit satellites were rarely used because they zip into and out of
view so quickly. In 1990, Motorola broke new ground by filing an
application with the FCC asking for permission to launch 77 low-orbit
satellites for the Iridium project (element 77 is iridium). The plan was
later revised to use only 66 satellites, so the project should have been
renamed Dysprosium (element 66), but that probably sounded too much like
a disease. The idea was that as soon as one satellite went out of view,
another would replace it. This proposal set off a feeding frenzy among
other communication companies. All of a sudden, everyone wanted to
launch a chain of low-orbit satellites.

After seven years of cobbling together partners and financing, the
partners launched the Iridium satellites in 1997. Communication service
began in November 1998. Unfortunately, the commercial demand for large,
heavy satellite telephones was negligible because the mobile phone
network had grown spectacularly since 1990. As a consequence, Iridium
was not profitable and was forced into bankruptcy in August 1999 in one
of the most spectacular corporate fiascos in history. The satellites and
other assets (worth \$5 billion) were subsequently purchased by an
investor for \$25 million at a kind of extraterrestrial garage sale. The
Iridium service was restarted in March 2001.

Iridium's business was (and is) providing worldwide telecommunication
service using hand-held devices that communicate directly with the
Iridium satellites. It provides voice, data, paging, fax, and navigation
service everywhere on land, sea, and air. Customers include the
maritime, aviation, and oil exploration industries, as well as people
traveling in parts of the world lacking a telecommunications
infrastructure (e.g., deserts, mountains, jungles, and some Third World
countries).

The Iridium satellites are positioned at an altitude of 750 km, in
circular polar orbits. They are arranged in north-south necklaces, with
one satellite every 32 degrees of latitude. With six satellite
necklaces, the entire earth is covered, as suggested by
\protect\hyperlink{0130661023_ch02lev1sec4.htmlux5cux23ch02fig18}{Fig.
2-18(a)}. People not knowing much about chemistry can think of this
arrangement as a very, very big dysprosium atom, with the earth as the
nucleus and the satellites as the electrons.

\subparagraph[Figure 2-18. (a) The Iridium satellites form six necklaces
around the earth. (b) 1628 moving cells cover the
earth.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec4.htmlux5cux23ch02fig18}{}{}Figure
2-18. (a) The Iridium satellites form six necklaces around the earth.
(b) 1628 moving cells cover the
earth.}{Figure 2-18. (a) The Iridium satellites form six necklaces around the earth. (b) 1628 moving cells cover the earth.}}

%\includegraphics{02fig18.jpg}

Each satellite has a maximum of 48 cells (spot beams), with a total of
1628 cells over the surface of the earth, as shown in
\protect\hyperlink{0130661023_ch02lev1sec4.htmlux5cux23ch02fig18}{Fig.
2-18(b)}. Each satellite has a capacity of 3840 channels, or 253,440 in
all. Some of these are used for paging and navigation, while others are
used for data and voice.

An interesting property of Iridium is that communication between distant
customers takes place in space, with one satellite relaying data to the
next one, as illustrated in
\protect\hyperlink{0130661023_ch02lev1sec4.htmlux5cux23ch02fig19}{Fig.
2-19(a)}. Here we see a caller at the North Pole contacting a satellite
directly overhead. The call is relayed via other satellites and finally
sent down to the callee at the South Pole.

\subparagraph[Figure 2-19. (a) Relaying in space. (b) Relaying on the
ground.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec4.htmlux5cux23ch02fig19}{}{}Figure
2-19. (a) Relaying in space. (b) Relaying on the
ground.}{Figure 2-19. (a) Relaying in space. (b) Relaying on the ground.}}

%\includegraphics{02fig19.gif}

\protect\hypertarget{0130661023_ch02lev1sec4.htmlux5cux23ch02lev3sec7}{}{}

\subparagraph{Globalstar}

An alternative design to Iridium is Globalstar. It is based on 48 LEO
satellites but uses a different switching scheme than that of Iridium.
Whereas Iridium relays calls from satellite to satellite, which requires
sophisticated switching equipment in the satellites, Globalstar uses a
traditional bent-pipe design. The call originating at the North Pole in
\protect\hyperlink{0130661023_ch02lev1sec4.htmlux5cux23ch02fig19}{Fig.
2-19(b)} is sent back to earth and picked up by the large ground station
at Santa's Workshop. The call is then routed via a terrestrial network
to the ground station nearest the callee and delivered by a bent-pipe
connection as shown. The advantage of this scheme is that it puts much
of the complexity on the ground, where it is easier to manage. Also, the
use of large ground station antennas that can put out a powerful signal
and receive a weak one means that lower-powered telephones can be used.
After all, the telephone puts out only a few milliwatts of power, so the
signal that gets back to the ground station is fairly weak, even after
having been amplified by the satellite.

\protect\hypertarget{0130661023_ch02lev1sec4.htmlux5cux23ch02lev3sec8}{}{}

\subparagraph{Teledesic}

Iridium is targeted at telephone users located in odd places. Our next
example, {Teledesic}, is targeted at bandwidth-hungry Internet users all
over the world. It was conceived in 1990 by mobile phone pioneer Craig
McCaw and Microsoft founder Bill Gates, who was unhappy with the snail's
pace at which the world's telephone companies were providing high
bandwidth to computer users. The goal of the Teledesic system is to
provide millions of concurrent Internet users with an uplink of as much
as 100 Mbps and a downlink of up to 720 Mbps using a small, fixed,
VSAT-type antenna, completely bypassing the telephone system. To
telephone companies, this is pie-in-the-sky.

The original design was for a system consisting of 288 small-footprint
satellites arranged in 12 planes just below the lower Van Allen belt at
an altitude of 1350 km. This was later changed to 30 satellites with
larger footprints. Transmission occurs in the relatively uncrowded and
high-bandwidth Ka band. The system is packet-switched in space, with
each satellite capable of routing packets to its neighboring satellites.
When a user needs bandwidth to send packets, it is requested and
assigned dynamically in about 50 msec. The system is scheduled to go
live in 2005 if all goes as planned.

\protect\hypertarget{0130661023_ch02lev1sec4.htmlux5cux23ch02lev2sec16}{}{}

\subsection{Satellites versus Fiber}

A comparison between satellite communication and terrestrial
communication is instructive. As recently as 20 years ago, a case could
be made that the future of communication lay with communication
satellites. After all, the telephone system had changed little in the
past 100 years and showed no signs of changing in the next 100 years.
This glacial movement was caused in no small part by the regulatory
environment in which the telephone companies were expected to provide
good voice service at reasonable prices (which they did), and in return
got a guaranteed profit on their investment. For people with data to
transmit, 1200-bps modems were available. That was pretty much all there
was.

The introduction of competition in 1984 in the United States and
somewhat later in Europe changed all that radically. Telephone companies
began replacing their long-haul networks with fiber and introduced
high-bandwidth services like ADSL (Asymmetric Digital Subscriber Line).
They also stopped their long-time practice of charging artificially-high
prices to long-distance users to subsidize local service.

All of a sudden, terrestrial fiber connections looked like the long-term
winner. Nevertheless, communication satellites have some major niche
markets that fiber does not (and, sometimes, cannot) address. We will
now look at a few of these.

First, while a single fiber has, in principle, more potential bandwidth
than all the satellites ever launched, this bandwidth is not available
to most users. The fibers that are now being installed are used within
the telephone system to handle many long distance calls at once, not to
provide individual users with high bandwidth. With satellites, it is
practical for a user to erect an antenna on the roof of the building and
completely bypass the telephone system to get high bandwidth. Teledesic
is based on this idea.

A second niche is for mobile communication. Many people nowadays want to
communicate while jogging, driving, sailing, and flying. Terrestrial
fiber optic links are of no use to them, but satellite links potentially
are. It is possible, however, that a combination of cellular radio and
fiber will do an adequate job for most users (but probably not for those
airborne or at sea).

A third niche is for situations in which broadcasting is essential. A
message sent by satellite can be received by thousands of ground
stations at once. For example, an organization transmitting a stream of
stock, bond, or commodity prices to thousands of dealers might find a
satellite system to be much cheaper than simulating broadcasting on the
ground.

A fourth niche is for communication in places with hostile terrain or a
poorly developed terrestrial infrastructure. Indonesia, for example, has
its own satellite for domestic telephone traffic. Launching one
satellite was cheaper than stringing thousands of undersea cables among
the 13,677 islands in the archipelago.

A fifth niche market for satellites is to cover areas where obtaining
the right of way for laying fiber is difficult or unduly expensive.

Sixth, when rapid deployment is critical, as in military communication
systems in time of war, satellites win easily.

In short, it looks like the mainstream communication of the future will
be terrestrial fiber optics combined with cellular radio, but for some
specialized uses, satellites are better. However, there is one caveat
that applies to all of this: economics. Although fiber offers more
bandwidth, it is certainly possible that terrestrial and satellite
communication will compete aggressively on price. If advances in
technology radically reduce the cost of deploying a satellite (e.g.,
some future space shuttle can toss out dozens of satellites on one
launch) or low-orbit satellites catch on in a big way, it is not certain
that fiber will win in all markets.

\protect\hypertarget{0130661023_ch02lev1sec5.html}{}{}

\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02lev1sec5}{}{}

\section{The Public Switched Telephone Network}

When two computers owned by the same company or organization and located
close to each other need to communicate, it is often easiest just to run
a cable between them. LANs work this way. However, when the distances
are large or there are many computers or the cables have to pass through
a public road or other public right of way, the costs of running private
cables are usually prohibitive. Furthermore, in just about every country
in the world, stringing private transmission lines across (or
underneath) public property is also illegal. Consequently, the network
designers must rely on the existing telecommunication facilities.

These facilities, especially the {PSTN} ({Public Switched Telephone
Network}), were usually designed many years ago, with a completely
different goal in mind: transmitting the human voice in a more-or-less
recognizable form. Their suitability for use in computer-computer
communication is often marginal at best, but the situation is rapidly
changing with the introduction of fiber optics and digital technology.
In any event, the telephone system is so tightly intertwined with (wide
area) computer networks, that it is worth devoting some time to studying
it.

To see the order of magnitude of the problem, let us make a rough but
illustrative comparison of the properties of a typical computer-computer
connection via a local cable and via a dial-up telephone line. A cable
running between two computers can transfer data at 10\textsuperscript{9}
bps, maybe more. In contrast, a dial-up line has a maximum data rate of
56 kbps, a difference of a factor of almost 20,000. That is the
difference between a duck waddling leisurely through the grass and a
rocket to the moon. If the dial-up line is replaced by an ADSL
connection, there is still a factor of 1000--2000 difference.

The trouble, of course, is that computer systems designers are used to
working with computer systems and when suddenly confronted with another
system whose performance (from their point of view) is 3 or 4 orders of
magnitude worse, they, not surprising, devoted much time and effort to
trying to figure out how to use it efficiently. In the following
sections we will describe the telephone system and show how it works.
For additional information about the innards of the telephone system see
(Bellamy, 2000).

\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02lev2sec17}{}{}

\subsection{Structure of the Telephone System}

Soon after Alexander Graham Bell patented the telephone in 1876 (just a
few hours ahead of his rival, Elisha Gray), there was an enormous demand
for his new invention. The initial market was for the sale of
telephones, which came in pairs. It was up to the customer to string a
single wire between them. The electrons returned through the earth. If a
telephone owner wanted to talk to {n} other telephone owners, separate
wires had to be strung to all {n} houses. Within a year, the cities were
covered with wires passing over houses and trees in a wild jumble. It
became immediately obvious that the model of connecting every telephone
to every other telephone, as shown in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig20}{Fig.
2-20(a)}, was not going to work.

\subparagraph[Figure 2-20. (a) Fully-interconnected network. (b)
Centralized switch. (c) Two-level
hierarchy.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02fig20}{}{}Figure
2-20. (a) Fully-interconnected network. (b) Centralized switch. (c)
Two-level
hierarchy.}{Figure 2-20. (a) Fully-interconnected network. (b) Centralized switch. (c) Two-level hierarchy.}}

%\includegraphics{02fig20.gif}

To his credit, Bell saw this and formed the Bell Telephone Company,
which opened its first switching office (in New Haven, Connecticut) in
1878. The company ran a wire to each customer's house or office. To make
a call, the customer would crank the phone to make a ringing sound in
the telephone company office to attract the attention of an operator,
who would then manually connect the caller to the callee by using a
jumper cable. The model of a single switching office is illustrated in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig20}{Fig.
2-20(b)}.

Pretty soon, Bell System switching offices were springing up everywhere
and people wanted to make long-distance calls between cities, so the
Bell system began to connect the switching offices. The original problem
soon returned: to connect every switching office to every other
switching office by means of a wire between them quickly became
unmanageable, so second-level switching offices were invented. After a
while, multiple second-level offices were needed, as illustrated in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig20}{Fig.
2-20(c)}. Eventually, the hierarchy grew to five levels.

By 1890, the three major parts of the telephone system were in place:
the switching offices, the wires between the customers and the switching
offices (by now balanced, insulated, twisted pairs instead of open wires
with an earth return), and the long-distance connections between the
switching offices. While there have been improvements in all three areas
since then, the basic Bell System model has remained essentially intact
for over 100 years. For a short technical history of the telephone
system, see (Hawley, 1991).

Prior to the 1984 breakup of AT\&T, the telephone system was organized
as a highly-redundant, multilevel hierarchy. The following description
is highly simplified but gives the essential flavor nevertheless. Each
telephone has two copper wires coming out of it that go directly to the
telephone company's nearest {end office} (also called a {local central
office}). The distance is typically 1 to 10 km, being shorter in cities
than in rural areas. In the United States alone there are about 22,000
end offices. The two-wire connections between each subscriber's
telephone and the end office are known in the trade as the {local loop}.
If the world's local loops were stretched out end to end, they would
extend to the moon and back 1000 times.

At one time, 80 percent of AT\&T's capital value was the copper in the
local loops. AT\&T was then, in effect, the world's largest copper mine.
Fortunately, this fact was not widely known in the investment community.
Had it been known, some corporate raider might have bought AT\&T,
terminated all telephone service in the United States, ripped out all
the wire, and sold the wire to a copper refiner to get a quick payback.

If a subscriber attached to a given end office calls another subscriber
attached to the same end office, the switching mechanism within the
office sets up a direct electrical connection between the two local
loops. This connection remains intact for the duration of the call.

If the called telephone is attached to another end office, a different
procedure has to be used. Each end office has a number of outgoing lines
to one or more nearby switching centers, called {toll offices} (or if
they are within the same local area, {tandem offices}). These lines are
called {toll connecting trunks}. If both the caller's and callee's end
offices happen to have a toll connecting trunk to the same toll office
(a likely occurrence if they are relatively close by), the connection
may be established within the toll office. A telephone network
consisting only of telephones (the small dots), end offices (the large
dots), and toll offices (the squares) is shown in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig20}{Fig.
2-20(c)}.

If the caller and callee do not have a toll office in common, the path
will have to be established somewhere higher up in the hierarchy.
Primary, sectional, and regional offices form a network by which the
toll offices are connected. The toll, primary, sectional, and regional
exchanges communicate with each other via high-bandwidth {intertoll
trunks} (also called {interoffice trunks}). The number of different
kinds of switching centers and their topology (e.g., can two sectional
offices have a direct connection or must they go through a regional
office?) varies from country to country depending on the country's
telephone density.
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig21}{Figure
2-21} shows how a medium-distance connection might be routed.

\subparagraph[Figure 2-21. A typical circuit route for a medium-distance
call.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02fig21}{}{}Figure
2-21. A typical circuit route for a medium-distance
call.}{Figure 2-21. A typical circuit route for a medium-distance call.}}

%\includegraphics{02fig21.gif}

A variety of transmission media are used for telecommunication. Local
loops consist of category 3 twisted pairs nowadays, although in the
early days of telephony, uninsulated wires spaced 25 cm apart on
telephone poles were common. Between switching offices, coaxial cables,
microwaves, and especially fiber optics are widely used.

In the past, transmission throughout the telephone system was analog,
with the actual voice signal being transmitted as an electrical voltage
from source to destination. With the advent of fiber optics, digital
electronics, and computers, all the trunks and switches are now digital,
leaving the local loop as the last piece of analog technology in the
system. Digital transmission is preferred because it is not necessary to
accurately reproduce an analog waveform after it has passed through many
amplifiers on a long call. Being able to correctly distinguish a 0 from
a 1 is enough. This property makes digital transmission more reliable
than analog. It is also cheaper and easier to maintain.

In summary, the telephone system consists of three major components:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  {}

  Local loops (analog twisted pairs going into houses and businesses).
\end{enumerate}

Trunks (digital fiber optics connecting the switching offices).

Switching offices (where calls are moved from one trunk to another).

After a short digression on the politics of telephones, we will come
back to each of these three components in some detail. The local loops
provide everyone access to the whole system, so they are critical.
Unfortunately, they are also the weakest link in the system. For the
long-haul trunks, the main issue is how to collect multiple calls
together and send them out over the same fiber. This subject is called
multiplexing, and we will study three different ways to do it. Finally,
there are two fundamentally different ways of doing switching; we will
look at both.

\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02lev2sec18}{}{}

\subsection{The Politics of Telephones}

For decades prior to 1984, the Bell System provided both local and long
distance service throughout most of the United States. In the 1970s, the
U.S. Federal Government came to believe that this was an illegal
monopoly and sued to break it up. The government won, and on January 1,
1984, AT\&T was broken up into AT\&T Long Lines, 23 {BOC}s ({Bell
Operating Companies}), and a few other pieces. The 23 BOCs were grouped
into seven regional BOCs (RBOCs) to make them economically viable. The
entire nature of telecommunication in the United States was changed
overnight by court order ({not} by an act of Congress).

The exact details of the divestiture were described in the so-called
{MFJ} ({Modified Final Judgment}, an oxymoron if ever there was one -- if
the judgment could be modified, it clearly was not final). This event
led to increased competition, better service, and lower long distance
prices to consumers and businesses. However, prices for local service
rose as the cross subsidies from long-distance calling were eliminated
and local service had to become self supporting. Many other countries
have now introduced competition along similar lines.

To make it clear who could do what, the United States was divided up
into 164 {LATA}s ({Local Access and Transport Areas}). Very roughly, a
LATA is about as big as the area covered by one area code. Within a
LATA, there was one {LEC} ({Local Exchange Carrier}) that had a monopoly
on traditional telephone service within its area. The most important
LECs were the BOCs, although some LATAs contained one or more of the
1500 independent telephone companies operating as LECs.

All inter-LATA traffic was handled by a different kind of company, an
{IXC} ({IntereXchange Carrier}). Originally, AT\&T Long Lines was the
only serious IXC, but now WorldCom and Sprint are well-established
competitors in the IXC business. One of the concerns at the breakup was
to ensure that all the IXCs would be treated equally in terms of line
quality, tariffs, and the number of digits their customers would have to
dial to use them. The way this is handled is illustrated in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig22}{Fig.
2-22}. Here we see three example LATAs, each with several end offices.
LATAs 2 and 3 also have a small hierarchy with tandem offices
(intra-LATA toll offices).

\subparagraph[Figure 2-22. The relationship of LATAs, LECs, and IXCs.
All the circles are LEC switching offices. Each hexagon belongs to the
IXC whose number is in
it.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02fig22}{}{}Figure
2-22. The relationship of LATAs, LECs, and IXCs. All the circles are LEC
switching offices. Each hexagon belongs to the IXC whose number is in
it.}{Figure 2-22. The relationship of LATAs, LECs, and IXCs. All the circles are LEC switching offices. Each hexagon belongs to the IXC whose number is in it.}}

%\includegraphics{02fig22.gif}

Any IXC that wishes to handle calls originating in a LATA can build a
switching office called a {POP} ({Point of Presence}) there. The LEC is
required to connect each IXC to every end office, either directly, as in
LATAs 1 and 3, or indirectly, as in LATA 2. Furthermore, the terms of
the connection, both technical and financial, must be identical for all
IXCs. In this way, a subscriber in, say, LATA 1, can choose which IXC to
use for calling subscribers in LATA 3.

As part of the MFJ, the IXCs were forbidden to offer local telephone
service and the LECs were forbidden to offer inter-LATA telephone
service, although both were free to enter any other business, such as
operating fried chicken restaurants. In 1984, that was a fairly
unambiguous statement. Unfortunately, technology has a funny way of
making the law obsolete. Neither cable television nor mobile phones were
covered by the agreement. As cable television went from one way to two
way and mobile phones exploded in popularity, both LECs and IXCs began
buying up or merging with cable and mobile operators.

By 1995, Congress saw that trying to maintain a distinction between the
various kinds of companies was no longer tenable and drafted a bill to
allow cable TV companies, local telephone companies, long-distance
carriers, and mobile operators to enter one another's businesses. The
idea was that any company could then offer its customers a single
integrated package containing cable TV, telephone, and information
services and that different companies would compete on service and
price. The bill was enacted into law in February 1996. As a result, some
BOCs became IXCs and some other companies, such as cable television
operators, began offering local telephone service in competition with
the LECs.

One interesting property of the 1996 law is the requirement that LECs
implement local number portability. This means that a customer can
change local telephone companies without having to get a new telephone
number. This provision removes a huge hurdle for many people and makes
them much more inclined to switch LECs, thus increasing competition. As
a result, the U.S. telecommunications landscape is currently undergoing
a radical restructuring. Again, many other countries are starting to
follow suit. Often other countries wait to see how this kind of
experiment works out in the U.S. If it works well, they do the same
thing; if it works badly, they try something else.

\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02lev2sec19}{}{}

\subsection{The Local Loop: Modems, ADSL, and Wireless}

It is now time to start our detailed study of how the telephone system
works. The main parts of the system are illustrated in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig23}{Fig.
2-23}. Here we see the local loops, the trunks, and the toll offices and
end offices, both of which contain switching equipment that switches
calls. An end office has up to 10,000 local loops (in the U.S. and other
large countries). In fact, until recently, the area code + exchange
indicated the end office, so (212) 601-xxxx was a specific end office
with 10,000 subscribers, numbered 0000 through 9999. With the advent of
competition for local service, this system was no longer tenable because
multiple companies wanted to own the end office code. Also, the number
of codes was basically used up, so complex mapping schemes had to be
introduced.

\subparagraph[Figure 2-23. The use of both analog and digital
transmission for a computer to computer call. Conversion is done by the
modems and
codecs.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02fig23}{}{}Figure
2-23. The use of both analog and digital transmission for a computer to
computer call. Conversion is done by the modems and
codecs.}{Figure 2-23. The use of both analog and digital transmission for a computer to computer call. Conversion is done by the modems and codecs.}}

%\includegraphics{02fig23.gif}

Let us begin with the part that most people are familiar with: the
two-wire local loop coming from a telephone company end office into
houses and small businesses. The local loop is also frequently referred
to as the ``last mile,'' although the length can be up to several miles.
It has used analog signaling for over 100 years and is likely to
continue doing so for some years to come, due to the high cost of
converting to digital. Nevertheless, even in this last bastion of analog
transmission, change is taking place. In this section we will study the
traditional local loop and the new developments taking place here, with
particular emphasis on data communication from home computers.

When a computer wishes to send digital data over an analog dial-up line,
the data must first be converted to analog form for transmission over
the local loop. This conversion is done by a device called a modem,
something we will study shortly. At the telephone company end office the
data are converted to digital form for transmission over the long-haul
trunks.

If the other end is a computer with a modem, the reverse
conversion -- digital to analog -- is needed to traverse the local loop at
the destination. This arrangement is shown in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig23}{Fig.
2-23} for ISP 1 (Internet Service Provider), which has a bank of modems,
each connected to a different local loop. This ISP can handle as many
connections as it has modems (assuming its server or servers have enough
computing power). This arrangement was the normal one until 56-kbps
modems appeared, for reasons that will become apparent shortly.

Analog signaling consists of varying a voltage with time to represent an
information stream. If transmission media were perfect, the receiver
would receive exactly the same signal that the transmitter sent.
Unfortunately, media are not perfect, so the received signal is not the
same as the transmitted signal. For digital data, this difference can
lead to errors.

Transmission lines suffer from three major problems: attenuation, delay
distortion, and noise. {Attenuation} is the loss of energy as the signal
propagates outward. The loss is expressed in decibels per kilometer. The
amount of energy lost depends on the frequency. To see the effect of
this frequency dependence, imagine a signal not as a simple waveform,
but as a series of Fourier components. Each component is attenuated by a
different amount, which results in a different Fourier spectrum at the
receiver.

To make things worse, the different Fourier components also propagate at
different speeds in the wire. This speed difference leads to
{distortion} of the signal received at the other end.

Another problem is {noise}, which is unwanted energy from sources other
than the transmitter. Thermal noise is caused by the random motion of
the electrons in a wire and is unavoidable. Crosstalk is caused by
inductive coupling between two wires that are close to each other.
Sometimes when talking on the telephone, you can hear another
conversation in the background. That is crosstalk. Finally, there is
impulse noise, caused by spikes on the power line or other causes. For
digital data, impulse noise can wipe out one or more bits.

\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02lev3sec9}{}{}

\subparagraph{Modems}

Due to the problems just discussed, especially the fact that both
attenuation and propagation speed are frequency dependent, it is
undesirable to have a wide range of frequencies in the signal.
Unfortunately, the square waves used in digital signals have a wide
frequency spectrum and thus are subject to strong attenuation and delay
distortion. These effects make baseband (DC) signaling unsuitable except
at slow speeds and over short distances.

To get around the problems associated with DC signaling, especially on
telephone lines, AC signaling is used. A continuous tone in the 1000 to
2000-Hz range, called a {sine wave carrier}, is introduced. Its
amplitude, frequency, or phase can be modulated to transmit information.
In {amplitude modulation}, two different amplitudes are used to
represent 0 and 1, respectively. In {frequency modulation}, also known
as {frequency shift keying}, two (or more) different tones are used.
(The term {keying} is also widely used in the industry as a synonym for
modulation.) In the simplest form of {phase modulation}, the carrier
wave is systematically shifted 0 or 180 degrees at uniformly spaced
intervals. A better scheme is to use shifts of 45, 135, 225, or 315
degrees to transmit 2 bits of information per time interval. Also,
always requiring a phase shift at the end of every time interval, makes
it is easier for the receiver to recognize the boundaries of the time
intervals.

\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig24}{Figure
2-24} illustrates the three forms of modulation. In
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig24}{Fig.
2-24(a)} one of the amplitudes is nonzero and one is zero. In
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig24}{Fig.
2-24(b)} two frequencies are used. In
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig24}{Fig.
2-24(c)} a phase shift is either present or absent at each bit boundary.
A device that accepts a serial stream of bits as input and produces a
carrier modulated by one (or more) of these methods (or vice versa) is
called a {modem} (for modulator-demodulator). The modem is inserted
between the (digital) computer and the (analog) telephone system.

\subparagraph[Figure 2-24. (a) A binary signal. (b) Amplitude
modulation. (c) Frequency modulation. (d) Phase
modulation.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02fig24}{}{}Figure
2-24. (a) A binary signal. (b) Amplitude modulation. (c) Frequency
modulation. (d) Phase
modulation.}{Figure 2-24. (a) A binary signal. (b) Amplitude modulation. (c) Frequency modulation. (d) Phase modulation.}}

%\includegraphics{02fig24.gif}

To go to higher and higher speeds, it is not possible to just keep
increasing the sampling rate. The Nyquist theorem says that even with a
perfect 3000-Hz line (which a dial-up telephone is decidedly not), there
is no point in sampling faster than 6000 Hz. In practice, most modems
sample 2400 times/sec and focus on getting more bits per sample.

The number of samples per second is measured in {baud}. During each
baud, one {symbol} is sent. Thus, an {n}-baud line transmits {n}
symbols/sec. For example, a 2400-baud line sends one symbol about every
416.667 sec. If the symbol consists of 0 volts for a logical 0 and 1
volt for a logical 1, the bit rate is 2400 bps. If, however, the
voltages 0, 1, 2, and 3 volts are used, every symbol consists of 2 bits,
so a 2400-baud line can transmit 2400 symbols/sec at a data rate of 4800
bps. Similarly, with four possible phase shifts, there are also 2
bits/symbol, so again here the bit rate is twice the baud rate. The
latter technique is widely used and called {QPSK} ({Quadrature Phase
Shift Keying}).

The concepts of bandwidth, baud, symbol, and bit rate are commonly
confused, so let us restate them here. The bandwidth of a medium is the
range of frequencies that pass through it with minimum attenuation. It
is a physical property of the medium (usually from 0 to some maximum
frequency) and measured in Hz. The baud rate is the number of
samples/sec made. Each sample sends one piece of information, that is,
one symbol. The baud rate and symbol rate are thus the same. The
modulation technique (e.g., QPSK) determines the number of bits/symbol.
The bit rate is the amount of information sent over the channel and is
equal to the number of symbols/sec times the number of bits/symbol.

All advanced modems use a combination of modulation techniques to
transmit multiple bits per baud. Often multiple amplitudes and multiple
phase shifts are combined to transmit several bits/symbol. In
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig25}{Fig.
2-25(a)}, we see dots at 45, 135, 225, and 315 degrees with constant
amplitude (distance from the origin). The phase of a dot is indicated by
the angle a line from it to the origin makes with the positive x-axis.
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig25}{Fig.
2-25(a)} has four valid combinations and can be used to transmit 2 bits
per symbol. It is QPSK.

\subparagraph[Figure 2-25. (a) QPSK. (b) QAM-16. (c)
QAM-64.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02fig25}{}{}Figure
2-25. (a) QPSK. (b) QAM-16. (c)
QAM-64.}{Figure 2-25. (a) QPSK. (b) QAM-16. (c) QAM-64.}}

%\includegraphics{02fig25.gif}

In
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig25}{Fig.
2-25(b)} we see a different modulation scheme, in which four amplitudes
and four phases are used, for a total of 16 different combinations. This
modulation scheme can be used to transmit 4 bits per symbol. It is
called {QAM-16} ({Quadrature Amplitude Modulation}). Sometimes the term
{16-QAM} is used instead. QAM-16 can be used, for example, to transmit
9600 bps over a 2400-baud line.

\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig25}{Figure
2-25(c)} is yet another modulation scheme involving amplitude and phase.
It allows 64 different combinations, so 6 bits can be transmitted per
symbol. It is called {QAM-64}. Higher-order QAMs also are used.

Diagrams such as those of
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig25}{Fig.
2-25}, which show the legal combinations of amplitude and phase, are
called {constellation diagrams}. Each high-speed modem standard has its
own constellation pattern and can talk only to other modems that use the
same one (although most modems can emulate all the slower ones).

With many points in the constellation pattern, even a small amount of
noise in the detected amplitude or phase can result in an error and,
potentially, many bad bits. To reduce the chance of an error, standards
for the higher speeds modems do error correction by adding extra bits to
each sample. The schemes are known as {TCM} ({Trellis Coded
Modulation}). Thus, for example, the V.32 modem standard uses 32
constellation points to transmit 4 data bits and 1 parity bit per symbol
at 2400 baud to achieve 9600 bps with error correction. Its
constellation pattern is shown in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig26}{Fig.
2-26(a)}. The decision to ``rotate'' around the origin by 45 degrees was
done for engineering reasons; the rotated and unrotated constellations
have the same information capacity.

\subparagraph[Figure 2-26. (a) V.32 for 9600 bps. (b) V32 bis for 14,400
bps.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02fig26}{}{}Figure
2-26. (a) V.32 for 9600 bps. (b) V32 bis for 14,400
bps.}{Figure 2-26. (a) V.32 for 9600 bps. (b) V32 bis for 14,400 bps.}}

%\includegraphics{02fig26.gif}

The next step above 9600 bps is 14,400 bps. It is called {V.32 bis}.
This speed is achieved by transmitting 6 data bits and 1 parity bit per
sample at 2400 baud. Its constellation pattern has 128 points when
QAM-128 is used and is shown in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig26}{Fig.
2-26(b)}. Fax modems use this speed to transmit pages that have been
scanned in as bit maps. QAM-256 is not used in any standard telephone
modems, but it is used on cable networks, as we shall see.

The next telephone modem after V.32 bis is {V.34}, which runs at 28,800
bps at 2400 baud with 12 data bits/symbol. The final modem in this
series is {V.34 bis} which uses 14 data bits/symbol at 2400 baud to
achieve 33,600 bps.

To increase the effective data rate further, many modems compress the
data before transmitting it, to get an effective data rate higher than
33,600 bps. On the other hand, nearly all modems test the line before
starting to transmit user data, and if they find the quality lacking,
cut back to a speed lower than the rated maximum. Thus, the {effective}
modem speed observed by the user can be lower, equal to, or higher than
the official rating.

All modern modems allow traffic in both directions at the same time (by
using different frequencies for different directions). A connection that
allows traffic in both directions simultaneously is called {full
duplex}. A two-lane road is full duplex. A connection that allows
traffic either way, but only one way at a time is called {half duplex}.
A single railroad track is half duplex. A connection that allows traffic
only one way is called {simplex}. A one-way street is simplex. Another
example of a simplex connection is an optical fiber with a laser on one
end and a light detector on the other end.

The reason that standard modems stop at 33,600 is that the Shannon limit
for the telephone system is about 35 kbps, so going faster than this
would violate the laws of physics (department of thermodynamics). To
find out whether 56-kbps modems are theoretically possible, stay tuned.

But why is the theoretical limit 35 kbps? It has to do with the average
length of the local loops and the quality of these lines. The 35 kbps is
determined by the average length of the local loops. In
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig23}{Fig.
2-23}, a call originating at the computer on the left and terminating at
ISP 1 goes over two local loops as an analog signal, once at the source
and once at the destination. Each of these adds noise to the signal. If
we could get rid of one of these local loops, the maximum rate would be
doubled.

ISP 2 does precisely that. It has a pure digital feed from the nearest
end office. The digital signal used on the trunks is fed directly to ISP
2, eliminating the codecs, modems, and analog transmission on its end.
Thus, when one end of the connection is purely digital, as it is with
most ISPs now, the maximum data rate can be as high as 70 kbps. Between
two home users with modems and analog lines, the maximum is 33.6 kbps.

The reason that 56 kbps modems are in use has to do with the Nyquist
theorem. The telephone channel is about 4000 Hz wide (including the
guard bands). The maximum number of independent samples per second is
thus 8000. The number of bits per sample in the U.S. is 8, one of which
is used for control purposes, allowing 56,000 bit/sec of user data. In
Europe, all 8 bits are available to users, so 64,000-bit/sec modems
could have been used, but to get international agreement on a standard,
56,000 was chosen.

This modem standard is called {V.90}. It provides for a 33.6-kbps
upstream channel (user to ISP), but a 56 kbps downstream channel (ISP to
user) because there is usually more data transport from the ISP to the
user than the other way (e.g., requesting a Web page takes only a few
bytes, but the actual page could be megabytes). In theory, an upstream
channel wider than 33.6 kbps would have been possible, but since many
local loops are too noisy for even 33.6 kbps, it was decided to allocate
more of the bandwidth to the downstream channel to increase the chances
of it actually working at 56 kbps.

The next step beyond V.90 is {V.92}. These modems are capable of 48 kbps
on the upstream channel if the line can handle it. They also determine
the appropriate speed to use in about half of the usual 30 seconds
required by older modems. Finally, they allow an incoming telephone call
to interrupt an Internet session, provided that the line has call
waiting service.

\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02lev3sec10}{}{}

\subparagraph{Digital Subscriber Lines}

When the telephone industry finally got to 56 kbps, it patted itself on
the back for a job well done. Meanwhile, the cable TV industry was
offering speeds up to 10 Mbps on shared cables, and satellite companies
were planning to offer upward of 50 Mbps. As Internet access became an
increasingly important part of their business, the telephone companies
(LECs) began to realize they needed a more competitive product. Their
answer was to start offering new digital services over the local loop.
Services with more bandwidth than standard telephone service are
sometimes called {broadband}, although the term really is more of a
marketing concept than a specific technical concept.

Initially, there were many overlapping offerings, all under the general
name of {xDSL} ({Digital Subscriber Line}), for various {x}. Below we
will discuss these but primarily focus on what is probably going to
become the most popular of these services, {ADSL} ({Asymmetric DSL}).
Since ADSL is still being developed and not all the standards are fully
in place, some of the details given below may change in time, but the
basic picture should remain valid. For more information about ADSL, see
(Summers, 1999; and Vetter et al., 2000).

The reason that modems are so slow is that telephones were invented for
carrying the human voice and the entire system has been carefully
optimized for this purpose. Data have always been stepchildren. At the
point where each local loop terminates in the end office, the wire runs
through a filter that attenuates all frequencies below 300 Hz and above
3400 Hz. The cutoff is not sharp -- 300 Hz and 3400 Hz are the 3 dB
points -- so the bandwidth is usually quoted as 4000 Hz even though the
distance between the 3 dB points is 3100 Hz. Data are thus also
restricted to this narrow band.

The trick that makes xDSL work is that when a customer subscribes to it,
the incoming line is connected to a different kind of switch, one that
does not have this filter, thus making the entire capacity of the local
loop available. The limiting factor then becomes the physics of the
local loop, not the artificial 3100 Hz bandwidth created by the filter.

Unfortunately, the capacity of the local loop depends on several
factors, including its length, thickness, and general quality. A plot of
the potential bandwidth as a function of distance is given in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig27}{Fig.
2-27}. This figure assumes that all the other factors are optimal (new
wires, modest bundles, etc.).

\subparagraph[Figure 2-27. Bandwidth versus distance over category 3 UTP
for
DSL.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02fig27}{}{}Figure
2-27. Bandwidth versus distance over category 3 UTP for
DSL.}{Figure 2-27. Bandwidth versus distance over category 3 UTP for DSL.}}

%\includegraphics{02fig27.gif}

The implication of this figure creates a problem for the telephone
company. When it picks a speed to offer, it is simultaneously picking a
radius from its end offices beyond which the service cannot be offered.
This means that when distant customers try to sign up for the service,
they may be told ``Thanks a lot for your interest, but you live 100
meters too far from the nearest end office to get the service. Could you
please move?'' The lower the chosen speed, the larger the radius and the
more customers covered. But the lower the speed, the less attractive the
service and the fewer the people who will be willing to pay for it. This
is where business meets technology. (One potential solution is building
mini end offices out in the neighborhoods, but that is an expensive
proposition.)

The xDSL services have all been designed with certain goals in mind.
First, the services must work over the existing category 3 twisted pair
local loops. Second, they must not affect customers' existing telephones
and fax machines. Third, they must be much faster than 56 kbps. Fourth,
they should be always on, with just a monthly charge but no per-minute
charge.

The initial ADSL offering was from AT\&T and worked by dividing the
spectrum available on the local loop, which is about 1.1 MHz, into three
frequency bands: {POTS} ({Plain Old Telephone Service}) upstream (user
to end office) and downstream (end office to user). The technique of
having multiple frequency bands is called frequency division
multiplexing; we will study it in detail in a later section. Subsequent
offerings from other providers have taken a different approach, and it
appears this one is likely to win out, so we will describe it below.

The alternative approach, called {DMT} ({Discrete MultiTone}), is
illustrated in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig28}{Fig.
2-28}. In effect, what it does is divide the available 1.1 MHz spectrum
on the local loop into 256 independent channels of 4312.5 Hz each.
Channel 0 is used for POTS. Channels 1--5 are not used, to keep the
voice signal and data signals from interfering with each other. Of the
remaining 250 channels, one is used for upstream control and one is used
for downstream control. The rest are available for user data.

\subparagraph[Figure 2-28. Operation of ADSL using discrete multitone
modulation.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02fig28}{}{}Figure
2-28. Operation of ADSL using discrete multitone
modulation.}{Figure 2-28. Operation of ADSL using discrete multitone modulation.}}

%\includegraphics{02fig28.gif}

In principle, each of the remaining channels can be used for a
full-duplex data stream, but harmonics, crosstalk, and other effects
keep practical systems well below the theoretical limit. It is up to the
provider to determine how many channels are used for upstream and how
many for downstream. A 50--50 mix of upstream and downstream is
technically possible, but most providers allocate something like
80\%--90\% of the bandwidth to the downstream channel since most users
download more data than they upload. This choice gives rise to the ``A''
in ADSL. A common split is 32 channels for upstream and the rest
downstream. It is also possible to have a few of the highest upstream
channels be bidirectional for increased bandwidth, although making this
optimization requires adding a special circuit to cancel echoes.

The ADSL standard (ANSI T1.413 and ITU G.992.1) allows speeds of as much
as 8 Mbps downstream and 1 Mbps upstream. However, few providers offer
this speed. Typically, providers offer 512 kbps downstream and 64 kbps
upstream (standard service) and 1 Mbps downstream and 256 kbps upstream
(premium service).

Within each channel, a modulation scheme similar to V.34 is used,
although the sampling rate is 4000 baud instead of 2400 baud. The line
quality in each channel is constantly monitored and the data rate
adjusted continuously as needed, so different channels may have
different data rates. The actual data are sent with QAM modulation, with
up to 15 bits per baud, using a constellation diagram analogous to that
of
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig25}{Fig.
2-25(b)}. With, for example, 224 downstream channels and 15 bits/baud at
4000 baud, the downstream bandwidth is 13.44 Mbps. In practice, the
signal-to-noise ratio is never good enough to achieve this rate, but 8
Mbps is possible on short runs over high-quality loops, which is why the
standard goes up this far.

A typical ADSL arrangement is shown in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig29}{Fig.
2-29}. In this scheme, a telephone company technician must install a
{NID} ({Network Interface Device}) on the customer's premises. This
small plastic box marks the end of the telephone company's property and
the start of the customer's property. Close to the NID (or sometimes
combined with it) is a {splitter}, an analog filter that separates the
0-4000 Hz band used by POTS from the data. The POTS signal is routed to
the existing telephone or fax machine, and the data signal is routed to
an ADSL modem. The ADSL modem is actually a digital signal processor
that has been set up to act as 250 QAM modems operating in parallel at
different frequencies. Since most current ADSL modems are external, the
computer must be connected to it at high speed. Usually, this is done by
putting an Ethernet card in the computer and operating a very short
two-node Ethernet containing only the computer and ADSL modem.
Occasionally the USB port is used instead of Ethernet. In the future,
internal ADSL modem cards will no doubt become available.

\subparagraph[Figure 2-29. A typical ADSL equipment
configuration.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02fig29}{}{}Figure
2-29. A typical ADSL equipment
configuration.}{Figure 2-29. A typical ADSL equipment configuration.}}

%\includegraphics{02fig29.gif}

At the other end of the wire, on the end office side, a corresponding
splitter is installed. Here the voice portion of the signal is filtered
out and sent to the normal voice switch. The signal above 26 kHz is
routed to a new kind of device called a {DSLAM} ({Digital Subscriber
Line Access Multiplexer}), which contains the same kind of digital
signal processor as the ADSL modem. Once the digital signal has been
recovered into a bit stream, packets are formed and sent off to the ISP.

This complete separation between the voice system and ADSL makes it
relatively easy for a telephone company to deploy ADSL. All that is
needed is buying a DSLAM and splitter and attaching the ADSL subscribers
to the splitter. Other high-bandwidth services (e.g., ISDN) require much
greater changes to the existing switching equipment.

One disadvantage of the design of
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig29}{Fig.
2-29} is the presence of the NID and splitter on the customer premises.
Installing these can only be done by a telephone company technician,
necessitating an expensive ``truck roll'' (i.e., sending a technician to
the customer's premises). Therefore, an alternative splitterless design
has also been standardized. It is informally called G.lite but the ITU
standard number is G.992.2. It is the same as
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig29}{Fig.
2-29} but without the splitter. The existing telephone line is used as
is. The only difference is that a microfilter has to be inserted into
each telephone jack between the telephone or ADSL modem and the wire.
The microfilter for the telephone is a low-pass filter eliminating
frequencies above 3400 Hz; the microfilter for the ADSL modem is a
high-pass filter eliminating frequencies below 26 kHz. However this
system is not as reliable as having a splitter, so G.lite can be used
only up to 1.5 Mbps (versus 8 Mbps for ADSL with a splitter). G.lite
still requires a splitter in the end office, however, but that
installation does not require thousands of truck rolls.

ADSL is just a physical layer standard. What runs on top of it depends
on the carrier. Often the choice is ATM due to ATM's ability to manage
quality of service and the fact that many telephone companies run ATM in
the core network.

\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02lev3sec11}{}{}

\subparagraph{Wireless Local Loops}

Since 1996 in the U.S. and a bit later in other countries, companies
that wish to compete with the entrenched local telephone company (the
former monopolist), called an {ILEC} ({Incumbent LEC}), are free to do
so. The most likely candidates are long-distance telephone companies
(IXCs). Any IXC wishing to get into the local phone business in some
city must do the following things. First, it must buy or lease a
building for its first end office in that city. Second, it must fill the
end office with telephone switches and other equipment, all of which are
available as off-the-shelf products from various vendors. Third, it must
run a fiber between the end office and its nearest toll office so the
new local customers will have access to its national network. Fourth, it
must acquire customers, typically by advertising better service or lower
prices than those of the ILEC.

Then the hard part begins. Suppose that some customers actually show up.
How is the new local phone company, called a {CLEC} ({Competitive LEC})
going to connect customer telephones and computers to its shiny new end
office? Buying the necessary rights of way and stringing wires or fibers
is prohibitively expensive. Many CLECs have discovered a cheaper
alternative to the traditional twisted-pair local loop: the {WLL}
({Wireless Local Loop}).

In a certain sense, a fixed telephone using a wireless local loop is a
bit like a mobile phone, but there are three crucial technical
differences. First, the wireless local loop customer often wants
high-speed Internet connectivity, often at speeds at least equal to
ADSL. Second, the new customer probably does not mind having a CLEC
technician install a large directional antenna on his roof pointed at
the CLEC's end office. Third, the user does not move, eliminating all
the problems with mobility and cell handoff that we will study later in
this chapter. And thus a new industry is born: {fixed wireless} (local
telephone and Internet service run by CLECs over wireless local loops).

Although WLLs began serious operation in 1998, we first have to go back
to 1969 to see the origin. In that year the FCC allocated two television
channels (at 6 MHz each) for instructional television at 2.1 GHz. In
subsequent years, 31 more channels were added at 2.5 GHz for a total of
198 MHz.

Instructional television never took off and in 1998, the FCC took the
frequencies back and allocated them to two-way radio. They were
immediately seized upon for wireless local loops. At these frequencies,
the microwaves are 10--12 cm long. They have a range of about 50 km and
can penetrate vegetation and rain moderately well. The 198 MHz of new
spectrum was immediately put to use for wireless local loops as a
service called {MMDS} ({Multichannel Multipoint Distribution Service}).
MMDS can be regarded as a MAN (Metropolitan Area Network), as can its
cousin LMDS (discussed below).

The big advantage of this service is that the technology is well
established and the equipment is readily available. The disadvantage is
that the total bandwidth available is modest and must be shared by many
users over a fairly large geographic area.

The low bandwidth of MMDS led to interest in millimeter waves as an
alternative. At frequencies of 28--31 GHz in the U.S. and 40 GHz in
Europe, no frequencies were allocated because it is difficult to build
silicon integrated circuits that operate so fast. That problem was
solved with the invention of gallium arsenide integrated circuits,
opening up millimeter bands for radio communication. The FCC responded
to the demand by allocating 1.3 GHz to a new wireless local loop service
called {LMDS} ({Local Multipoint Distribution Service}). This allocation
is the single largest chunk of bandwidth ever allocated by the FCC for
any one use. A similar chunk is being allocated in Europe, but at 40
GHz.

The operation of LMDS is shown in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig30}{Fig.
2-30}. Here a tower is shown with multiple antennas on it, each pointing
in a different direction. Since millimeter waves are highly directional,
each antenna defines a sector, independent of the other ones. At this
frequency, the range is 2--5 km, which means that many towers are needed
to cover a city.

\subparagraph[Figure 2-30. Architecture of an LMDS
system.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02fig30}{}{}Figure
2-30. Architecture of an LMDS
system.}{Figure 2-30. Architecture of an LMDS system.}}

%\includegraphics{02fig30.gif}

Like ADSL, LMDS uses an asymmetric bandwidth allocation favoring the
downstream channel. With current technology, each sector can have 36
Gbps downstream and 1 Mbps upstream, shared among all the users in that
sector. If each active user downloads three 5-KB pages per minute, the
user is occupying an average of 2000 bps of spectrum, which allows a
maximum of 18,000 active users per sector. To keep the delay reasonable,
no more than 9000 active users should be supported, though. With four
sectors, as shown in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig30}{Fig.
2-30}, an active user population of 36,000 could be supported. Assuming
that one in three customers is on line during peak periods, a single
tower with four antennas could serve 100,000 people within a 5-km radius
of the tower. These calculations have been done by many potential CLECs,
some of whom have concluded that for a modest investment in
millimeter-wave towers, they can get into the local telephone and
Internet business and offer users data rates comparable to cable TV and
at a lower price.

LMDS has a few problems, however. For one thing, millimeter waves
propagate in straight lines, so there must be a clear line of sight
between the roof top antennas and the tower. For another, leaves absorb
these waves well, so the tower must be high enough to avoid having trees
in the line of sight. And what may have looked like a clear line of
sight in December may not be clear in July when the trees are full of
leaves. Rain also absorbs these waves. To some extent, errors introduced
by rain can be compensated for with error correcting codes or turning up
the power when it is raining. Nevertheless, LMDS service is more likely
to be rolled out first in dry climates, say, in Arizona rather than in
Seattle.

Wireless local loops are not likely to catch on unless there are
standards, to encourage equipment vendors to produce products and to
ensure that customers can change CLECs without having to buy new
equipment. To provide this standardization, IEEE set up a committee
called 802.16 to draw up a standard for LMDS. The 802.16 standard was
published in April 2002. IEEE calls 802.16 a {wireless MAN}.

IEEE 802.16 was designed for digital telephony, Internet access,
connection of two remote LANs, television and radio broadcasting, and
other uses. We will look at it in more detail in
\protect\hyperlink{0130661023_ch04.htmlux5cux23ch04}{Chap. 4}.

\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02lev2sec20}{}{}

\subsection{Trunks and Multiplexing}

Economies of scale play an important role in the telephone system. It
costs essentially the same amount of money to install and maintain a
high-bandwidth trunk as a low-bandwidth trunk between two switching
offices (i.e., the costs come from having to dig the trench and not from
the copper wire or optical fiber). Consequently, telephone companies
have developed elaborate schemes for multiplexing many conversations
over a single physical trunk. These multiplexing schemes can be divided
into two basic categories: {FDM} ({Frequency Division Multiplexing}) and
{TDM} ({Time Division Multiplexing}). In FDM, the frequency spectrum is
divided into frequency bands, with each user having exclusive possession
of some band. In TDM, the users take turns (in a round-robin fashion),
each one periodically getting the entire bandwidth for a little burst of
time.

AM radio broadcasting provides illustrations of both kinds of
multiplexing. The allocated spectrum is about 1 MHz, roughly 500 to 1500
kHz. Different frequencies are allocated to different logical channels
(stations), each operating in a portion of the spectrum, with the
interchannel separation great enough to prevent interference. This
system is an example of frequency division multiplexing. In addition (in
some countries), the individual stations have two logical subchannels:
music and advertising. These two alternate in time on the same
frequency, first a burst of music, then a burst of advertising, then
more music, and so on. This situation is time division multiplexing.

Below we will examine frequency division multiplexing. After that we
will see how FDM can be applied to fiber optics (wavelength division
multiplexing). Then we will turn to TDM, and end with an advanced TDM
system used for fiber optics (SONET).

\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02lev3sec12}{}{}

\subparagraph{Frequency Division Multiplexing}

\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig31}{Figure
2-31} shows how three voice-grade telephone channels are multiplexed
using FDM. Filters limit the usable bandwidth to about 3100 Hz per
voice-grade channel. When many channels are multiplexed together, 4000
Hz is allocated to each channel to keep them well separated. First the
voice channels are raised in frequency, each by a different amount. Then
they can be combined because no two channels now occupy the same portion
of the spectrum. Notice that even though there are gaps (guard bands)
between the channels, there is some overlap between adjacent channels
because the filters do not have sharp edges. This overlap means that a
strong spike at the edge of one channel will be felt in the adjacent one
as nonthermal noise.

\subparagraph[Figure 2-31. Frequency division multiplexing. (a) The
original bandwidths. (b) The bandwidths raised in frequency. (c) The
multiplexed
channel.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02fig31}{}{}Figure
2-31. Frequency division multiplexing. (a) The original bandwidths. (b)
The bandwidths raised in frequency. (c) The multiplexed
channel.}{Figure 2-31. Frequency division multiplexing. (a) The original bandwidths. (b) The bandwidths raised in frequency. (c) The multiplexed channel.}}

%\includegraphics{02fig31.gif}

The FDM schemes used around the world are to some degree standardized. A
widespread standard is twelve 4000-Hz voice channels multiplexed into
the 60 to 108 kHz band. This unit is called a {group.} The 12-kHz to
60-kHz band is sometimes used for another group. Many carriers offer a
48- to 56-kbps leased line service to customers, based on the group.
Five groups (60 voice channels) can be multiplexed to form a
{supergroup}. The next unit is the {mastergroup}, which is five
supergroups (CCITT standard) or ten supergroups (Bell system). Other
standards of up to 230,000 voice channels also exist.

\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02lev3sec13}{}{}

\subparagraph{Wavelength Division Multiplexing}

For fiber optic channels, a variation of frequency division multiplexing
is used. It is called {WDM} ({Wavelength Division Multiplexing}). The
basic principle of WDM on fibers is depicted in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig32}{Fig.
2-32}. Here four fibers come together at an optical combiner, each with
its energy present at a different wavelength. The four beams are
combined onto a single shared fiber for transmission to a distant
destination. At the far end, the beam is split up over as many fibers as
there were on the input side. Each output fiber contains a short,
specially-constructed core that filters out all but one wavelength. The
resulting signals can be routed to their destination or recombined in
different ways for additional multiplexed transport.

\subparagraph[Figure 2-32. Wavelength division
multiplexing.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02fig32}{}{}Figure
2-32. Wavelength division
multiplexing.}{Figure 2-32. Wavelength division multiplexing.}}

%\includegraphics{02fig32.gif}

There is really nothing new here. This is just frequency division
multiplexing at very high frequencies. As long as each channel has its
own frequency (i.e., wavelength) range and all the ranges are disjoint,
they can be multiplexed together on the long-haul fiber. The only
difference with electrical FDM is that an optical system using a
diffraction grating is completely passive and thus highly reliable.

WDM technology has been progressing at a rate that puts computer
technology to shame. WDM was invented around 1990. The first commercial
systems had eight channels of 2.5 Gbps per channel. By 1998, systems
with 40 channels of 2.5 Gbps were on the market. By 2001, there were
products with 96 channels of 10 Gbps, for a total of 960 Gbps. This is
enough bandwidth to transmit 30 full-length movies per second (in
MPEG-2). Systems with 200 channels are already working in the
laboratory. When the number of channels is very large and the
wavelengths are spaced close together, for example, 0.1 nm, the system
is often referred to as {DWDM} ({Dense WDM}).

It should be noted that the reason WDM is popular is that the energy on
a single fiber is typically only a few gigahertz wide because it is
currently impossible to convert between electrical and optical media any
faster. By running many channels in parallel on different wavelengths,
the aggregate bandwidth is increased linearly with the number of
channels. Since the bandwidth of a single fiber band is about 25,000 GHz
(see
\protect\hyperlink{0130661023_ch02lev1sec2.htmlux5cux23ch02fig06}{Fig.
2-6}), there is theoretically room for 2500 10-Gbps channels even at 1
bit/Hz (and higher rates are also possible).

Another new development is all optical amplifiers. Previously, every 100
km it was necessary to split up all the channels and convert each one to
an electrical signal for amplification separately before reconverting to
optical and combining them. Nowadays, all optical amplifiers can
regenerate the entire signal once every 1000 km without the need for
multiple opto-electrical conversions.

In the example of
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig32}{Fig.
2-32}, we have a fixed wavelength system. Bits from input fiber 1 go to
output fiber 3, bits from input fiber 2 go to output fiber 1, etc.
However, it is also possible to build WDM systems that are switched. In
such a device, the output filters are tunable using Fabry-Perot or
Mach-Zehnder interferometers. For more information about WDM and its
application to Internet packet switching, see (Elmirghani and Mouftah,
2000; Hunter and Andonovic, 2000; and Listani et al., 2001).

\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02lev3sec14}{}{}

\subparagraph{Time Division Multiplexing}

WDM technology is wonderful, but there is still a lot of copper wire in
the telephone system, so let us turn back to it for a while. Although
FDM is still used over copper wires or microwave channels, it requires
analog circuitry and is not amenable to being done by a computer. In
contrast, TDM can be handled entirely by digital electronics, so it has
become far more widespread in recent years. Unfortunately, it can only
be used for digital data. Since the local loops produce analog signals,
a conversion is needed from analog to digital in the end office, where
all the individual local loops come together to be combined onto
outgoing trunks.

We will now look at how multiple analog voice signals are digitized and
combined onto a single outgoing digital trunk. Computer data sent over a
modem are also analog, so the following description also applies to
them. The analog signals are digitized in the end office by a device
called a {codec} (coder-decoder), producing a series of 8-bit numbers.
The codec makes 8000 samples per second (125 sec/sample) because the
Nyquist theorem says that this is sufficient to capture all the
information from the 4-kHz telephone channel bandwidth. At a lower
sampling rate, information would be lost; at a higher one, no extra
information would be gained. This technique is called {PCM} ({Pulse Code
Modulation}). PCM forms the heart of the modern telephone system. As a
consequence, virtually all time intervals within the telephone system
are multiples of 125 sec.

When digital transmission began emerging as a feasible technology, CCITT
was unable to reach agreement on an international standard for PCM.
Consequently, a variety of incompatible schemes are now in use in
different countries around the world.

The method used in North America and Japan is the {T1} carrier, depicted
in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig33}{Fig.
2-33}. (Technically speaking, the format is called DS1 and the carrier
is called T1, but following widespread industry tradition, we will not
make that subtle distinction here.) The T1 carrier consists of 24 voice
channels multiplexed together. Usually, the analog signals are sampled
on a round-robin basis with the resulting analog stream being fed to the
codec rather than having 24 separate codecs and then merging the digital
output. Each of the 24 channels, in turn, gets to insert 8 bits into the
output stream. Seven bits are data and one is for control, yielding 7 x
8000 = 56,000 bps of data, and 1 x 8000 = 8000 bps of signaling
information per channel.

\subparagraph[Figure 2-33. The T1 carrier (1.544
Mbps).]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02fig33}{}{}Figure
2-33. The T1 carrier (1.544
Mbps).}{Figure 2-33. The T1 carrier (1.544 Mbps).}}

%\includegraphics{02fig33.gif}

A frame consists of 24 x 8 = 192 bits plus one extra bit for framing,
yielding 193 bits every 125 sec{.} This gives a gross data rate of
1.544 Mbps. The 193rd bit is used for frame synchronization. It takes on
the pattern 0101010101 . . . . Normally, the receiver keeps checking
this bit to make sure that it has not lost synchronization. If it does
get out of sync, the receiver can scan for this pattern to get
resynchronized. Analog customers cannot generate the bit pattern at all
because it corresponds to a sine wave at 4000 Hz, which would be
filtered out. Digital customers can, of course, generate this pattern,
but the odds are against its being present when the frame slips. When a
T1 system is being used entirely for data, only 23 of the channels are
used for data. The 24th one is used for a special synchronization
pattern, to allow faster recovery in the event that the frame slips.

When CCITT finally did reach agreement, they felt that 8000 bps of
signaling information was far too much, so its 1.544-Mbps standard is
based on an 8- rather than a 7-bit data item; that is, the analog signal
is quantized into 256 rather than 128 discrete levels. Two
(incompatible) variations are provided. In {common-channel signaling},
the extra bit (which is attached onto the rear rather than the front of
the 193-bit frame) takes on the values 10101010 . . . in the odd frames
and contains signaling information for all the channels in the even
frames.

In the other variation, {channel-associated signaling}, each channel has
its own private signaling subchannel. A private subchannel is arranged
by allocating one of the eight user bits in every sixth frame for
signaling purposes, so five out of six samples are 8 bits wide, and the
other one is only 7 bits wide. CCITT also recommended a PCM carrier at
2.048 Mbps called {E1}. This carrier has 32 8-bit data samples packed
into the basic 125{-}sec frame. Thirty of the channels are used for
information and two are used for signaling. Each group of four frames
provides 64 signaling bits, half of which are used for
channel-associated signaling and half of which are used for frame
synchronization or are reserved for each country to use as it wishes.
Outside North America and Japan, the 2.048-Mbps E1 carrier is used
instead of T1.

Once the voice signal has been digitized, it is tempting to try to use
statistical techniques to reduce the number of bits needed per channel.
These techniques are appropriate not only for encoding speech, but for
the digitization of any analog signal. All of the compaction methods are
based on the principle that the signal changes relatively slowly
compared to the sampling frequency, so that much of the information in
the 7- or 8-bit digital level is redundant.

One method, called {differential pulse code modulation}, consists of
outputting not the digitized amplitude, but the difference between the
current value and the previous one. Since jumps of 16 or more on a
scale of 128 are unlikely, 5 bits should suffice instead of 7. If the
signal does occasionally jump wildly, the encoding logic may require
several sampling periods to ``catch up.'' For speech, the error
introduced can be ignored.

A variation of this compaction method requires each sampled value to
differ from its predecessor by either +1 or -1. Under these conditions,
a single bit can be transmitted, telling whether the new sample is above
or below the previous one. This technique, called {delta modulation}, is
illustrated in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig34}{Fig.
2-34}. Like all compaction techniques that assume small level changes
between consecutive samples, delta encoding can get into trouble if the
signal changes too fast, as shown in the figure. When this happens,
information is lost.

\subparagraph[Figure 2-34. Delta
modulation.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02fig34}{}{}Figure
2-34. Delta modulation.}{Figure 2-34. Delta modulation.}}

%\includegraphics{02fig34.gif}

An improvement to differential PCM is to extrapolate the previous few
values to predict the next value and then to encode the difference
between the actual signal and the predicted one. The transmitter and
receiver must use the same prediction algorithm, of course. Such schemes
are called {predictive encoding}. They are useful because they reduce
the size of the numbers to be encoded, hence the number of bits to be
sent.

Time division multiplexing allows multiple T1 carriers to be multiplexed
into higher-order carriers.
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig35}{Figure
2-35} shows how this can be done. At the left we see four T1 channels
being multiplexed onto one T2 channel. The multiplexing at T2 and above
is done bit for bit, rather than byte for byte with the 24 voice
channels that make up a T1 frame. Four T1 streams at 1.544 Mbps should
generate 6.176 Mbps, but T2 is actually 6.312 Mbps. The extra bits are
used for framing and recovery in case the carrier slips. T1 and T3 are
widely used by customers, whereas T2 and T4 are only used within the
telephone system itself, so they are not well known.

\subparagraph[Figure 2-35. Multiplexing T1 streams onto higher
carriers.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02fig35}{}{}Figure
2-35. Multiplexing T1 streams onto higher
carriers.}{Figure 2-35. Multiplexing T1 streams onto higher carriers.}}

%\includegraphics{02fig35.gif}

At the next level, seven T2 streams are combined bitwise to form a T3
stream. Then six T3 streams are joined to form a T4 stream. At each step
a small amount of overhead is added for framing and recovery in case the
synchronization between sender and receiver is lost.

Just as there is little agreement on the basic carrier between the
United States and the rest of the world, there is equally little
agreement on how it is to be multiplexed into higher-bandwidth carriers.
The U.S. scheme of stepping up by 4, 7, and 6 did not strike everyone
else as the way to go, so the CCITT standard calls for multiplexing four
streams onto one stream at each level. Also, the framing and recovery
data are different between the U.S. and CCITT standards. The CCITT
hierarchy for 32, 128, 512, 2048, and 8192 channels runs at speeds of
2.048, 8.848, 34.304, 139.264, and 565.148 Mbps.

\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02lev3sec15}{}{}

\subparagraph{SONET/SDH}

In the early days of fiber optics, every telephone company had its own
proprietary optical TDM system. After AT\&T was broken up in 1984, local
telephone companies had to connect to multiple long-distance carriers,
all with different optical TDM systems, so the need for standardization
became obvious. In 1985, Bellcore, the RBOCs research arm, began working
on a standard, called {SONET} ({Synchronous Optical NETwork}). Later,
CCITT joined the effort, which resulted in a SONET standard and a set of
parallel CCITT recommendations (G.707, G.708, and G.709) in 1989. The
CCITT recommendations are called {SDH} ({Synchronous Digital Hierarchy})
but differ from SONET only in minor ways. Virtually all the
long-distance telephone traffic in the United States, and much of it
elsewhere, now uses trunks running SONET in the physical layer. For
additional information about SONET, see (Bellamy, 2000; Goralski, 2000;
and Shepard, 2001).

The SONET design had four major goals. First and foremost, SONET had to
make it possible for different carriers to interwork. Achieving this
goal required defining a common signaling standard with respect to
wavelength, timing, framing structure, and other issues.

Second, some means was needed to unify the U.S., European, and Japanese
digital systems, all of which were based on 64-kbps PCM channels, but
all of which combined them in different (and incompatible) ways.

Third, SONET had to provide a way to multiplex multiple digital
channels. At the time SONET was devised, the highest-speed digital
carrier actually used widely in the United States was T3, at 44.736
Mbps. T4 was defined, but not used much, and nothing was even defined
above T4 speed. Part of SONET's mission was to continue the hierarchy to
gigabits/sec and beyond. A standard way to multiplex slower channels
into one SONET channel was also needed.

Fourth, SONET had to provide support for operations, administration, and
maintenance (OAM). Previous systems did not do this very well.

An early decision was to make SONET a traditional TDM system, with the
entire bandwidth of the fiber devoted to one channel containing time
slots for the various subchannels. As such, SONET is a synchronous
system. It is controlled by a master clock with an accuracy of about 1
part in 10\textsuperscript{9}. Bits on a SONET line are sent out at
extremely precise intervals, controlled by the master clock. When cell
switching was later proposed to be the basis of ATM, the fact that it
permitted irregular cell arrivals got it labeled as {Asynchronous}
Transfer Mode to contrast it to the synchronous operation of SONET. With
SONET, the sender and receiver are tied to a common clock; with ATM they
are not.

The basic SONET frame is a block of 810 bytes put out every 125 sec.
Since SONET is synchronous, frames are emitted whether or not there are
any useful data to send. Having 8000 frames/sec exactly matches the
sampling rate of the PCM channels used in all digital telephony systems.

The 810-byte SONET frames are best described as a rectangle of bytes, 90
columns wide by 9 rows high. Thus, 8 x 810 = 6480 bits are transmitted
8000 times per second, for a gross data rate of 51.84 Mbps. This is the
basic SONET channel, called {STS-1} ({Synchronous Transport Signal-1}).
All SONET trunks are a multiple of STS-1.

The first three columns of each frame are reserved for system management
information, as illustrated in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig36}{Fig.
2-36}. The first three rows contain the section overhead; the next six
contain the line overhead. The section overhead is generated and checked
at the start and end of each section, whereas the line overhead is
generated and checked at the start and end of each line.

\subparagraph[Figure 2-36. Two back-to-back SONET
frames.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02fig36}{}{}Figure
2-36. Two back-to-back SONET
frames.}{Figure 2-36. Two back-to-back SONET frames.}}

%\includegraphics{02fig36.gif}

A SONET transmitter sends back-to-back 810-byte frames, without gaps
between them, even when there are no data (in which case it sends dummy
data). From the receiver's point of view, all it sees is a continuous
bit stream, so how does it know where each frame begins? The answer is
that the first two bytes of each frame contain a fixed pattern that the
receiver searches for. If it finds this pattern in the same place in a
large number of consecutive frames, it assumes that it is in sync with
the sender. In theory, a user could insert this pattern into the payload
in a regular way, but in practice it cannot be done due to the
multiplexing of multiple users into the same frame and other reasons.

The remaining 87 columns hold 87 x 9 x 8 x 8000 = 50.112 Mbps of user
data. However, the user data, called the {SPE} ({Synchronous Payload
Envelope}), do not always begin in row 1, column 4. The SPE can begin
anywhere within the frame. A pointer to the first byte is contained in
the first row of the line overhead. The first column of the SPE is the
path overhead (i.e., header for the end-to-end path sublayer protocol).

The ability to allow the SPE to begin anywhere within the SONET frame
and even to span two frames, as shown in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig36}{Fig.
2-36}, gives added flexibility to the system. For example, if a payload
arrives at the source while a dummy SONET frame is being constructed, it
can be inserted into the current frame instead of being held until the
start of the next one.

The SONET multiplexing hierarchy is shown in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig37}{Fig.
2-37}. Rates from STS-1 to STS-192 have been defined. The optical
carrier corresponding to STS-{n} is called OC-{n} but is bit for bit the
same except for a certain bit reordering needed for synchronization. The
SDH names are different, and they start at OC-3 because CCITT-based
systems do not have a rate near 51.84 Mbps. The OC-9 carrier is present
because it closely matches the speed of a major high-speed trunk used in
Japan. OC-18 and OC-36 are used in Japan. The gross data rate includes
all the overhead. The SPE data rate excludes the line and section
overhead. The user data rate excludes all overhead and counts only the
86 payload columns.

\subparagraph[Figure 2-37. SONET and SDH multiplex
rates.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02fig37}{}{}Figure
2-37. SONET and SDH multiplex
rates.}{Figure 2-37. SONET and SDH multiplex rates.}}

%\includegraphics{02fig37.gif}

As an aside, when a carrier, such as OC-3, is not multiplexed, but
carries the data from only a single source, the letter {c} (for
concatenated) is appended to the designation, so OC-3 indicates a
155.52-Mbps carrier consisting of three separate OC-1 carriers, but
OC-3c indicates a data stream from a single source at 155.52 Mbps. The
three OC-1 streams within an OC-3c stream are interleaved by column,
first column 1 from stream 1, then column 1 from stream 2, then column 1
from stream 3, followed by column 2 from stream 1, and so on, leading to
a frame 270 columns wide and 9 rows deep.

\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02lev2sec21}{}{}

\subsection{Switching}

From the point of view of the average telephone engineer, the phone
system is divided into two principal parts: outside plant (the local
loops and trunks, since they are physically outside the switching
offices) and inside plant (the switches), which are inside the switching
offices. We have just looked at the outside plant. Now it is time to
examine the inside plant.

Two different switching techniques are used nowadays: circuit switching
and packet switching. We will give a brief introduction to each of them
below. Then we will go into circuit switching in detail because that is
how the telephone system works. We will study packet switching in detail
in subsequent chapters.

\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02lev3sec16}{}{}

\subparagraph{Circuit Switching}

When you or your computer places a telephone call, the switching
equipment within the telephone system seeks out a physical path all the
way from your telephone to the receiver's telephone. This technique is
called {circuit switching} and is shown schematically in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig38}{Fig.
2-38(a)}. Each of the six rectangles represents a carrier switching
office (end office, toll office, etc.). In this example, each office has
three incoming lines and three outgoing lines. When a call passes
through a switching office, a physical connection is (conceptually)
established between the line on which the call came in and one of the
output lines, as shown by the dotted lines.

\subparagraph[Figure 2-38. (a) Circuit switching. (b) Packet
switching.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02fig38}{}{}Figure
2-38. (a) Circuit switching. (b) Packet
switching.}{Figure 2-38. (a) Circuit switching. (b) Packet switching.}}

%\includegraphics{02fig38.gif}

In the early days of the telephone, the connection was made by the
operator plugging a jumper cable into the input and output sockets. In
fact, a surprising little story is associated with the invention of
automatic circuit switching equipment. It was invented by a 19th century
Missouri undertaker named Almon B. Strowger. Shortly after the telephone
was invented, when someone died, one of the survivors would call the
town operator and say ``Please connect me to an undertaker.''
Unfortunately for Mr. Strowger, there were two undertakers in his town,
and the other one's wife was the town telephone operator. He quickly saw
that either he was going to have to invent automatic telephone switching
equipment or he was going to go out of business. He chose the first
option. For nearly 100 years, the circuit-switching equipment used
worldwide was known as Strowger gear. (History does not record whether
the now-unemployed switchboard operator got a job as an information
operator, answering questions such as ``What is the phone number of an
undertaker?'')

The model shown in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig39}{Fig.
2-39(a)} is highly simplified, of course, because parts of the physical
path between the two telephones may, in fact, be microwave or fiber
links onto which thousands of calls are multiplexed. Nevertheless, the
basic idea is valid: once a call has been set up, a dedicated path
between both ends exists and will continue to exist until the call is
finished.

\subparagraph[Figure 2-39. Timing of events in (a) circuit switching,
(b) message switching, (c) packet
switching.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02fig39}{}{}Figure
2-39. Timing of events in (a) circuit switching, (b) message switching,
(c) packet
switching.}{Figure 2-39. Timing of events in (a) circuit switching, (b) message switching, (c) packet switching.}}

%\includegraphics{02fig39.gif}

The alternative to circuit switching is packet switching, shown in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig38}{Fig.
2-38(b)}. With this technology, individual packets are sent as need be,
with no dedicated path being set up in advance. It is up to each packet
to find its way to the destination on its own.

An important property of circuit switching is the need to set up an
end-to-end path {before} any data can be sent. The elapsed time between
the end of dialing and the start of ringing can easily be 10 sec, more
on long-distance or international calls. During this time interval, the
telephone system is hunting for a path, as shown in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig39}{Fig.
2-39(a)}. Note that before data transmission can even begin, the call
request signal must propagate all the way to the destination and be
acknowledged. For many computer applications (e.g., point-of-sale credit
verification), long setup times are undesirable.

As a consequence of the reserved path between the calling parties, once
the setup has been completed, the only delay for data is the propagation
time for the electromagnetic signal, about 5 msec per 1000 km. Also as a
consequence of the established path, there is no danger of
congestion -- that is, once the call has been put through, you never get
busy signals. Of course, you might get one before the connection has
been established due to lack of switching or trunk capacity.

\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02lev3sec17}{}{}

\subparagraph{Message Switching}

An alternative switching strategy is {message switching}, illustrated in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig39}{Fig.
2-39(b)}. When this form of switching is used, no physical path is
established in advance between sender and receiver. Instead, when the
sender has a block of data to be sent, it is stored in the first
switching office (i.e., router) and then forwarded later, one hop at a
time. Each block is received in its entirety, inspected for errors, and
then retransmitted. A network using this technique is called a
{store-and-forward} network, as mentioned in
\protect\hyperlink{0130661023_ch01.htmlux5cux23ch01}{Chap. 1}.

The first electromechanical telecommunication systems used message
switching, namely, for telegrams. The message was punched on paper tape
(off-line) at the sending office, and then read in and transmitted over
a communication line to the next office along the way, where it was
punched out on paper tape. An operator there tore the tape off and read
it in on one of the many tape readers, one reader per outgoing trunk.
Such a switching office was called a {torn tape office}. Paper tape is
long gone and message switching is not used any more, so we will not
discuss it further in this book.

\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02lev3sec18}{}{}

\subparagraph{Packet Switching}

With message switching, there is no limit at all on block size, which
means that routers (in a modern system) must have disks to buffer long
blocks. It also means that a single block can tie up a router-router
line for minutes, rendering message switching useless for interactive
traffic. To get around these problems, {packet switching} was invented,
as described in
\protect\hyperlink{0130661023_ch01.htmlux5cux23ch01}{Chap. 1}.
Packet-switching networks place a tight upper limit on block size,
allowing packets to be buffered in router main memory instead of on
disk. By making sure that no user can monopolize any transmission line
very long (milliseconds), packet-switching networks are well suited for
handling interactive traffic. A further advantage of packet switching
over message switching is shown in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig39}{Fig.
2-39(b)} and
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig39}{(c)}:
the first packet of a multipacket message can be forwarded before the
second one has fully arrived, reducing delay and improving throughput.
For these reasons, computer networks are usually packet switched,
occasionally circuit switched, but never message switched.

Circuit switching and packet switching differ in many respects. To start
with, circuit switching requires that a circuit be set up end to end
before communication begins. Packet switching does not require any
advance setup. The first packet can just be sent as soon as it is
available.

The result of the connection setup with circuit switching is the
reservation of bandwidth all the way from the sender to the receiver.
All packets follow this path. Among other properties, having all packets
follow the same path means that they cannot arrive out of order. With
packet switching there is no path, so different packets can follow
different paths, depending on network conditions at the time they are
sent. They may arrive out of order.

Packet switching is more fault tolerant than circuit switching. In fact,
that is why it was invented. If a switch goes down, all of the circuits
using it are terminated and no more traffic can be sent on any of them.
With packet switching, packets can be routed around dead switches.

Setting up a path in advance also opens up the possibility of reserving
bandwidth in advance. If bandwidth is reserved, then when a packet
arrives, it can be sent out immediately over the reserved bandwidth.
With packet switching, no bandwidth is reserved, so packets may have to
wait their turn to be forwarded.

Having bandwidth reserved in advance means that no congestion can occur
when a packet shows up (unless more packets show up than expected). On
the other hand, when an attempt is made to establish a circuit, the
attempt can fail due to congestion. Thus, congestion can occur at
different times with circuit switching (at setup time) and packet
switching (when packets are sent).

If a circuit has been reserved for a particular user and there is no
traffic to send, the bandwidth of that circuit is wasted. It cannot be
used for other traffic. Packet switching does not waste bandwidth and
thus is more efficient from a system-wide perspective. Understanding
this trade-off is crucial for comprehending the difference between
circuit switching and packet switching. The trade-off is between
guaranteed service and wasting resources versus not guaranteeing service
and not wasting resources.

Packet switching uses store-and-forward transmission. A packet is
accumulated in a router's memory, then sent on to the next router. With
circuit switching, the bits just flow through the wire continuously. The
store-and-forward technique adds delay.

Another difference is that circuit switching is completely transparent.
The sender and receiver can use any bit rate, format, or framing method
they want to. The carrier does not know or care. With packet switching,
the carrier determines the basic parameters. A rough analogy is a road
versus a railroad. In the former, the user determines the size, speed,
and nature of the vehicle; in the latter, the carrier does. It is this
transparency that allows voice, data, and fax to coexist within the
phone system.

A final difference between circuit and packet switching is the charging
algorithm. With circuit switching, charging has historically been based
on distance and time. For mobile phones, distance usually does not play
a role, except for international calls, and time plays only a minor role
(e.g., a calling plan with 2000 free minutes costs more than one with
1000 free minutes and sometimes night or weekend calls are cheaper than
normal). With packet switching, connect time is not an issue, but the
volume of traffic sometimes is. For home users, ISPs usually charge a
flat monthly rate because it is less work for them and their customers
can understand this model easily, but backbone carriers charge regional
networks based on the volume of their traffic. The differences are
summarized in
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig40}{Fig.
2-40}.

\subparagraph[Figure 2-40. A comparison of circuit-switched and
packet-switched
networks.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec5.htmlux5cux23ch02fig40}{}{}Figure
2-40. A comparison of circuit-switched and packet-switched
networks.}{Figure 2-40. A comparison of circuit-switched and packet-switched networks.}}

%\includegraphics{02fig40.gif}

Both circuit switching and packet switching are important enough that we
will come back to them shortly and describe the various technologies
used in detail.

\section{The Mobile Telephone System}

The traditional telephone system (even if it some day gets multigigabit
end-to-end fiber) will still not be able to satisfy a growing group of
users: people on the go. People now expect to make phone calls from
airplanes, cars, swimming pools, and while jogging in the park. Within a
few years they will also expect to send e-mail and surf the Web from all
these locations and more. Consequently, there is a tremendous amount of
interest in wireless telephony. In the following sections we will study
this topic in some detail.

Wireless telephones come in two basic varieties: cordless phones and
mobile phones (sometimes called {cell phones}). {Cordless phones} are
devices consisting of a base station and a handset sold as a set for use
within the home. These are never used for networking, so we will not
examine them further. Instead we will concentrate on the mobile system,
which is used for wide area voice and data communication.

{Mobile phones} have gone through three distinct generations, with
different technologies:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  {}

  Analog voice.
\end{enumerate}

Digital voice.

Digital voice and data (Internet, e-mail, etc.).

Although most of our discussion will be about the technology of these
systems, it is interesting to note how political and tiny marketing
decisions can have a huge impact. The first mobile system was devised in
the U.S. by AT\&T and mandated for the whole country by the FCC. As a
result, the entire U.S. had a single (analog) system and a mobile phone
purchased in California also worked in New York. In contrast, when
mobile came to Europe, every country devised its own system, which
resulted in a fiasco.

Europe learned from its mistake and when digital came around, the
government-run PTTs got together and standardized on a single system
(GSM), so any European mobile phone will work anywhere in Europe. By
then, the U.S. had decided that government should not be in the
standardization business, so it left digital to the marketplace. This
decision resulted in different equipment manufacturers producing
different kinds of mobile phones. As a consequence, the U.S. now has two
major incompatible digital mobile phone systems in operation (plus one
minor one).

Despite an initial lead by the U.S., mobile phone ownership and usage in
Europe is now far greater than in the U.S. Having a single system for
all of Europe is part of the reason, but there is more. A second area
where the U.S. and Europe differed is in the humble matter of phone
numbers. In the U.S. mobile phones are mixed in with regular (fixed)
telephones. Thus, there is no way for a caller to see if, say, (212)
234-5678 is a fixed telephone (cheap or free call) or a mobile phone
(expensive call). To keep people from getting nervous about using the
telephone, the telephone companies decided to make the mobile phone
owner pay for incoming calls. As a consequence, many people hesitated to
buy a mobile phone for fear of running up a big bill by just receiving
calls. In Europe, mobile phones have a special area code (analogous to
800 and 900 numbers) so they are instantly recognizable. Consequently,
the usual rule of ``caller pays'' also applies to mobile phones in
Europe (except for international calls where costs are split).

A third issue that has had a large impact on adoption is the widespread
use of prepaid mobile phones in Europe (up to 75\% in some areas). These
can be purchased in many stores with no more formality than buying a
radio. You pay and you go. They are preloaded with, for example, 20 or
50 euro and can be recharged (using a secret PIN code) when the balance
drops to zero. As a consequence, practically every teenager and many
small children in Europe have (usually prepaid) mobile phones so their
parents can locate them, without the danger of the child running up a
huge bill. If the mobile phone is used only occasionally, its use is
essentially free since there is no monthly charge or charge for incoming
calls.

\protect\hypertarget{0130661023_ch02lev1sec6.htmlux5cux23ch02lev2sec22}{}{}

\subsection{First-Generation Mobile Phones: Analog Voice}

Enough about the politics and marketing aspects of mobile phones. Now
let us look at the technology, starting with the earliest system. Mobile
radiotelephones were used sporadically for maritime and military
communication during the early decades of the 20th century. In 1946, the
first system for car-based telephones was set up in St. Louis. This
system used a single large transmitter on top of a tall building and had
a single channel, used for both sending and receiving. To talk, the user
had to push a button that enabled the transmitter and disabled the
receiver. Such systems, known as {push-to-talk systems}, were installed
in several cities beginning in the late 1950s. CB-radio, taxis, and
police cars on television programs often use this technology.

In the 1960s, {IMTS} ({Improved Mobile Telephone System}) was installed.
It, too, used a high-powered (200-watt) transmitter, on top of a hill,
but now had two frequencies, one for sending and one for receiving, so
the push-to-talk button was no longer needed. Since all communication
from the mobile telephones went inbound on a different channel than the
outbound signals, the mobile users could not hear each other (unlike the
push-to-talk system used in taxis).

IMTS supported 23 channels spread out from 150 MHz to 450 MHz. Due to
the small number of channels, users often had to wait a long time before
getting a dial tone. Also, due to the large power of the hilltop
transmitter, adjacent systems had to be several hundred kilometers apart
to avoid interference. All in all, the limited capacity made the system
impractical.

\protect\hypertarget{0130661023_ch02lev1sec6.htmlux5cux23ch02lev3sec19}{}{}

\subparagraph{Advanced Mobile Phone System}

All that changed with {AMPS} ({Advanced Mobile Phone System}), invented
by Bell Labs and first installed in the United States in 1982. It was
also used in England, where it was called TACS, and in Japan, where it
was called MCS-L1. Although no longer state of the art, we will look at
it in some detail because many of its fundamental properties have been
directly inherited by its digital successor, D-AMPS, in order to achieve
backward compatibility.

In all mobile phone systems, a geographic region is divided up into
{cells}, which is why the devices are sometimes called cell phones. In
AMPS, the cells are typically 10 to 20 km across; in digital systems,
the cells are smaller. Each cell uses some set of frequencies not used
by any of its neighbors. The key idea that gives cellular systems far
more capacity than previous systems is the use of relatively small cells
and the reuse of transmission frequencies in nearby (but not adjacent)
cells. Whereas an IMTS system 100 km across can have one call on each
frequency, an AMPS system might have 100 10-km cells in the same area
and be able to have 10 to 15 calls on each frequency, in widely
separated cells. Thus, the cellular design increases the system capacity
by at least an order of magnitude, more as the cells get smaller.
Furthermore, smaller cells mean that less power is needed, which leads
to smaller and cheaper transmitters and handsets. Hand-held telephones
put out 0.6 watts; transmitters in cars are 3 watts, the maximum allowed
by the FCC.

The idea of frequency reuse is illustrated in
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig41}{Fig.
2-41(a)}. The cells are normally roughly circular, but they are easier
to model as hexagons. In
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig41}{Fig.
2-41(a)}, the cells are all the same size. They are grouped in units of
seven cells. Each letter indicates a group of frequencies. Notice that
for each frequency set, there is a buffer about two cells wide where
that frequency is not reused, providing for good separation and low
interference.

\subparagraph[Figure 2-41. (a) Frequencies are not reused in adjacent
cells. (b) To add more users, smaller cells can be
used.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec6.htmlux5cux23ch02fig41}{}{}Figure
2-41. (a) Frequencies are not reused in adjacent cells. (b) To add more
users, smaller cells can be
used.}{Figure 2-41. (a) Frequencies are not reused in adjacent cells. (b) To add more users, smaller cells can be used.}}

%\includegraphics{02fig41.gif}

Finding locations high in the air to place base station antennas is a
major issue. This problem has led some telecommunication carriers to
forge alliances with the Roman Catholic Church, since the latter owns a
substantial number of exalted potential antenna sites worldwide, all
conveniently under a single management.

In an area where the number of users has grown to the point that the
system is overloaded, the power is reduced, and the overloaded cells are
split into smaller {microcells} to permit more frequency reuse, as shown
in
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig41}{Fig.
2-41(b)}. Telephone companies sometimes create temporary microcells,
using portable towers with satellite links at sporting events, rock
concerts, and other places where large numbers of mobile users
congregate for a few hours. How big the cells should be is a complex
matter, which is treated in (Hac, 1995).

At the center of each cell is a base station to which all the telephones
in the cell transmit. The base station consists of a computer and
transmitter/receiver connected to an antenna. In a small system, all the
base stations are connected to a single device called an {MTSO} ({Mobile
Telephone Switching Office}) or {MSC} ({Mobile Switching Center}). In a
larger one, several MTSOs may be needed, all of which are connected to a
second-level MTSO, and so on. The MTSOs are essentially end offices as
in the telephone system, and are, in fact, connected to at least one
telephone system end office. The MTSOs communicate with the base
stations, each other, and the PSTN using a packet-switching network.

At any instant, each mobile telephone is logically in one specific cell
and under the control of that cell's base station. When a mobile
telephone physically leaves a cell, its base station notices the
telephone's signal fading away and asks all the surrounding base
stations how much power they are getting from it. The base station then
transfers ownership to the cell getting the strongest signal, that is,
the cell where the telephone is now located. The telephone is then
informed of its new boss, and if a call is in progress, it will be asked
to switch to a new channel (because the old one is not reused in any of
the adjacent cells). This process, called {handoff}, takes about 300
msec. Channel assignment is done by the MTSO, the nerve center of the
system. The base stations are really just radio relays.

Handoffs can be done in two ways. In a {soft handoff}, the telephone is
acquired by the new base station before the previous one signs off. In
this way there is no loss of continuity. The downside here is that the
telephone needs to be able to tune to two frequencies at the same time
(the old one and the new one). Neither first nor second generation
devices can do this.

In a {hard handoff}, the old base station drops the telephone before the
new one acquires it. If the new one is unable to acquire it (e.g.,
because there is no available frequency), the call is disconnected
abruptly. Users tend to notice this, but it is inevitable occasionally
with the current design.

\protect\hypertarget{0130661023_ch02lev1sec6.htmlux5cux23ch02lev3sec20}{}{}

\subparagraph{Channels}

The AMPS system uses 832 full-duplex channels, each consisting of a pair
of simplex channels. There are 832 simplex transmission channels from
824 to 849 MHz and 832 simplex receive channels from 869 to 894 MHz.
Each of these simplex channels is 30 kHz wide. Thus, AMPS uses FDM to
separate the channels.

In the 800-MHz band, radio waves are about 40 cm long and travel in
straight lines. They are absorbed by trees and plants and bounce off the
ground and buildings. It is possible that a signal sent by a mobile
telephone will reach the base station by the direct path, but also
slightly later after bouncing off the ground or a building. This may
lead to an echo or signal distortion (multipath fading). Sometimes, it
is even possible to hear a distant conversation that has bounced several
times.

The 832 channels are divided into four categories:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  {}

  Control (base to mobile) to manage the system.
\end{enumerate}

Paging (base to mobile) to alert mobile users to calls for them.

Access (bidirectional) for call setup and channel assignment.

Data (bidirectional) for voice, fax, or data.

Twenty-one of the channels are reserved for control, and these are wired
into a PROM in each telephone. Since the same frequencies cannot be
reused in nearby cells, the actual number of voice channels available
per cell is much smaller than 832, typically about 45.

\protect\hypertarget{0130661023_ch02lev1sec6.htmlux5cux23ch02lev3sec21}{}{}

\subparagraph{Call Management}

Each mobile telephone in AMPS has a 32-bit serial number and a 10-digit
telephone number in its PROM. The telephone number is represented as a
3-digit area code in 10 bits, and a 7-digit subscriber number in 24
bits. When a phone is switched on, it scans a preprogrammed list of 21
control channels to find the most powerful signal.

The phone then broadcasts its 32-bit serial number and 34-bit telephone
number. Like all the control information in AMPS, this packet is sent in
digital form, multiple times, and with an error-correcting code, even
though the voice channels themselves are analog.

When the base station hears the announcement, it tells the MTSO, which
records the existence of its new customer and also informs the
customer's home MTSO of his current location. During normal operation,
the mobile telephone reregisters about once every 15 minutes.

To make a call, a mobile user switches on the phone, enters the number
to be called on the keypad, and hits the SEND button. The phone then
transmits the number to be called and its own identity on the access
channel. If a collision occurs there, it tries again later. When the
base station gets the request, it informs the MTSO. If the caller is a
customer of the MTSO's company (or one of its partners), the MTSO looks
for an idle channel for the call. If one is found, the channel number is
sent back on the control channel. The mobile phone then automatically
switches to the selected voice channel and waits until the called party
picks up the phone.

Incoming calls work differently. To start with, all idle phones
continuously listen to the paging channel to detect messages directed at
them. When a call is placed to a mobile phone (either from a fixed phone
or another mobile phone), a packet is sent to the callee's home MTSO to
find out where it is. A packet is then sent to the base station in its
current cell, which then sends a broadcast on the paging channel of the
form ``Unit 14, are you there?'' The called phone then responds with
``Yes'' on the access channel. The base then says something like: ``Unit
14, call for you on channel 3.'' At this point, the called phone
switches to channel 3 and starts making ringing sounds (or playing some
melody the owner was given as a birthday present).

\protect\hypertarget{0130661023_ch02lev1sec6.htmlux5cux23ch02lev2sec23}{}{}

\subsection{Second-Generation Mobile Phones: Digital Voice}

The first generation of mobile phones was analog; the second generation
was digital. Just as there was no worldwide standardization during the
first generation, there was also no standardization during the second,
either. Four systems are in use now: D-AMPS, GSM, CDMA, and PDC. Below
we will discuss the first three. PDC is used only in Japan and is
basically D-AMPS modified for backward compatibility with the
first-generation Japanese analog system. The name {PCS} ({Personal
Communications Services}) is sometimes used in the marketing literature
to indicate a second-generation (i.e., digital) system. Originally it
meant a mobile phone using the 1900 MHz band, but that distinction is
rarely made now.

\protect\hypertarget{0130661023_ch02lev1sec6.htmlux5cux23ch02lev3sec22}{}{}

\subparagraph{D-AMPS -- The Digital Advanced Mobile Phone System}

The second generation of the AMPS systems is {D-AMPS} and is fully
digital. It is described in International Standard IS-54 and its
successor IS-136. D-AMPS was carefully designed to co-exist with AMPS so
that both first- and second-generation mobile phones could operate
simultaneously in the same cell. In particular, D-AMPS uses the same 30
kHz channels as AMPS and at the same frequencies so that one channel can
be analog and the adjacent ones can be digital. Depending on the mix of
phones in a cell, the cell's MTSO determines which channels are analog
and which are digital, and it can change channel types dynamically as
the mix of phones in a cell changes.

When D-AMPS was introduced as a service, a new frequency band was made
available to handle the expected increased load. The upstream channels
were in the 1850--1910 MHz range, and the corresponding downstream
channels were in the 1930--1990 MHz range, again in pairs, as in AMPS.
In this band, the waves are 16 cm long, so a standard -wave antenna is
only 4 cm long, leading to smaller phones. However, many D-AMPS phones
can use both the 850-MHz and 1900-MHz bands to get a wider range of
available channels.

On a D-AMPS mobile phone, the voice signal picked up by the microphone
is digitized and compressed using a model that is more sophisticated
than the delta modulation and predictive encoding schemes we studied
earlier. Compression takes into account detailed properties of the human
vocal system to get the bandwidth from the standard 56-kbps PCM encoding
to 8 kbps or less. The compression is done by a circuit called a
{vocoder} (Bellamy, 2000). The compression is done in the telephone,
rather than in the base station or end office, to reduce the number of
bits sent over the air link. With fixed telephony, there is no benefit
to having compression done in the telephone, since reducing the traffic
over the local loop does not increase system capacity at all.

With mobile telephony there is a huge gain from doing digitization and
compression in the handset, so much so that in D-AMPS, three users can
share a single frequency pair using time division multiplexing. Each
frequency pair supports 25 frames/sec of 40 msec each. Each frame is
divided into six time slots of 6.67 msec each, as illustrated in
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig42}{Fig.
2-42(a)} for the lowest frequency pair.

\subparagraph[Figure 2-42. (a) A D-AMPS channel with three users. (b) A
D-AMPS channel with six
users.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec6.htmlux5cux23ch02fig42}{}{}Figure
2-42. (a) A D-AMPS channel with three users. (b) A D-AMPS channel with
six
users.}{Figure 2-42. (a) A D-AMPS channel with three users. (b) A D-AMPS channel with six users.}}

%\includegraphics{02fig42.gif}

Each frame holds three users who take turns using the upstream and
downstream links. During slot 1 of
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig42}{Fig.
2-42(a)}, for example, user 1 may transmit to the base station and user
3 is receiving from the base station. Each slot is 324 bits long, of
which 64 bits are used for guard times, synchronization, and control
purposes, leaving 260 bits for the user payload. Of the payload bits,
101 are used for error correction over the noisy air link, so ultimately
only 159 bits are left for compressed speech. With 50 slots/sec, the
bandwidth available for compressed speech is just under 8 kbps, 1/7 of
the standard PCM bandwidth.

Using better compression algorithms, it is possible to get the speech
down to 4 kbps, in which case six users can be stuffed into a frame, as
illustrated in
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig42}{Fig.
2-42(b)}. From the operator's perspective, being able to squeeze three
to six times as many D-AMPS users into the same spectrum as one AMPS
user is a huge win and explains much of the popularity of PCS. Of
course, the quality of speech at 4 kbps is not comparable to what can be
achieved at 56 kbps, but few PCS operators advertise their hi-fi sound
quality. It should also be clear that for data, an 8 kbps channel is not
even as good as an ancient 9600-bps modem.

The control structure of D-AMPS is fairly complicated. Briefly
summarized, groups of 16 frames form a superframe, with certain control
information present in each superframe a limited number of times. Six
main control channels are used: system configuration, real-time and
nonreal-time control, paging, access response, and short messages. But
conceptually, it works like AMPS. When a mobile is switched on, it makes
contact with the base station to announce itself and then listens on a
control channel for incoming calls. Having picked up a new mobile, the
MTSO informs the user's home base where he is, so calls can be routed
correctly.

One difference between AMPS and D-AMPS is how handoff is handled. In
AMPS, the MTSO manages it completely without help from the mobile
devices. As can be seen from
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig42}{Fig.
2-42}, in D-AMPS, 1/3 of the time a mobile is neither sending nor
receiving. It uses these idle slots to measure the line quality. When it
discovers that the signal is waning, it complains to the MTSO, which can
then break the connection, at which time the mobile can try to tune to a
stronger signal from another base station. As in AMPS, it still takes
about 300 msec to do the handoff. This technique is called {MAHO}
({Mobile Assisted HandOff}).

\protect\hypertarget{0130661023_ch02lev1sec6.htmlux5cux23ch02lev3sec23}{}{}

\subparagraph{GSM -- The Global System for Mobile Communications}

D-AMPS is widely used in the U.S. and (in modified form) in Japan.
Virtually everywhere else in the world, a system called {GSM} ({Global
System for Mobile communications}) is used, and it is even starting to
be used in the U.S. on a limited scale. To a first approximation, GSM is
similar to D-AMPS. Both are cellular systems. In both systems, frequency
division multiplexing is used, with each mobile transmitting on one
frequency and receiving on a higher frequency (80 MHz higher for D-AMPS,
55 MHz higher for GSM). Also in both systems, a single frequency pair is
split by time-division multiplexing into time slots shared by multiple
mobiles. However, the GSM channels are much wider than the AMPS channels
(200 kHz versus 30 kHz) and hold relatively few additional users (8
versus 3), giving GSM a much higher data rate per user than D-AMPS.

Below we will briefly discuss some of the main properties of GSM.
However, the printed GSM standard is over 5000 {[}sic{]} pages long. A
large fraction of this material relates to engineering aspects of the
system, especially the design of receivers to handle multipath signal
propagation, and synchronizing transmitters and receivers. None of this
will be even mentioned below.

Each frequency band is 200 kHz wide, as shown in
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig43}{Fig.
2-43}. A GSM system has 124 pairs of simplex channels. Each simplex
channel is 200 kHz wide and supports eight separate connections on it,
using time division multiplexing. Each currently active station is
assigned one time slot on one channel pair. Theoretically, 992 channels
can be supported in each cell, but many of them are not available, to
avoid frequency conflicts with neighboring cells. In
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig43}{Fig.
2-43}, the eight shaded time slots all belong to the same connection,
four of them in each direction. Transmitting and receiving does not
happen in the same time slot because the GSM radios cannot transmit and
receive at the same time and it takes time to switch from one to the
other. If the mobile station assigned to 890.4/935.4 MHz and time slot 2
wanted to transmit to the base station, it would use the lower four
shaded slots (and the ones following them in time), putting some data in
each slot until all the data had been sent.

\subparagraph[Figure 2-43. GSM uses 124 frequency channels, each of
which uses an eight-slot TDM
system.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec6.htmlux5cux23ch02fig43}{}{}Figure
2-43. GSM uses 124 frequency channels, each of which uses an eight-slot
TDM
system.}{Figure 2-43. GSM uses 124 frequency channels, each of which uses an eight-slot TDM system.}}

%\includegraphics{02fig43.gif}

The TDM slots shown in
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig43}{Fig.
2-43} are part of a complex framing hierarchy. Each TDM slot has a
specific structure, and groups of TDM slots form multiframes, also with
a specific structure. A simplified version of this hierarchy is shown in
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig44}{Fig.
2-44}. Here we can see that each TDM slot consists of a 148-bit data
frame that occupies the channel for 577 sec (including a 30-sec guard
time after each slot). Each data frame starts and ends with three 0
bits, for frame delineation purposes. It also contains two 57-bit
{Information} fields, each one having a control bit that indicates
whether the following {Information} field is for voice or data. Between
the {Information} fields is a 26-bit {Sync} (training) field that is
used by the receiver to synchronize to the sender's frame boundaries.

\subparagraph[Figure 2-44. A portion of the GSM framing
structure.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec6.htmlux5cux23ch02fig44}{}{}Figure
2-44. A portion of the GSM framing
structure.}{Figure 2-44. A portion of the GSM framing structure.}}

%\includegraphics{02fig44.gif}

A data frame is transmitted in 547 sec, but a transmitter is only
allowed to send one data frame every 4.615 msec, since it is sharing the
channel with seven other stations. The gross rate of each channel is
270,833 bps, divided among eight users. This gives 33.854 kbps gross,
more than double D-AMPS' 324 bits 50 times per second for 16.2 kbps.
However, as with AMPS, the overhead eats up a large fraction of the
bandwidth, ultimately leaving 24.7 kbps worth of payload per user before
error correction. After error correction, 13 kbps is left for speech,
giving substantially better voice quality than D-AMPS (at the cost of
using correspondingly more bandwidth).

As can be seen from
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig44}{Fig.
2-44}, eight data frames make up a TDM frame and 26 TDM frames make up a
120-msec multiframe. Of the 26 TDM frames in a multiframe, slot 12 is
used for control and slot 25 is reserved for future use, so only 24 are
available for user traffic.

However, in addition to the 26-slot multiframe shown in
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig44}{Fig.
2-44}, a 51-slot multiframe (not shown) is also used. Some of these
slots are used to hold several control channels used to manage the
system. The {broadcast control channel} is a continuous stream of output
from the base station containing the base station's identity and the
channel status. All mobile stations monitor their signal strength to see
when they have moved into a new cell.

The {dedicated control channel} is used for location updating,
registration, and call setup. In particular, each base station maintains
a database of mobile stations currently under its jurisdiction.
Information needed to maintain this database is sent on the dedicated
control channel.

Finally, there is the {common control channel}, which is split up into
three logical subchannels. The first of these subchannels is the {paging
channel}, which the base station uses to announce incoming calls. Each
mobile station monitors it continuously to watch for calls it should
answer. The second is the {random access channel}, which allows users to
request a slot on the dedicated control channel. If two requests
collide, they are garbled and have to be retried later. Using the
dedicated control channel slot, the station can set up a call. The
assigned slot is announced on the third subchannel, the {access grant
channel}.

\protect\hypertarget{0130661023_ch02lev1sec6.htmlux5cux23ch02lev3sec24}{}{}

\subparagraph{CDMA -- Code Division Multiple Access}

D-AMPS and GSM are fairly conventional systems. They use both FDM and
TDM to divide the spectrum into channels and the channels into time
slots. However, there is a third kid on the block, {CDMA} ({Code
Division Multiple Access}), which works completely differently. When
CDMA was first proposed, the industry gave it approximately the same
reaction that Columbus first got from Queen Isabella when he proposed
reaching India by sailing in the wrong direction. However, through the
persistence of a single company, Qualcomm, CDMA has matured to the point
where it is not only acceptable, it is now viewed as the best technical
solution around and the basis for the third-generation mobile systems.
It is also widely used in the U.S. in second-generation mobile systems,
competing head-on with D-AMPS. For example, Sprint PCS uses CDMA,
whereas AT\&T Wireless uses D-AMPS. CDMA is described in International
Standard IS-95 and is sometimes referred to by that name. The brand name
{cdmaOne} is also used.

CDMA is completely different from AMPS, D-AMPS, and GSM. Instead of
dividing the allowed frequency range into a few hundred narrow channels,
CDMA allows each station to transmit over the entire frequency spectrum
all the time. Multiple simultaneous transmissions are separated using
coding theory. CDMA also relaxes the assumption that colliding frames
are totally garbled. Instead, it assumes that multiple signals add
linearly.

Before getting into the algorithm, let us consider an analogy: an
airport lounge with many pairs of people conversing. TDM is comparable
to all the people being in the middle of the room but taking turns
speaking. FDM is comparable to the people being in widely separated
clumps, each clump holding its own conversation at the same time as, but
still independent of, the others. CDMA is comparable to everybody being
in the middle of the room talking at once, but with each pair in a
different language. The French-speaking couple just hones in on the
French, rejecting everything that is not French as noise. Thus, the key
to CDMA is to be able to extract the desired signal while rejecting
everything else as random noise. A somewhat simplified description of
CDMA follows.

In CDMA, each bit time is subdivided into {m} short intervals called
{chips}. Typically, there are 64 or 128 chips per bit, but in the
example given below we will use 8 chips/bit for simplicity.

Each station is assigned a unique {m}-bit code called a {chip sequence}.
To transmit a 1 bit, a station sends its chip sequence. To transmit a 0
bit, it sends the one's complement of its chip sequence. No other
patterns are permitted. Thus, for {m} = 8, if station {A} is assigned
the chip sequence 00011011, it sends a 1 bit by sending 00011011 and a 0
bit by sending 11100100.

Increasing the amount of information to be sent from {b} bits/sec to
{mb} chips/sec can only be done if the bandwidth available is increased
by a factor of {m}, making CDMA a form of spread spectrum communication
(assuming no changes in the modulation or encoding techniques). If we
have a 1-MHz band available for 100 stations, with FDM each one would
have 10 kHz and could send at 10 kbps (assuming 1 bit per Hz). With
CDMA, each station uses the full 1 MHz, so the chip rate is 1 megachip
per second. With fewer than 100 chips per bit, the effective bandwidth
per station is higher for CDMA than FDM, and the channel allocation
problem is also solved.

For pedagogical purposes, it is more convenient to use a bipolar
notation, with binary 0 being -1 and binary 1 being +1. We will show
chip sequences in parentheses, so a 1 bit for station {A} now becomes
(-1 -1 -1 +1 +1 -1 +1 +1). In
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig45}{Fig.
2-45(a)} we show the binary chip sequences assigned to four example
stations. In
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig45}{Fig.
2-45(b)} we show them in our bipolar notation.

\subparagraph[Figure 2-45. (a) Binary chip sequences for four stations.
(b) Bipolar chip sequences. (c) Six examples of transmissions. (d)
Recovery of station C's
signal.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec6.htmlux5cux23ch02fig45}{}{}Figure
2-45. (a) Binary chip sequences for four stations. (b) Bipolar chip
sequences. (c) Six examples of transmissions. (d) Recovery of station
C's
signal.}{Figure 2-45. (a) Binary chip sequences for four stations. (b) Bipolar chip sequences. (c) Six examples of transmissions. (d) Recovery of station C's signal.}}

%\includegraphics{02fig45.gif}

Each station has its own unique chip sequence. Let us use the symbol {S}
to indicate the {m}-chip vector for station {S}, and
%\includegraphics{02icon12.gif}
 for its negation. All chip sequences are
pairwise {orthogonal}, by which we mean that the normalized inner
product of any two distinct chip sequences, {S} and {T} (written as
{S}{T}), is 0. It is known how to generate such orthogonal chip
sequences using a method known as {Walsh codes}. In mathematical terms,
orthogonality of the chip sequences can be expressed as follows:

\textbf{\protect\hypertarget{0130661023_ch02lev1sec6.htmlux5cux23ch02eq04}{}{}
Equation 2}

%\includegraphics{02icon13.gif}

~

In plain English, as many pairs are the same as are different. This
orthogonality property will prove crucial later on. Note that if {S}{T}
= 0, then
%\includegraphics{01icon01.gif}
is also 0. The normalized inner
product of any chip sequence with itself is 1:

%\includegraphics{02icon14.gif}

~

This follows because each of the {m} terms in the inner product is 1, so
the sum is {m}. Also note that
%\includegraphics{02icon15.gif}.

During each bit time, a station can transmit a 1 by sending its chip
sequence, it can transmit a 0 by sending the negative of its chip
sequence, or it can be silent and transmit nothing. For the moment, we
assume that all stations are synchronized in time, so all chip sequences
begin at the same instant.

When two or more stations transmit simultaneously, their bipolar signals
add linearly. For example, if in one chip period three stations output
+1 and one station outputs -1, the result is +2. One can think of this
as adding voltages: three stations outputting +1 volts and 1 station
outputting -1 volts gives 2 volts.

In
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig45}{Fig.
2-45(c)} we see six examples of one or more stations transmitting at the
same time. In the first example, {C} transmits a 1 bit, so we just get
{C}'s chip sequence. In the second example, both {B} and {C} transmit 1
bits, so we get the sum of their bipolar chip sequences, namely:

%\includegraphics{02icon16.gif}

~

In the third example, station {A} sends a 1 and station {B} sends a 0.
The others are silent. In the fourth example, {A} and {C} send a 1 bit
while {B} sends a 0 bit. In the fifth example, all four stations send a
1 bit. Finally, in the last example, {A}, {B}, and {D} send a 1 bit,
while {C} sends a 0 bit. Note that each of the six sequences {S}
\textsubscript{1} through {S} \textsubscript{6} given in
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig45}{Fig.
2-45(c)} represents only one bit time.

To recover the bit stream of an individual station, the receiver must
know that station's chip sequence in advance. It does the recovery by
computing the normalized inner product of the received chip sequence
(the linear sum of all the stations that transmitted) and the chip
sequence of the station whose bit stream it is trying to recover. If the
received chip sequence is {S} and the receiver is trying to listen to a
station whose chip sequence is {C}, it just computes the normalized
inner product, {S}{C}.

To see why this works, just imagine that two stations, {A} and {C}, both
transmit a 1 bit at the same time that {B} transmits a 0 bit. The
receiver sees the sum,
%\includegraphics{02icon17.gif}
and computes

%\includegraphics{02icon18.gif}

~

The first two terms vanish because all pairs of chip sequences have been
carefully chosen to be orthogonal, as shown in
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02eq04}{Eq.
(2-4)}. Now it should be clear why this property must be imposed on the
chip sequences.

An alternative way of thinking about this situation is to imagine that
the three chip sequences all came in separately, rather than summed.
Then, the receiver would compute the inner product with each one
separately and add the results. Due to the orthogonality property, all
the inner products except {C}{C} would be 0. Adding them and then doing
the inner product is in fact the same as doing the inner products and
then adding those.

To make the decoding process more concrete, let us consider the six
examples of
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig45}{Fig.
2-45(c)} again as illustrated in
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig45}{Fig.
2-45(d)}. Suppose that the receiver is interested in extracting the bit
sent by station {C} from each of the six sums {S}\textsubscript{1}
through {S}\textsubscript{6}. It calculates the bit by summing the
pairwise products of the received {S} and the {C} vector of
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig45}{Fig.
2-45(b)} and then taking 1/8 of the result (since {m} = 8 here). As
shown, the correct bit is decoded each time. It is just like speaking
French.

In an ideal, noiseless CDMA system, the capacity (i.e., number of
stations) can be made arbitrarily large, just as the capacity of a
noiseless Nyquist channel can be made arbitrarily large by using more
and more bits per sample. In practice, physical limitations reduce the
capacity considerably. First, we have assumed that all the chips are
synchronized in time. In reality, such synchronization is impossible.
What can be done is that the sender and receiver synchronize by having
the sender transmit a predefined chip sequence that is long enough for
the receiver to lock onto. All the other (unsynchronized) transmissions
are then seen as random noise. If there are not too many of them,
however, the basic decoding algorithm still works fairly well. A large
body of theory exists relating the superposition of chip sequences to
noise level (Pickholtz et al., 1982). As one might expect, the longer
the chip sequence, the higher the probability of detecting it correctly
in the presence of noise. For extra reliability, the bit sequence can
use an error-correcting code. Chip sequences never use error-correcting
codes.

An implicit assumption in our discussion is that the power levels of all
stations are the same as perceived by the receiver. CDMA is typically
used for wireless systems with a fixed base station and many mobile
stations at varying distances from it. The power levels received at the
base station depend on how far away the transmitters are. A good
heuristic here is for each mobile station to transmit to the base
station at the inverse of the power level it receives from the base
station. In other words, a mobile station receiving a weak signal from
the will use more power than one getting a strong signal. The base
station can also give explicit commands to the mobile stations to
increase or decrease their transmission power.

We have also assumed that the receiver knows who the sender is. In
principle, given enough computing capacity, the receiver can listen to
all the senders at once by running the decoding algorithm for each of
them in parallel. In real life, suffice it to say that this is easier
said than done. CDMA also has many other complicating factors that have
been glossed over in this brief introduction. Nevertheless, CDMA is a
clever scheme that is being rapidly introduced for wireless mobile
communication. It normally operates in a band of 1.25 MHz (versus 30 kHz
for D-AMPS and 200 kHz for GSM), but it supports many more users in that
band than either of the other systems. In practice, the bandwidth
available to each user is at least as good as GSM and often much better.

Engineers who want to gain a very deep understanding of CDMA should read
(Lee and Miller, 1998). An alternative spreading scheme, in which the
spreading is over time rather than frequency, is described in (Crespo et
al., 1995). Yet another scheme is described in (Sari et al., 2000). All
of these references require quite a bit of background in communication
engineering.

\protect\hypertarget{0130661023_ch02lev1sec6.htmlux5cux23ch02lev2sec24}{}{}

\subsection{Third-Generation Mobile Phones: Digital Voice and Data}

What is the future of mobile telephony? Let us take a quick look. A
number of factors are driving the industry. First, data traffic already
exceeds voice traffic on the fixed network and is growing exponentially,
whereas voice traffic is essentially flat. Many industry experts expect
data traffic to dominate voice on mobile devices as well soon. Second,
the telephone, entertainment, and computer industries have all gone
digital and are rapidly converging. Many people are drooling over a
lightweight, portable device that acts as a telephone, CD player, DVD
player, e-mail terminal, Web interface, gaming machine, word processor,
and more, all with worldwide wireless connectivity to the Internet at
high bandwidth. This device and how to connect it is what third
generation mobile telephony is all about. For more information, see
(Huber et al., 2000; and Sarikaya, 2000).

Back in 1992, ITU tried to get a bit more specific about this dream and
issued a blueprint for getting there called {IMT-2000}, where IMT stood
for {International Mobile Telecommunications}. The number 2000 stood for
three things: (1) the year it was supposed to go into service, (2) the
frequency it was supposed to operate at (in MHz), and (3) the bandwidth
the service should have (in kHz).

It did not make it on any of the three counts. Nothing was implemented
by 2000. ITU recommended that all governments reserve spectrum at 2 GHz
so devices could roam seamlessly from country to country. China reserved
the required bandwidth but nobody else did. Finally, it was recognized
that 2 Mbps is not currently feasible for users who are {too} mobile
(due to the difficulty of performing handoffs quickly enough). More
realistic is 2 Mbps for stationary indoor users (which will compete
head-on with ADSL), 384 kbps for people walking, and 144 kbps for
connections in cars. Nevertheless, the whole area of {3G},asitis called,
is one great cauldron of activity. The third generation may be a bit
less than originally hoped for and a bit late, but it will surely
happen.

The basic services that the IMT-2000 network is supposed to provide to
its users are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  {}

  High-quality voice transmission.
\end{enumerate}

Messaging (replacing e-mail, fax, SMS, chat, etc.).

Multimedia (playing music, viewing videos, films, television, etc.).

Internet access (Web surfing, including pages with audio and video).

Additional services might be video conferencing, telepresence, group
game playing, and m-commerce (waving your telephone at the cashier to
pay in a store). Furthermore, all these services are supposed to be
available worldwide (with automatic connection via a satellite when no
terrestrial network can be located), instantly (always on), and with
quality-of-service guarantees.

ITU envisioned a single worldwide technology for IMT-2000, so that
manufacturers could build a single device that could be sold and used
anywhere in the world (like CD players and computers and unlike mobile
phones and televisions). Having a single technology would also make life
much simpler for network operators and would encourage more people to
use the services. Format wars, such as the Betamax versus VHS battle
when videorecorders first came out, are not good for business.

Several proposals were made, and after some winnowing, it came down to
two main ones. The first one, {W-CDMA} ({Wideband CDMA}), was proposed
by Ericsson. This system uses direct sequence spread spectrum of the
type we described above. It runs in a 5 MHz bandwidth and has been
designed to interwork with GSM networks although it is not backward
compatible with GSM. It does, however, have the property that a caller
can leave a W-CDMA cell and enter a GSM cell without losing the call.
This system was pushed hard by the European Union, which called it
{UMTS} ({Universal Mobile Telecommunications System}).

The other contender was {CDMA2000}, proposed by Qualcomm. It, too, is a
direct sequence spread spectrum design, basically an extension of IS-95
and backward compatible with it. It also uses a 5-MHz bandwidth, but it
has not been designed to interwork with GSM and cannot hand off calls to
a GSM cell (or a D-AMPS cell, for that matter). Other technical
differences with W-CDMA include a different chip rate, different frame
time, different spectrum used, and a different way to do time
synchronization.

If the Ericsson and Qualcomm engineers were put in a room and told to
come to a common design, they probably could. After all, the basic
principle behind both systems is CDMA in a 5 MHz channel and nobody is
willing to die for his preferred chip rate. The trouble is that the real
problem is not engineering, but politics (as usual). Europe wanted a
system that interworked with GSM; the U.S. wanted a system that was
compatible with one already widely deployed in the U.S. (IS-95). Each
side also supported its local company (Ericsson is based in Sweden;
Qualcomm is in California). Finally, Ericsson and Qualcomm were involved
in numerous lawsuits over their respective CDMA patents.

In March 1999, the two companies settled the lawsuits when Ericsson
agreed to buy Qualcomm's infrastructure. They also agreed to a single 3G
standard, but one with multiple incompatible options, which to a large
extent just papers over the technical differences. These disputes
notwithstanding, 3G devices and services are likely to start appearing
in the coming years.

Much has been written about 3G systems, most of it praising it as the
greatest thing since sliced bread. Some references are (Collins and
Smith, 2001; De Vriendt et al., 2002; Harte et al., 2002; Lu, 2002; and
Sarikaya, 2000). However, some dissenters think that the industry is
pointed in the wrong direction (Garber, 2002; and Goodman, 2000).

While waiting for the fighting over 3G to stop, some operators are
gingerly taking a cautious small step in the direction of 3G by going to
what is sometimes called {2.5G}, although 2.1G might be more accurate.
One such system is {EDGE} ({Enhanced Data rates for GSM Evolution}),
which is just GSM with more bits per baud. The trouble is, more bits per
baud also means more errors per baud, so EDGE has nine different schemes
for modulation and error correction, differing on how much of the
bandwidth is devoted to fixing the errors introduced by the higher
speed.

Another 2.5G scheme is {GPRS} ({General Packet Radio Service}), which is
an overlay packet network on top of D-AMPS or GSM. It allows mobile
stations to send and receive IP packets in a cell running a voice
system. When GPRS is in operation, some time slots on some frequencies
are reserved for packet traffic. The number and location of the time
slots can be dynamically managed by the base station, depending on the
ratio of voice to data traffic in the cell.

The available time slots are divided into several logical channels, used
for different purposes. The base station determines which logical
channels are mapped onto which time slots. One logical channel is for
downloading packets from the base station to some mobile station, with
each packet indicating who it is destined for. To send an IP packet, a
mobile station requests one or more time slots by sending a request to
the base station. If the request arrives without damage, the base
station announces the frequency and time slots allocated to the mobile
for sending the packet. Once the packet has arrived at the base station,
it is transferred to the Internet by a wired connection. Since GPRS is
just an overlay over the existing voice system, it is at best a stop-gap
measure until 3G arrives.

Even though 3G networks are not fully deployed yet, some researchers
regard 3G as a done deal and thus not interesting any more. These people
are already working on 4G systems (Berezdivin et al., 2002; Guo and
Chaskar, 2002; Huang and Zhuang, 2002; Kellerer et al., 2002; and Misra
et al., 2002). Some of the proposed features of 4G systems include high
bandwidth, ubiquity (connectivity everywhere), seamless integration with
wired networks and especially IP, adaptive resource and spectrum
management, software radios, and high quality of service for multimedia.

Then on the other hand, so many 802.11 wireless LAN access points are
being set up all over the place, that some people think 3G is not only
not a done deal, it is doomed. In this vision, people will just wander
from one 802.11 access point to another to stay connected. To say the
industry is in a state of enormous flux is a huge understatement. Check
back in about 5 years to see what happens.


\section{Cable Television}

We have now studied both the fixed and wireless telephone systems in a
fair amount of detail. Both will clearly play a major role in future
networks. However, an alternative available for fixed networking is now
becoming a major player: cable television networks. Many people already
get their telephone and Internet service over the cable, and the cable
operators are actively working to increase their market share. In the
following sections we will look at cable television as a networking
system in more detail and contrast it with the telephone systems we have
just studied. For more information about cable, see (Laubach et al.,
2001; Louis, 2002; Ovadia, 2001; and Smith, 2002).

\protect\hypertarget{0130661023_ch02lev1sec7.htmlux5cux23ch02lev2sec25}{}{}

\subsection{Community Antenna Television}

Cable television was conceived in the late 1940s as a way to provide
better reception to people living in rural or mountainous areas. The
system initially consisted of a big antenna on top of a hill to pluck
the television signal out of the air, an amplifier, called the {head
end}, to strengthen it, and a coaxial cable to deliver it to people's
houses, as illustrated in
\protect\hyperlink{0130661023_ch02lev1sec7.htmlux5cux23ch02fig46}{Fig.
2-46}.

\subparagraph[Figure 2-46. An early cable television
system.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec7.htmlux5cux23ch02fig46}{}{}Figure
2-46. An early cable television
system.}{Figure 2-46. An early cable television system.}}

%\includegraphics{02fig46.gif}

In the early years, cable television was called {Community Antenna
Television}. It was very much a mom-and-pop operation; anyone handy with
electronics could set up a service for his town, and the users would
chip in to pay the costs. As the number of subscribers grew, additional
cables were spliced onto the original cable and amplifiers were added as
needed. Transmission was one way, from the headend to the users. By
1970, thousands of independent systems existed.

In 1974, Time, Inc., started a new channel, Home Box Office, with new
content (movies) and distributed only on cable. Other cable-only
channels followed with news, sports, cooking, and many other topics.
This development gave rise to two changes in the industry. First, large
corporations began buying up existing cable systems and laying new cable
to acquire new subscribers. Second, there was now a need to connect
multiple systems, often in distant cities, in order to distribute the
new cable channels. The cable companies began to lay cable between their
cities to connect them all into a single system. This pattern was
analogous to what happened in the telephone industry 80 years earlier
with the connection of previously isolated end offices to make long
distance calling possible.

\protect\hypertarget{0130661023_ch02lev1sec7.htmlux5cux23ch02lev2sec26}{}{}

\subsection{Internet over Cable}

Over the course of the years the cable system grew and the cables
between the various cities were replaced by high-bandwidth fiber,
similar to what was happening in the telephone system. A system with
fiber for the long-haul runs and coaxial cable to the houses is called
an {HFC} ({Hybrid Fiber Coax}) system. The electro-optical converters
that interface between the optical and electrical parts of the system
are called {fiber nodes}. Because the bandwidth of fiber is so much more
than that of coax, a fiber node can feed multiple coaxial cables. Part
of a modern HFC system is shown in
\protect\hyperlink{0130661023_ch02lev1sec7.htmlux5cux23ch02fig47}{Fig.
2-47(a)}.

\subparagraph[Figure 2-47. (a) Cable television. (b) The fixed telephone
system.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec7.htmlux5cux23ch02fig47}{}{}Figure
2-47. (a) Cable television. (b) The fixed telephone
system.}{Figure 2-47. (a) Cable television. (b) The fixed telephone system.}}

%\includegraphics{02fig47.gif}

In recent years, many cable operators have decided to get into the
Internet access business, and often the telephony business as well.
However, technical differences between the cable plant and telephone
plant have an effect on what has to be done to achieve these goals. For
one thing, all the one-way amplifiers in the system have to be replaced
by two-way amplifiers.

However, there is another difference between the HFC system of
\protect\hyperlink{0130661023_ch02lev1sec7.htmlux5cux23ch02fig47}{Fig.
2-47(a)} and the telephone system of
\protect\hyperlink{0130661023_ch02lev1sec7.htmlux5cux23ch02fig47}{Fig.
2-47(b)} that is much harder to remove. Down in the neighborhoods, a
single cable is shared by many houses, whereas in the telephone system,
every house has its own private local loop. When used for television
broadcasting, this sharing does not play a role. All the programs are
broadcast on the cable and it does not matter whether there are 10
viewers or 10,000 viewers. When the same cable is used for Internet
access, it matters a lot if there are 10 users or 10,000. If one user
decides to download a very large file, that bandwidth is potentially
being taken away from other users. The more users, the more competition
for bandwidth. The telephone system does not have this particular
property: downloading a large file over an ADSL line does not reduce
your neighbor's bandwidth. On the other hand, the bandwidth of coax is
much higher than that of twisted pairs.

The way the cable industry has tackled this problem is to split up long
cables and connect each one directly to a fiber node. The bandwidth from
the headend to each fiber node is effectively infinite, so as long as
there are not too many subscribers on each cable segment, the amount of
traffic is manageable. Typical cables nowadays have 500--2000 houses,
but as more and more people subscribe to Internet over cable, the load
may become too much, requiring more splitting and more fiber nodes.

\protect\hypertarget{0130661023_ch02lev1sec7.htmlux5cux23ch02lev2sec27}{}{}

\subsection{Spectrum Allocation}

Throwing off all the TV channels and using the cable infrastructure
strictly for Internet access would probably generate a fair number of
irate customers, so cable companies are hesitant to do this.
Furthermore, most cities heavily regulate what is on the cable, so the
cable operators would not be allowed to do this even if they really
wanted to. As a consequence, they needed to find a way to have
television and Internet coexist on the same cable.

Cable television channels in North America normally occupy the 54--550
MHz region (except for FM radio from 88 to 108 MHz). These channels are
6 MHz wide, including guard bands. In Europe the low end is usually 65
MHz and the channels are 6--8 MHz wide for the higher resolution
required by PAL and SECAM but otherwise the allocation scheme is
similar. The low part of the band is not used. Modern cables can also
operate well above 550 MHz, often to 750 MHz or more. The solution
chosen was to introduce upstream channels in the 5--42 MHz band
(slightly higher in Europe) and use the frequencies at the high end for
the downstream. The cable spectrum is illustrated in
\protect\hyperlink{0130661023_ch02lev1sec7.htmlux5cux23ch02fig48}{Fig.
2-48}.

\subparagraph[Figure 2-48. Frequency allocation in a typical cable TV
system used for Internet
access.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec7.htmlux5cux23ch02fig48}{}{}Figure
2-48. Frequency allocation in a typical cable TV system used for
Internet
access.}{Figure 2-48. Frequency allocation in a typical cable TV system used for Internet access.}}

%\includegraphics{02fig48.gif}

Note that since the television signals are all downstream, it is
possible to use upstream amplifiers that work only in the 5--42 MHz
region and downstream amplifiers that work only at 54 MHz and up, as
shown in the figure. Thus, we get an asymmetry in the upstream and
downstream bandwidths because more spectrum is available above
television than below it. On the other hand, most of the traffic is
likely to be downstream, so cable operators are not unhappy with this
fact of life. As we saw earlier, telephone companies usually offer an
asymmetric DSL service, even though they have no technical reason for
doing so.

Long coaxial cables are not any better for transmitting digital signals
than are long local loops, so analog modulation is needed here, too. The
usual scheme is to take each 6 MHz or 8 MHz downstream channel and
modulate it with QAM-64 or, if the cable quality is exceptionally good,
QAM-256. With a 6 MHz channel and QAM-64, we get about 36 Mbps. When the
overhead is subtracted, the net payload is about 27 Mbps. With QAM-256,
the net payload is about 39 Mbps. The European values are 1/3 larger.

For upstream, even QAM-64 does not work well. There is too much noise
from terrestrial microwaves, CB radios, and other sources, so a more
conservative scheme -- QPSK -- is used. This method (shown in
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig45}{Fig.
2-25}) yields 2 bits per baud instead of the 6 or 8 bits QAM provides on
the downstream channels. Consequently, the asymmetry between upstream
bandwidth and downstream bandwidth is much more than suggested by
\protect\hyperlink{0130661023_ch02lev1sec7.htmlux5cux23ch02fig48}{Fig.
2-48}.

In addition to upgrading the amplifiers, the operator has to upgrade the
headend, too, from a dumb amplifier to an intelligent digital computer
system with a high-bandwidth fiber interface to an ISP. Often the name
gets upgraded as well, from ``headend'' to {CMTS} ({Cable Modem
Termination System}). In the following text, we will refrain from doing
a name upgrade and stick with the traditional ``headend.''

\protect\hypertarget{0130661023_ch02lev1sec7.htmlux5cux23ch02lev2sec28}{}{}

\subsection{Cable Modems}

Internet access requires a cable modem, a device that has two interfaces
on it: one to the computer and one to the cable network. In the early
years of cable Internet, each operator had a proprietary cable modem,
which was installed by a cable company technician. However, it soon
became apparent that an open standard would create a competitive cable
modem market and drive down prices, thus encouraging use of the service.
Furthermore, having the customers buy cable modems in stores and install
them themselves (as they do with V.9x telephone modems) would eliminate
the dreaded truck rolls.

Consequently, the larger cable operators teamed up with a company called
CableLabs to produce a cable modem standard and to test products for
compliance. This standard, called {DOCSIS} ({Data Over Cable Service
Interface Specification}) is just starting to replace proprietary
modems. The European version is called {EuroDOCSIS}. Not all cable
operators like the idea of a standard, however, since many of them were
making good money leasing their modems to their captive customers. An
open standard with dozens of manufacturers selling cable modems in
stores ends this lucrative practice.

The modem-to-computer interface is straightforward. It is normally
10-Mbps Ethernet (or occasionally USB) at present. In the future, the
entire modem might be a small card plugged into the computer, just as
with V.9x internal modems.

The other end is more complicated. A large part of the standard deals
with radio engineering, a subject that is far beyond the scope of this
book. The only part worth mentioning here is that cable modems, like
ADSL modems, are always on. They make a connection when turned on and
maintain that connection as long as they are powered up because cable
operators do not charge for connect time.

To better understand how they work, let us see what happens when a cable
modem is plugged in and powered up. The modem scans the downstream
channels looking for a special packet periodically put out by the
headend to provide system parameters to modems that have just come
on-line. Upon finding this packet, the new modem announces its presence
on one of the upstream channels. The headend responds by assigning the
modem to its upstream and downstream channels. These assignments can be
changed later if the headend deems it necessary to balance the load.

The modem then determines its distance from the headend by sending it a
special packet and seeing how long it takes to get the response. This
process is called {ranging}. It is important for the modem to know its
distance to accommodate the way the upstream channels operate and to get
the timing right. They are divided in time in {minislots}. Each upstream
packet must fit in one or more consecutive minislots. The headend
announces the start of a new round of minislots periodically, but the
starting gun is not heard at all modems simultaneously due to the
propagation time down the cable. By knowing how far it is from the
headend, each modem can compute how long ago the first minislot really
started. Minislot length is network dependent. A typical payload is 8
bytes.

During initialization, the headend also assigns each modem to a minislot
to use for requesting upstream bandwidth. As a rule, multiple modems
will be assigned the same minislot, which leads to contention. When a
computer wants to send a packet, it transfers the packet to the modem,
which then requests the necessary number of minislots for it. If the
request is accepted, the headend puts an acknowledgement on the
downstream channel telling the modem which minislots have been reserved
for its packet. The packet is then sent, starting in the minislot
allocated to it. Additional packets can be requested using a field in
the header.

On the other hand, if there is contention for the request minislot,
there will be no acknowledgement and the modem just waits a random time
and tries again. After each successive failure, the randomization time
is doubled. (For readers already somewhat familiar with networking, this
algorithm is just slotted ALOHA with binary exponential backoff.
Ethernet cannot be used on cable because stations cannot sense the
medium. We will come back to these issues in
\protect\hyperlink{0130661023_ch04.htmlux5cux23ch04}{Chap. 4}.)

The downstream channels are managed differently from the upstream
channels. For one thing, there is only one sender (the headend) so there
is no contention and no need for minislots, which is actually just time
division statistical multiplexing. For another, the traffic downstream
is usually much larger than upstream, so a fixed packet size of 204
bytes is used. Part of that is a Reed-Solomon error-correcting code and
some other overhead, leaving a user payload of 184 bytes. These numbers
were chosen for compatibility with digital television using MPEG-2, so
the TV and downstream data channels are formatted the same way.
Logically, the connections are as depicted in
\protect\hyperlink{0130661023_ch02lev1sec7.htmlux5cux23ch02fig49}{Fig.
2-49}.

\subparagraph[Figure 2-49. Typical details of the upstream and
downstream channels in North
America.]{\texorpdfstring{\protect\hypertarget{0130661023_ch02lev1sec7.htmlux5cux23ch02fig49}{}{}Figure
2-49. Typical details of the upstream and downstream channels in North
America.}{Figure 2-49. Typical details of the upstream and downstream channels in North America.}}

%\includegraphics{02fig49.gif}

Getting back to modem initialization, once the modem has completed
ranging and gotten its upstream channel, downstream channel, and
minislot assignments, it is free to start sending packets. The first
packet it sends is one to the ISP requesting an IP address, which is
dynamically assigned using a protocol called DHCP, which we will study
in \protect\hyperlink{0130661023_ch05.htmlux5cux23ch05}{Chap. 5}. It
also requests and gets an accurate time of day from the headend.

The next step involves security. Since cable is a shared medium, anybody
who wants to go to the trouble to do so can read all the traffic going
past him. To prevent everyone from snooping on their neighbors
(literally), all traffic is encrypted in both directions. Part of the
initialization procedure involves establishing encryption keys. At first
one might think that having two strangers, the headend and the modem,
establish a secret key in broad daylight with thousands of people
watching would be impossible. Turns out it is not, but we have to wait
until \protect\hyperlink{0130661023_ch08.htmlux5cux23ch08}{Chap. 8} to
explain how (the short answer: use the Diffie-Hellman algorithm).

Finally, the modem has to log in and provide its unique identifier over
the secure channel. At this point the initialization is complete. The
user can now log in to the ISP and get to work.

There is much more to be said about cable modems. Some relevant
references are (Adams and Dulchinos, 2001; Donaldson and Jones, 2001;
and Dutta-Roy, 2001).

\protect\hypertarget{0130661023_ch02lev1sec7.htmlux5cux23ch02lev2sec29}{}{}

\subsection{ADSL versus Cable}

Which is better, ADSL or cable? That is like asking which operating
system is better. Or which language is better. Or which religion. Which
answer you get depends on whom you ask. Let us compare ADSL and cable on
a few points. Both use fiber in the backbone, but they differ on the
edge. Cable uses coax; ADSL uses twisted pair. The theoretical carrying
capacity of coax is hundreds of times more than twisted pair. However,
the full capacity of the cable is not available for data users because
much of the cable's bandwidth is wasted on useless stuff such as
television programs.

In practice, it is hard to generalize about effective capacity. ADSL
providers give specific statements about the bandwidth (e.g., 1 Mbps
downstream, 256 kbps upstream) and generally achieve about 80\% of it
consistently. Cable providers do not make any claims because the
effective capacity depends on how many people are currently active on
the user's cable segment. Sometimes it may be better than ADSL and
sometimes it may be worse. What can be annoying, though, is the
unpredictability. Having great service one minute does not guarantee
great service the next minute since the biggest bandwidth hog in town
may have just turned on his computer.

As an ADSL system acquires more users, their increasing numbers have
little effect on existing users, since each user has a dedicated
connection. With cable, as more subscribers sign up for Internet
service, performance for existing users will drop. The only cure is for
the cable operator to split busy cables and connect each one to a fiber
node directly. Doing so costs time and money, so their are business
pressures to avoid it.

As an aside, we have already studied another system with a shared
channel like cable: the mobile telephone system. Here, too, a group of
users, we could call them cellmates, share a fixed amount of bandwidth.
Normally, it is rigidly divided in fixed chunks among the active users
by FDM and TDM because voice traffic is fairly smooth. But for data
traffic, this rigid division is very inefficient because data users are
frequently idle, in which case their reserved bandwidth is wasted.
Nevertheless, in this respect, cable access is more like the mobile
phone system than it is like the fixed system.

Availability is an issue on which ADSL and cable differ. Everyone has a
telephone, but not all users are close enough to their end office to get
ADSL. On the other hand, not everyone has cable, but if you do have
cable and the company provides Internet access, you can get it. Distance
to the fiber node or headend is not an issue. It is also worth noting
that since cable started out as a television distribution medium, few
businesses have it.

Being a point-to-point medium, ADSL is inherently more secure than
cable. Any cable user can easily read all the packets going down the
cable. For this reason, any decent cable provider will encrypt all
traffic in both directions. Nevertheless, having your neighbor get your
encrypted messages is still less secure than having him not get anything
at all.

The telephone system is generally more reliable than cable. For example,
it has backup power and continues to work normally even during a power
outage. With cable, if the power to any amplifier along the chain fails,
all downstream users are cut off instantly.

Finally, most ADSL providers offer a choice of ISPs. Sometimes they are
even required to do so by law. This is not always the case with cable
operators.

The conclusion is that ADSL and cable are much more alike than they are
different. They offer comparable service and, as competition between
them heats up, probably comparable prices.

\section{Summary}

The physical layer is the basis of all networks. Nature imposes two
fundamental limits on all channels, and these determine their bandwidth.
These limits are the Nyquist limit, which deals with noiseless channels,
and the Shannon limit, which deals with noisy channels.

Transmission media can be guided or unguided. The principal guided media
are twisted pair, coaxial cable, and fiber optics. Unguided media
include radio, microwaves, infrared, and lasers through the air. An
up-and-coming transmission system is satellite communication, especially
LEO systems.

A key element in most wide area networks is the telephone system. Its
main components are the local loops, trunks, and switches. Local loops
are analog, twisted pair circuits, which require modems for transmitting
digital data. ADSL offers speeds up to 50 Mbps by dividing the local
loop into many virtual channels and modulating each one separately.
Wireless local loops are another new development to watch, especially
LMDS.

Trunks are digital, and can be multiplexed in several ways, including
FDM, TDM, and WDM. Both circuit switching and packet switching are
important.

For mobile applications, the fixed telephone system is not suitable.
Mobile phones are currently in widespread use for voice and will soon be
in widespread use for data. The first generation was analog, dominated
by AMPS. The second generation was digital, with D-AMPS, GSM, and CDMA
the major options. The third generation will be digital and based on
broadband CDMA.

An alternative system for network access is the cable television system,
which has gradually evolved from a community antenna to hybrid fiber
coax. Potentially, it offers very high bandwidth, but the actual
bandwidth available in practice depends heavily on the number of other
users currently active and what they are doing.

\protect\hypertarget{0130661023_ch02lev1sec8.htmlux5cux23ch02lev2sec30}{}{}

\paragraph{Problems}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  {}

Compute the Fourier coefficients for the function {f}({t}) = {t} (0
%\includegraphics{u2264.gif}
{t}
%\includegraphics{u2264.gif} 1){.}
\end{enumerate}

A noiseless 4-kHz channel is sampled every 1 msec. What is the maximum
data rate?

Television channels are 6 MHz wide. How many bits/sec can be sent if
four-level digital signals are used? Assume a noiseless channel.

If a binary signal is sent over a 3-kHz channel whose signal-to-noise
ratio is 20 dB, what is the maximum achievable data rate?

What signal-to-noise ratio is needed to put a T1 carrier on a 50-kHz
line?

What is the difference between a passive star and an active repeater in
a fiber network?

How much bandwidth is there in 0.1 micron of spectrum at a wavelength of
1 micron?

It is desired to send a sequence of computer screen images over an
optical fiber. The screen is 480 x 640 pixels, each pixel being 24 bits.
There are 60 screen images per second. How much bandwidth is needed, and
how many microns of wavelength are needed for this band at 1.30 microns?

Is the Nyquist theorem true for optical fiber or only for copper wire?

In
\protect\hyperlink{0130661023_ch02lev1sec2.htmlux5cux23ch02fig06}{Fig.
2-6} the lefthand band is narrower than the others. Why?

Radio antennas often work best when the diameter of the antenna is equal
to the wavelength of the radio wave. Reasonable antennas range from 1 cm
to 5 meters in diameter. What frequency range does this cover?

Multipath fading is maximized when the two beams arrive 180 degrees out
of phase. How much of a path difference is required to maximize the
fading for a 50-km-long 1-GHz microwave link?

A laser beam 1 mm wide is aimed at a detector 1 mm wide 100 m away on
the roof of a building. How much of an angular diversion (in degrees)
does the laser have to have before it misses the detector?

The 66 low-orbit satellites in the Iridium project are divided into six
necklaces around the earth. At the altitude they are using, the period
is 90 minutes. What is the average interval for handoffs for a
stationary transmitter?

Consider a satellite at the altitude of geostationary satellites but
whose orbital plane is inclined to the equatorial plane by an angle
%\includegraphics{u03d5.gif}
. To a stationary user on the earth's surface
at north latitude
%\includegraphics{u03d5.gif}
, does this satellite
appear motionless in the sky? If not, describe its motion.

How many end office codes were there pre-1984, when each end office was
named by its three-digit area code and the first three digits of the
local number? Area codes started with a digit in the range 2--9, had a 0
or 1 as the second digit, and ended with any digit. The first two digits
of a local number were always in the range 2--9. The third digit could
be any digit.

Using {only} the data given in the text, what is the maximum number of
telephones that the existing U.S. system can support without changing
the numbering plan or adding additional equipment? Could this number of
telephones actually be achieved? For purposes of this problem, a
computer or fax machine counts as a telephone. Assume there is only one
device per subscriber line.

A simple telephone system consists of two end offices and a single toll
office to which each end office is connected by a 1-MHz full-duplex
trunk. The average telephone is used to make four calls per 8-hour
workday. The mean call duration is 6 min. Ten percent of the calls are
long-distance (i.e., pass through the toll office). What is the maximum
number of telephones an end office can support? (Assume 4 kHz per
circuit.)

A regional telephone company has 10 million subscribers. Each of their
telephones is connected to a central office by a copper twisted pair.
The average length of these twisted pairs is 10 km. How much is the
copper in the local loops worth? Assume that the cross section of each
strand is a circle 1 mm in diameter, the density of copper is 9.0
grams/cm\textsuperscript{3}, and that copper sells for 3 dollars per
kilogram.

Is an oil pipeline a simplex system, a half-duplex system, a full-duplex
system, or none of the above?

The cost of a fast microprocessor has dropped to the point where it is
now possible to put one in each modem. How does that affect the handling
of telephone line errors?

A modem constellation diagram similar to
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig25}{Fig.
2-25} has data points at the following coordinates: (1, 1), (1, -1),
(-1, 1), and (-1, -1). How many bps can a modem with these parameters
achieve at 1200 baud?

A modem constellation diagram similar to
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig25}{Fig.
2-25} has data points at (0, 1) and (0, 2). Does the modem use phase
modulation or amplitude modulation?

In a constellation diagram, all the points lie on a circle centered on
the origin. What kind of modulation is being used?

How many frequencies does a full-duplex QAM-64 modem use?

An ADSL system using DMT allocates 3/4 of the available data channels to
the downstream link. It uses QAM-64 modulation on each channel. What is
the capacity of the downstream link?

In the four-sector LMDS example of
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig30}{Fig.
2-30}, each sector has its own 36-Mbps channel. According to queueing
theory, if the channel is 50\% loaded, the queueing time will be equal
to the download time. Under these conditions, how long does it take to
download a 5-KB Web page? How long does it take to download the page
over a 1-Mbps ADSL line? Over a 56-kbps modem?

Ten signals, each requiring 4000 Hz, are multiplexed on to a single
channel using FDM. How much minimum bandwidth is required for the
multiplexed channel? Assume that the guard bands are 400 Hz wide.

Why has the PCM sampling time been set at 125 sec?

What is the percent overhead on a T1 carrier; that is, what percent of
the 1.544 Mbps are not delivered to the end user?

Compare the maximum data rate of a noiseless 4-kHz channel using

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  {}

  (a) Analog encoding (e.g., QPSK) with 2 bits per sample.
\end{enumerate}

(b) The T1 PCM system.

If a T1 carrier system slips and loses track of where it is, it tries to
resynchronize using the 1st bit in each frame. How many frames will have
to be inspected on average to resynchronize with a probability of 0.001
of being wrong?

What is the difference, if any, between the demodulator part of a modem
and the coder part of a codec? (After all, both convert analog signals
to digital ones.)

A signal is transmitted digitally over a 4-kHz noiseless channel with
one sample every 125 sec{.} How many bits per second are actually sent
for each of these encoding methods?

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  {}

  (a) CCITT 2.048 Mbps standard.
\end{enumerate}

(b) DPCM with a 4-bit relative signal value.

(c) Delta modulation.

A pure sine wave of amplitude {A} is encoded using delta modulation,
with {x} samples/sec. An output of +1 corresponds to a signal change of
+{A/}8, and an output signal of -1 corresponds to a signal change of
-{A/}8{.} What is the highest frequency that can be tracked without
cumulative error?

SONET clocks have a drift rate of about 1 part in 10\textsuperscript{9}.
How long does it take for the drift to equal the width of 1 bit? What
are the implications of this calculation?

In
\protect\hyperlink{0130661023_ch02lev1sec5.htmlux5cux23ch02fig37}{Fig.
2-37}, the user data rate for OC-3 is stated to be 148.608 Mbps. Show
how this number can be derived from the SONET OC-3 parameters.

To accommodate lower data rates than STS-1, SONET has a system of
virtual tributaries (VT). A VT is a partial payload that can be inserted
into an STS-1 frame and combined with other partial payloads to fill the
data frame. VT1.5 uses 3 columns, VT2 uses 4 columns, VT3 uses 6
columns, and VT6 uses 12 columns of an STS-1 frame. Which VT can
accommodate

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  {}

  (a) A DS-1 service (1.544 Mbps)?
\end{enumerate}

(b) European CEPT-1 service (2.048 Mbps)?

(c) A DS-2 service (6.312 Mbps)?

What is the essential difference between message switching and packet
switching?

What is the available user bandwidth in an OC-12c connection?

Three packet-switching networks each contain {n} nodes. The first
network has a star topology with a central switch, the second is a
(bidirectional) ring, and the third is fully interconnected, with a wire
from every node to every other node. What are the best-, average-,
and-worst case transmission paths in hops?

Compare the delay in sending an {x}-bit message over a {k}-hop path in a
circuit-switched network and in a (lightly loaded) packet-switched
network. The circuit setup time is {s} sec, the propagation delay is {d}
sec per hop, the packet size is {p} bits, and the data rate is {b} bps.
Under what conditions does the packet network have a lower delay?

Suppose that {x} bits of user data are to be transmitted over a {k}-hop
path in a packet-switched network as a series of packets, each
containing {p} data bits and {h} header bits, with {x}
%\includegraphics{u226b.gif}
 {p} + {h.} The bit rate of the lines is {b}
bps and the propagation delay is negligible. What value of {p} minimizes
the total delay?

In a typical mobile phone system with hexagonal cells, it is forbidden
to reuse a frequency band in an adjacent cell. If 840 frequencies are
available, how many can be used in a given cell?

The actual layout of cells is seldom as regular that as shown in
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig41}{Fig.
2-41}. Even the shapes of individual cells are typically irregular. Give
a possible reason why this might be.

Make a rough estimate of the number of PCS microcells 100 m in diameter
it would take to cover San Francisco (120 square km).

Sometimes when a mobile user crosses the boundary from one cell to
another, the current call is abruptly terminated, even though all
transmitters and receivers are functioning perfectly. Why?

D-AMPS has appreciably worse speech quality than GSM. Is this due to the
requirement that D-AMPS be backward compatible with AMPS, whereas GSM
had no such constraint? If not, what is the cause?

Calculate the maximum number of users that D-AMPS can support
simultaneously within a single cell. Do the same calculation for GSM.
Explain the difference.

Suppose that {A}, {B}, and {C} are simultaneously transmitting 0 bits,
using a CDMA system with the chip sequences of
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig45}{Fig.
2-45(b)}. What is the resulting chip sequence?

In the discussion about orthogonality of CDMA chip sequences, it was
stated that if {S}{T} = 0 then
%\includegraphics{01icon01.gif}
 is also
0. Prove this.

Consider a different way of looking at the orthogonality property of
CDMA chip sequences. Each bit in a pair of sequences can match or not
match. Express the orthogonality property in terms of matches and
mismatches.

A CDMA receiver gets the following chips: (-1 +1 -3 +1 -1 -3 +1 +1).
Assuming the chip sequences defined in
\protect\hyperlink{0130661023_ch02lev1sec6.htmlux5cux23ch02fig45}{Fig.
2-45(b)}, which stations transmitted, and which bits did each one send?

At the low end, the telephone system is star shaped, with all the local
loops in a neighborhood converging on an end office. In contrast, cable
television consists of a single long cable snaking its way past all the
houses in the same neighborhood. Suppose that a future TV cable were 10
Gbps fiber instead of copper. Could it be used to simulate the telephone
model of everybody having their own private line to the end office? If
so, how many one-telephone houses could be hooked up to a single fiber?

A cable TV system has 100 commercial channels, all of them alternating
programs with advertising. Is this more like TDM or like FDM?

A cable company decides to provide Internet access over cable in a
neighborhood consisting of 5000 houses. The company uses a coaxial cable
and spectrum allocation allowing 100 Mbps downstream bandwidth per
cable. To attract customers, the company decides to guarantee at least 2
Mbps downstream bandwidth to each house at any time. Describe what the
cable company needs to do to provide this guarantee.

Using the spectral allocation shown in
\protect\hyperlink{0130661023_ch02lev1sec7.htmlux5cux23ch02fig48}{Fig.
2-48} and the information given in the text, how many Mbps does a cable
system allocate to upstream and how many to downstream?

How fast can a cable user receive data if the network is otherwise idle?

Multiplexing STS-1 multiple data streams, called tributaries, plays an
important role in SONET. A 3:1 multiplexer multiplexes three input STS-1
tributaries onto one output STS-3 stream. This multiplexing is done byte
for byte, that is, the first three output bytes are the first bytes of
tributaries 1, 2, and 3, respectively. The next three output bytes are
the second bytes of tributaries 1, 2, and 3, respectively, and so on.
Write a program that simulates this 3:1 multiplexer. Your program should
consist of five processes. The main process creates four processes, one
each for the three STS-1 tributaries and one for the multiplexer. Each
tributary process reads in an STS-1 frame from an input file as a
sequence of 810 bytes. They send their frames (byte by byte) to the
multiplexer process. The multiplexer process receives these bytes and
outputs an STS-3 frame (byte by byte) by writing it on standard output.
Use pipes for communication among processes.
